{"id": "http://karpathy.github.io/_p0", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p0", "contents": "Apr 27, 2011"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p1", "contents": "Note, this post is from 2011 and slightly outdated in some places."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p2", "contents": "Statistics. CIFAR-10 consists of 50,000 training images, all of them in 1 of 10 categories (displayed left). The test set consists of 10,000 novel images from the same categories, and the task is to classify each to its category. The state of the art is currently at about 80% classification accuracy (4000 centroids), achieved by Adam Coates et al. (PDF). This paper achieved the accuracy by using whitening, k-means to learn many centroids, and then using a soft activation function as features."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p3", "contents": "State of the Art performance. By the way, running their method with 1600 centroids gives 77% classification accuracy. If you set the clusters to be random the accuracy becomes 70%, and if you set the clusters to be random patches from the training set, the accuracy goes up to 74%. It seems like the whole purpose of k-means is to nicely spread out the clusters around the data. I\u2019m guessing that the 70% random clusters performance might be because many of the clusters are relatively too far away from data manifolds, and never become activated \u2013 it\u2019s as if you had much fewer clusters to begin with."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p4", "contents": "Human Accuracy. Over the weekend I wanted to see what kind of classification accuracy a human would achieve on this dataset. I set out to write some quick MATLAB code that would provide the interface to do this. It showed one image at a time and allowed me to press a key from 0-9 indicating my belief about its class category. My classification accuracy ended up at about 94% on 400 images. Why not 100%? Because some images are really unfair! To give you an idea, here are some questionable images from CIFAR-10:\n"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p5", "contents": "CIFAR-10 human accuracy is approximately 94%"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p6", "contents": "A few observations I derived from this exercise:"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p7", "contents": "The objects within classes in this dataset can be extremely varied. For example the \u201cbird\u201d class contains many different types of bird (both big birds and small). Not only are there many types of bird, but the occur at many possible magnifications, all possible angles and all possible poses. Sometimes only parts of the bird are shown. The poses problem is even worse for the dog/cat category, because these animals occur at many many different types of poses, and sometimes only the head is shown. Or left part of the body, etc."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p8", "contents": "My classification method felt strangely dichotomous. Sometimes you can clearly see the animal or object and classify it based very highly-informative distinct parts (for example, you find ears of a cat). Other times, my recognition was purely based on context and the overall cues in the image such as the colors."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p9", "contents": "The CIFAR-10 dataset is too small to properly contain examples of everything that it is asking for in the test set. I base this conclusion at least on my multiple ways of visualizing the nearest image in the training set."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p10", "contents": "I don\u2019t quite understand how Adam Coates et al. perform so well on this dataset (80%) with their method. My guess is that it works along the following lines: looking at the image squinting your eyes you can almost always narrow down the category to about 2 or 3. The final disambiguation probably comes from finding very good specific informative patches (like a patch of some kind of fur, or pointy ear part, etc.). The k-means dictionary must be catching these cases and the SVM likely picks up on them."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p11", "contents": "My impression from this exercise is that it will be hard to go above 80%, but I suspect improvements might be possible up to range of about 85-90%, depending on how wrong I am about the lack of training data. (2015 update: Obviously this prediction was way off, with state of the art now in 95%, as seen in this Kaggle competition leaderboard. I\u2019m impressed!)"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p12", "contents": "I encourage people to try this for themselves (see my code, above), as it is very interesting and fun! I have trouble exactly articulating what I learned, but overall I feel like I gained more intuition for image classification tasks and more appreciation for the difficulty of the problem at hand."}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p13", "contents": "Finally, here is an example of my debugging interface:\n"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p14", "contents": "The Matlab code used to generate these results can be found here"}
{"id": "http://karpathy.github.io//2011/04/27/manually-classifying-cifar10/_p15", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p0", "contents": "Oct 22, 2012"}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p1", "contents": "\nThe picture above is funny."}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p2", "contents": "But for me it is also one of those examples that make me sad about the outlook for AI and for Computer Vision. What would it take for a computer to understand this image as you or I do? I challenge you to think explicitly of all the pieces of knowledge that have to fall in place for it to make sense. Here is my short attempt:"}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p3", "contents": "I could go on, but the point here is that you\u2019ve used a HUGE amount of information in that half second when you look at the picture and laugh. Information about the 3D structure of the scene, confounding visual elements like mirrors, identities of people, affordances and how people interact with objects, physics (how a particular instrument works, \u00a0leaning and what that does), people, their tendency to be insecure about weight, you\u2019ve reasoned about the situation from the point of view of the person on the scale, what he is aware of, what his intents are and what information is available to him, and you\u2019ve reasoned about people reasoning about people. You\u2019ve also thought about the dynamics of the scene and made guesses about how the situation will unfold in the next few seconds visually, how it will unfold in the thoughts of people involved, and you reasoned about how likely or unlikely it is for people of particular identity/status to carry out some action. Somehow all these things come together to \u201cmake sense\u201d of the scene."}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p4", "contents": "It is mind-boggling that all of the above inferences unfold from a brief glance at a 2D array of R,G,B values. The core issue is that the pixel values are just a tip of a huge\u00a0iceberg\u00a0and deriving the entire shape and size of the icerberg from prior knowledge is the most difficult task ahead of us. How can we even begin to go about writing an algorithm that can reason about the scene like I did? Forget for a moment the inference algorithm that is capable of putting all of this together; How do we even begin to gather data that can support these inferences (for example how a scale works)? How do we go about even giving the computer a chance?"}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p5", "contents": "Now consider that the state of the art techniques in Computer Vision are tested on things like Imagenet (task of assigning 1-of-k labels for entire images), or Pascal VOC detection challenge (+ include bounding boxes). There is also quite a bit of work on pose estimation, action recognition, etc., but it is all specific, disconnected, and only half works. I hate to say it but the state of CV and AI is pathetic when we consider the task ahead, and when we think about how we can ever go from here to there. The road ahead is long, uncertain and unclear. \u00a0"}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p6", "contents": "I\u2019ve seen some\u00a0arguments that all we need is lots more data from images, video, maybe text and run some clever learning algorithm: maybe a better objective function, run SGD, maybe anneal the step size, use adagrad, or slap an L1 here and there and everything will just pop out. If we only had a few more tricks up our sleeves!\u00a0But to me, examples like this illustrate that we are missing many crucial pieces of the puzzle and that a central problem will be as much about obtaining the right training data in the right form to support these inferences as it will be about making them."}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p7", "contents": "Thinking about the complexity and scale of the problem further, a seemingly inescapable conclusion for me is that we may also need embodiment, and that the only way to build computers that can interpret scenes like we do is to allow them to get exposed to all the years \u00a0of (structured, temporally coherent) experience we have, \u00a0ability to interact with the world, and some magical active learning/inference architecture that I can barely even imagine when I think backwards about what it should be capable of."}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p8", "contents": "In any case, we are very, very far and this depresses me. What is the way forward? :( Maybe I should just do a startup. I have a really cool idea for a mobile local social iPhone app."}
{"id": "http://karpathy.github.io//2012/10/22/state-of-computer-vision/_p9", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p0", "contents": "Nov 23, 2013"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p1", "contents": "I wanted to share a few examples of a powerful skill that I\u2019ve been gradually picking up over the last year. It is simply the ability to quickly hack together custom browser extensions in Chrome and using them to customize my favorite websites. Writing extensions is very fast: you need a short manifest file that contains some boring meta information, a few js/html files with your code in a folder, and then you simply activate the folder as an extension from the Extensions menu with a few clicks. In general, you can do a lot of fancy things with extensions:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p2", "contents": "I can\u2019t stress how powerful the last item is. You can run Javascript. On top of any webpage. You can Read the page DOM. You can write to it, automatically, on load of the webpage or even periodically! This gives you complete freedom in modifying any webpage to your tastes:\u00a0remove annoying content, add new features, log/scrape website data, change the layout, etc. It\u2019s completely crazy!"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p3", "contents": "I\u2019ll walk you through some examples with possible mods of Twitter just to give you a glimpse of how easy and powerful this can be.\u00a0Twitter is fun and I use it often, but their website is annoying, has some ugly elements, and sometimes lacks certain functionality I would like it to have. A normal person would request features and wait, but with the dark arts of extension hacking we can do much better. Lets get right to it."}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p4", "contents": "A recent change on Twitter added this ugly text, visible by default and always, on every single tweet:\n"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p5", "contents": "I understand it gets people to accidentally click on these more and pads Twitter\u2019s engagement numbers, but it\u2019s useless, ugly, and it just takes up too much space. Lets right click on one of these and choose Inspect Element. This opens up the HTML of the page and here we see the culprit DOM elements:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p7", "contents": "So we have a list <ul></ul> with items <li> one for each of Reply, Retweet, Favorite and More. Inside every of them they have a <a>(anchor that processes the click action), deeper we have a <span> that becomes the icon, and finally followed by the ugly text wrapped in <b>. That looks easy enough, we will find all these elements based on their \u00a0class attribute, descend down to find the text and get rid of it.\u00a0\u00a0So we create a new folder for TwitterClean extension, copy paste some manifest boring code and set it up to load a javascript file anytime twitter loads. For example, right after twitter.com page loads, lets execute:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p8", "contents": "Load the Extension, refresh Twitter and poof! All the text is gone and we\u2019re just left with the icons. These suffice. Oh and while we\u2019re at code we run automatically on load of twitter.com, lets slip this one is as well:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p9", "contents": "I\u2019ll let you figure out what that single naughty line of code does for you :)"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p10", "contents": "Here\u2019s another annoyance: you have your Twitter running on your side monitor and new tweets come in, but Twitter doesn\u2019t load them automatically! It just shows this:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p12", "contents": "That\u2019s the passive aggressive look of Twitter telling you that there are two more tweets to show, but also refusing to actually show them. That would be too useful to their users. Instead, they want you to stop what you\u2019re doing and click the button to load the new tweets. Luckily, you are skilled at extension hacking so you can simply right click the caption, go to Inspect Element, and see that the <div> element that tells you there are more tweets has class \u201cjs-new-tweets-bar\u201d. Easy enough:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p13", "contents": "When this gets run when twitter.com loads, it sets up the code to look for the annoying bar every second (1000 milliseconds) and then runs its click event handler which loads the new tweets. That\u2019s all it takes, and now your tweets are streaming down automatically whenever they are available without you having to explicitly refresh them all the time. We\u2019ve only written code for 5 minutes and in that time we tweaked the way Twitter looked, removed some \u201cfunctionality\u201d and added some functionality! We\u2019re on a roll! Let\u2019s do something fancier now."}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p14", "contents": "One day I decided to collect tweets on my timeline over a period of a week using Twitter\u2019s REST API and saw that 30 accounts make up 50% of everything I see on Twitter. Since I follow 384 accounts in total, that\u2019s only 7%! Unfortunately, for Twitter every tweet is created equal, which means that this annoying social media guru person who tweets 100 times a day completely drowns tweets coming from your other friends who believe that one should also have something worthy of tweeting too. Okay well it\u2019s not exactly like that but I wished there was a mechanism for highlighting the very infrequent tweeters and seeing that low frequency content. Twitter will never implement this because it makes Zero sense for their revenue model, but luckily, we can hack this together quite easily! First, here\u2019s a function that goes through all tweets on your timeline, looks at who tweeted, and \u201ccharges\u201d every unique tweet to the originating user:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p15", "contents": "Basically, it turns out every tweet has class \u201ctweet\u201d, so it is trivial to iterate over them as seen above. Similarly, by inspecting the way the HTML is laid out, it turns out we can simply scrape the user and the (unique) tweet id and use it to build up a dictionary of user_string -> [tweet id, ...]. Of course, we will have to let this accumulate for a few days before it measures a good tweeting frequency distribution for all people we follow as we visit Twitter again and again always seeing new tweets from more people. But this also means we have to load and save the charge dictionary from Chrome\u2019s local extension storage or otherwise we would lose all our charging work whenever we close the Tab! Easy enough:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p16", "contents": "Now we just make sure to run load_charge() at start up, and save_charge() anytime there are new tweets and our charge dictionary changes. Based on this charge dictionary we can easily find, say, the 50th percentile frequency, and highlight any tweet that comes from a user who tweets less often than 50% of the users we follow:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p17", "contents": "This is just one possibility out of many. Here, ratio will be low for users who rarely tweet, and we\u2019re setting their tweet to be yellow based on their rareness. Very hard to not notice on your timeline! :) And while we\u2019re at it, why not also fit in:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p18", "contents": "This way, Elon Musk\u2019s (or your other Twitter favorites) tweets will always glow a vibrant, green color that is hard to notice! Nice. Here\u2019s what we get:"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p20", "contents": "Just look at that! Mashable and some person who needed every single one of his followers to know \u201cAarrrgh\u201d look normal, Elon\u2019s tweets are hard to miss green, and someone who doesn\u2019t tweet relatively as often is highlighted a bit as yellow."}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p21", "contents": "It took us ~100 lines and 10 minutes of Javascript (with a bit of practice) and we tweaked Twitter\u2019s look, removed err\u2026 undesirable content, made Twitter autorefresh, and added an entirely new feature that highlights infrequent tweepers!"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p22", "contents": "Yet we\u2019ve only barely scratched the surface. If you\u2019re \u00a0comfortable with navigating HTML of pages with Chrome\u2019s awesome inspector and writing HTML/Javascript/CSS, these quick hacks have the potential to significantly improve your online experience by giving you powerful options for customizing your favorite sites. And if you are not comfortable, perhaps it\u2019s time to head over to Chrome Extensions \u201cGetting Started\u201d and write a few hacks :)"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p23", "contents": "Oh, and if you\u2019d like the full code of the above, you may find it here: LINK (Note it is a bit rough around the edges, but then it is a quick hack after all!). Let me know if you have any issues on @karpathy, and until later!"}
{"id": "http://karpathy.github.io//2013/11/23/chrome-extension-programming/_p24", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p0", "contents": "Nov 27, 2013"}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p1", "contents": "I thought it would be fun to analyze the activity on one of my favorite sources of interesting links and information,\u00a0Hacker News. My source of data is a script I\u2019ve set up some time in August that downloads HN (the Front page and the New stories page) every minute. We will be interested in visualizing the stories as they get upvoted during the day, figuring out which domains/users are most popular, what topics are most popular, and the best time to post a story. I\u2019m making all my data and code (Python data collection scripts + IPython Notebook for analysis) available in case you\u2019d like to carry out a similar analysis."}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p2", "contents": "I set up a very simple python script that scrapes the HN front page and the new stories page every minute. A single day of data begins at 4am (PST) and ends at 4am the next day. The .html files are saved compressed as gzipped pickles and one day occupies roughly 10mb in this format. I had bring down my machine for a few days a few times so there are some gaps in the data, but in the end we get 47 days of data from period between August 22 and October 30."}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p3", "contents": "The parsing Python script uses BeautifulSoup to convert the raw HTML into a more structured JSON. This script was by the way by no means simple to write \u2013 HN is based on unstructured tables and I had to discover many strange edge cases in its behavior along the way. At the end I ended up with a 100-line ugliest-parsing-function-ever (really, I\u2019m not proud of it) but it works and outputs something like the following for a single story at a specific snapshot:"}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p4", "contents": "We get 60 such entries every minute (30 for front page and 30 for new page) and these are again all saved to disk. We are now ready to bring out the IPython Notebook and get to the juicy analysis!"}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p5", "contents": "Head over to the IPython Notebook rendered as HTML for the analysis:"}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p7", "contents": "Note: I had the entire dataset and .ipynb Ipython Notebook source available for download but recently took it down to save space on my host (sorry)."}
{"id": "http://karpathy.github.io//2013/11/27/quantifying-hacker-news/_p8", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2014/04/26/datascience-weekly-interview/_p0", "contents": "Apr 26, 2014"}
{"id": "http://karpathy.github.io//2014/04/26/datascience-weekly-interview/_p1", "contents": "I thought I should link this: I\u2019ve given an interview ~two months ago about ConvNetJS, some of my background and a few perspectives on neural net trends and where the field seems to be going, at least in academia. Find it here:"}
{"id": "http://karpathy.github.io//2014/04/26/datascience-weekly-interview/_p2", "contents": "http://www.datascienceweekly.org/blog/14-training-deep-learning-models-browser-andrej-karpathy-interview"}
{"id": "http://karpathy.github.io//2014/04/26/datascience-weekly-interview/_p3", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p0", "contents": "Jul 1, 2014"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p1", "contents": "Inspired by Mark Reid\u2019s blog post Switching from Jekyll to Hakyll I decided to abandon Wordpress and give Jekyll a try (note, I currently do not yet feel pro enough to switch to Haskell-based Hakyll). I can confidently say that I could not be happier about this decision."}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p2", "contents": "\u201cSo what\u2019s wrong with Wordpress?\u201d You may ask. Let\u2019s see, everything:"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p3", "contents": "Wordpress is a bloated, clunky, slow, vulnerable, closed mess."}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p4", "contents": "Jekyll describes itself as a tool for building \u201cSimple, blog-aware, static sites\u201d, and was originally written by one of the Github co-founders, Tom Preston-Werner. It is flat and transparent: Your blog workspace is a single folder with a config file, and a few folders for CSS and HTML templates. All my content, for example, lives in two folders:"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p5", "contents": "That\u2019s it. You call $ jekyll build from command line and it will automatically render all posts it finds in your _posts folder from markdown to HTML, wraps it with header/footer templates, creates the parent index page that lists all your posts and outputs everything into a directory _site. The _site directory holds your entire webpage as static content. It can then be uploaded to a webserver wherever you like."}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p6", "contents": "The entire code base consists of like 7 files. It\u2019s easy to see how the HTML templates get composed to your final site. It\u2019s trivial to tweak the CSS or any of the HTML templates. For example, I added Google Analytics tracking code to all my pages by tweaking the html template, and also Disqus comments to all my posts by tweaking the posts template with the Disqus Javascript code."}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p7", "contents": "Lastly, as you might expect Jekyll is tightly integrated with Github: create a repository that looks like username.github.io and add your files to the repo. Github will automatically compile your files with Jekyll and make the _site folder available. For example, mine lives on karpathy.github.io. Thus, Github makes sure that your blog is beautifully backed up forever in simple markdown, and also hosts your content!"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p8", "contents": "Jekyll strikes the balance: It\u2019s packed with just the right amount of features."}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p9", "contents": "To give a flavor for the workflow, to add a new blog post I proceed as follows:"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p10", "contents": "Now we write the blog post in markdown, here\u2019s an example file:"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p11", "contents": "Lets pop back out to console now. I could preview the changes in a local webserver with $ jekyll serve --watch (the watch switch refreshes any updated files as you write them). Now let\u2019s just push it live:"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p12", "contents": "After the last command, Github will see that my repo has changed and automatically refreshes karpathy.github.io to point to the newly generated _site. My post is live!"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p13", "contents": "Anyway, that\u2019s just a brief taste. Check out Jekyll and get blogging in a sane way!"}
{"id": "http://karpathy.github.io//2014/07/01/switching-to-jekyll/_p14", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p0", "contents": "Jul 2, 2014"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p2", "contents": "I was recently looking into various ways of embedding unlabeled, high-dimensional data in 2 dimensions for visualization. A wide variety of methods have been proposed for this task. This Review paper from 2009 contains nice references to many of them (PCA, Kernel PCA, Isomap, LLE, Autoencoders, etc.). If you have Matlab available, the Dimensionality Reduction Toolbox has a nice implementation of many of these methods. Scikit Learn also has a brief section on Manifold Learning along with the implementation."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p3", "contents": "Among these algorithms, t-SNE comes across as one that has a pleasing, intuitive formulation, simple gradient and nice properties. Here is a Google Tech Talks video of Laurens van der Maaten (the author) explaining the method. I set out to re-implement t-SNE from scratch since doing so is the best way of learning something that I know of, and what better language to do this in than - Javascript! :)"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p4", "contents": "Long story short, I\u2019ve implemented t-SNE in JS, released it as tsnejs on Github, and created a small demo that uses the library to visualize the top twitter accounts based on what they talk about. In this post, I thought it might be fun to document a small 1-day project like this, from beginning to end. This also gives me an opportunity to describe some of my projects toolkit, which others might find useful."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p5", "contents": "First, take a look at the final demo. To create this demo I found the top 500 most followed accounts on Twitter, downloaded 200 of their tweets and then measured differences in what they tweet about. These differences are then fed to t-SNE to produce a 2-dimensional visualization, where nearby people tweet similar things. Fun!"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p6", "contents": "We first have to identify the top 500 tweeps. I googled \u201ctop twitter accounts\u201d and found http://twitaholic.com/ , which lists them out. However, the accounts are embedded in the webpage and we need to extract them in structured format. For this, I love a recent YC startup Kimono; I use it extensively to scrape structured data from websites. It lets you click the elements of interest (the Twitter handles in this case), and extracts them out in JSON. Easy as pie!"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p7", "contents": "Now we have a list of top 500 tweeps and we\u2019d like to obtain their tweets to get an idea about what they tweet about. My library of choice for this task is Tweepy. Their documentation is quite terrible but if you browse the source code things seem relatively simple. Here\u2019s an example call to get 200 tweets for a given user:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p8", "contents": "We iterate this over all users, extract the tweet text, and dumpt it all into files, one per account. I had to be careful with two annoyances in process:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p9", "contents": "One solution for the second annoyance is to use the codecs library:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p10", "contents": "Oh, and lets also grab and save the Twitter profile pictures, which we\u2019ll use in the visualization. An example for one user might be:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p11", "contents": "I should mention that I write a lot of quick and dirty Python code in IPython Notebooks, which I very warmly recommend. If you\u2019re writing all your Python in text editors, you\u2019re seriously missing out."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p12", "contents": "We now have 500 tweeps and their 200 most recent tweets concatenated in 500 files. We\u2019d now like to find who tweets about similar things. Scikit learn is very nice for quick NLP tasks like this. In particular, we load up all the files and create a 500-long array where every element are the 200 concatenated tweets. Then we use the TfidfVectorizer class to extract all words and bigrams from the text data, and to turn every user\u2019s language into one tfidf vector. This vector is a fingerprint of the language that each person uses. Here\u2019s how we can simply wire this up:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p13", "contents": "In the above, user_language_array is the 500-element array that has the concatenated tweets. The TfidfVectorizer class looks through all tweets and takes note of all words (unigrams) and word bigrams (i.e. series of two words). It builds a dictionary out of all unigram/bigrams and essentially counts up how often every person uses each one. Here\u2019s an example of some tweet text converted to unigram/bigrams:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p15", "contents": "The tfidf vectors are returned stacked up as rows inside X, which has size 500 x 87,342. Every one of the 87,342 dimensions corresponds to some unigram or bigram. For example, the 10,000th dimension could correspond to the frequency of usage of the unigram \u201cYOLO\u201d. The vectors are L2 normalized, so the dot product between these vectors is related to the angle between any two vectors. This can be interpreted as the similarity of language. Finally, we dump the matrix and the usernames into a JSON file, and we\u2019re ready to load things up in Javascript!"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p16", "contents": "We now create an .html file and import jQuery (as always), and d3js, which I like to use for any kind of plotting. We load up the JSON that stores our distances and usernames with jQuery, and use d3js to initialize the SVG element that will hold all the users. For starters, we plot the users at random position but we will soon arrange them so that similar users cluster nearby with t-SNE. Inspect the code on the demo page to see the jQuery and d3js parts (Ctrl+U). In the code, we see a few things I like to use:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p18", "contents": "Finally we get to the meat! We need to arrange the users in our d3js plot so that similar users appear nearby. The t-SNE cost function was described in this 2008 paper by van der Maaten and Hinton. Similar to many other methods, we set up two distance metrics in the original and the embedded space and minimize their difference. In t-SNE in particular, the original space distance is based on a Gaussian distribution and the embedded space is based on the heavy-tailed Student-t distribution. The KL-divergence formulation has the nice property that it is asymmetric in how it penalizes distances between the two spaces:"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p19", "contents": "Thus, the algorithm preferentially cares about preserving the local structure of the high-dimensional data. Conveniently, the authors link to multiple implementations of t-SNE on their website, which allows us to see some code for reference as well (if you\u2019re like me, reading code can be much easier than reading text descriptions). We\u2019re ready to write up the Javascript version!"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p20", "contents": "The final code can be seen in tsne.js file, on Github. Note how we\u2019re wrapping all the JS code into a function closure so that we don\u2019t pollute the global namespace. This is a very common trick in Javascript that is essentially used to implement classes. Note also the large number of utility boring code I had to include up top because Javascript is not exactly intended for math :) The core function where all magic happens is costGrad(), which computes the cost function and the gradient of the objective. The correct implementation of this function is double checked with debugGrad() gradient check. Once the analytic gradient checks out compared to numeric gradient, we\u2019re good to go! We set up a piece of Javascript to call our step() function repeatedly (setInterval() call), and we plot the solution as it gets computed."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p21", "contents": "Phew! Final result, again: t-SNE demo."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p22", "contents": "I hope some of the references were useful. If you use tsnejs to embed some of your data, let me know!"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p23", "contents": "I created another demo, this time to visualize word vector embeddings. Head over here to see it. The word embeddings are trained as described in this ACL 2012 paper."}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p24", "contents": "The (unsupervised) objective function makes it so that words that are interchangable (i.e. occur in very similar surrounding context) are close in the embedding. This comes across in the visualization!"}
{"id": "http://karpathy.github.io//2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/_p25", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p0", "contents": "Jul 3, 2014"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p1", "contents": "My summer internship work at Google has turned into a CVPR 2014 Oral titled  \u201cLarge-scale Video Classification with Convolutional Neural Networks\u201d (project page). Politically correct, professional, and carefully crafted scientific exposition in the paper and during my oral presentation at CVPR last week is one thing, but I thought this blog might be a nice medium to also give a more informal and personal account of the story behind the paper and how it fits into a larger context."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p2", "contents": "The thread of this paper begins in Summer of 2011, when I accepted a summer internship offer from Google Research. My project involved Deep Learning for videos, as part of a great team that was at the time only a few people but would later grow to become Google Brain."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p3", "contents": "The goal of the project was to learn spatio-temporal features that could support a variety of video classification tasks. The problem, of course, is that videos are a giant 3-dimensional block of pixel values which is useless in its raw form if you\u2019re trying to classify what objects/concepts occur within. Computer Vision researchers have come up with many ingenious ways of computing hand-crafted features over these pixels to transform the representation into one that is more directly useful to a classification task, but we were interested in learning features from raw data with Deep Learning."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p4", "contents": "\u201d Deep Learning landscape was very different at that time. \u201c"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p5", "contents": "It\u2019s interesting to note that the Deep Learning landscape was very different at that time. Everyone was excited primarily about Unsupervised Learning: The idea of training enormous autoencoders that gobble up all of internet data and automagically create powerful representations that support a large variety of transfer learning tasks. A lot of this ambition was motivated by:"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p6", "contents": "Around this time I became particularly interested in videos because I convinced myself through various thought experiments and neuroscience papers that if unsupervised learning in visual domain was to ever work, it would involve video data. Somehow. I thought the best shot might be some kind of Deep, Slow Feature Analysis objective, but I ended up working on architectures more similar to CVPR 2011 \u201cLearning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis\u201d. However, the summer was over before we could get something interesting scaled over a chunk of YouTube."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p7", "contents": "I left Google that fall and joined Stanford as a PhD student. I was swayed by my project at Google and felt eager to continue working on Unsupervised Feature Learning in visual domains."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p8", "contents": "Images. One of my first rotations was with Andrew Ng, who was also at the time interested in Unsupervised Learning in images. I joined forces with his student Adam Coates who worked on doing so with simple, explicit methods (e.g. k-means). The NIPS paper Emergence of Object-Selective Features in Unsupervised Feature Learning was the result of our efforts, but I didn\u2019t fully believe that the formulation made sense. The algorithm\u2019s only cue for building invariance was through similarity: Things that looked similar (in L2 distance) would group together and become invariants in the layer above. That alone can\u2019t be right, I thought."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p9", "contents": "\u201d I couldn\u2019t see how Unsupervised Learning based solely on images could work. \u201c"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p10", "contents": "More generally, I couldn\u2019t see how Unsupervised Learning based solely on images could work. To an unsupervised algorithm, a patch of pixels with a face on it is exactly as exciting as a patch that contains some weird edge/corner/grass/tree noise stuff. The algorithm shouldn\u2019t worry about the latter but it should spent extra effort worrying about the former. But you would never know this if all you had was a billion patches! It all comes down to this question: if all you have are pixels and nothing else, what distinguishes images of a face, or objects from a random bush, or a corner in the ceilings of a room? I\u2019ll come back to this."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p11", "contents": "3D. At this point it was time for my next rotation. I felt frustrated by working with pixels and started thinking about another line of attack to unsupervised learning. A few ideas that have been dormant in my brain until then centered around the fact that we live and perceive a 3D world. Perhaps images and videos were too hard. Wouldn\u2019t it be more natural if our unsupervised learning algorithms reasoned about 3D structures and arrangements rather than 2D grids of brightness? I felt that humans had advantage in their access to all this information during learning from stereo and structure from motion (and also Active Learning). Were we not giving our algorithms a fair chance when we throw grids of pixels at them and expect something interesting to happen?"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p12", "contents": "\u201d Were we not giving our algorithms a fair chance? \u201c"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p13", "contents": "This was also around the time when the Kinect came out, so I thought I\u2019d give 3D a shot. I rotated with Vladlen Koltun in Graphics and later with Fei-Fei over the summer. I spent a lot of my time wrestling with Kinect, 3D data, Kinect Fusion, Point Clouds, etc. There were four challenges to learning from 3D data that I eventually discovered:"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p14", "contents": "I ended up doing a bit of Unsupervised Object Discovery in my 3D meshes and publishing it at a robotics conference, where it was most relevant (Object Discovery in 3D scenes via Shape Analysis). I was happy that I found a very simple, efficient and surprisingly effective way of computing objectness over 3D meshes, but it wasn\u2019t what I set out to do. I followed up on the project a bit while working with Sebastian Thrun for my last rotation, but I remained unsatisfied and unfulfilled. There was no brain stuff, no huge datasets to learn from, and even if it all worked, it would work on static, boring scenes."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p15", "contents": "This was a low point for me in my PhD. I kept thinking about ways of making unsupervised feature learning work, but kept coming across roadblocks\u2013 both practical but more worryingly, philosophical. I was getting a little burnt out."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p16", "contents": "Around this time I joined Fei-Fei\u2019s lab and looked around for a research direction related to Computer Vision. I wanted my work to involve elements of deep learning and feature learning, but at this time deep learning was not a hot topic in Computer Vision. Many people were skeptical of the endeavor: Deep Learning papers had trouble getting accepted to Computer Vision conferences (see for example, famously Yann LeCun\u2019s public letter to CVPR AC). The other issue was that I felt a little stuck and unsure about how to proceed."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p17", "contents": "AlexNets. It was around this time that the paper that would change the course of my research, and also the course of Computer Vision came out. I\u2019m referring to \u201cImageNet Classification with Deep Convolutional Neural Networks\u201d, in which a Convolutional Neural Network (CNN) significantly outperformed state of the art methods on the ImageNet Classification Challenge. The described CNN architecture has become known as the \u201cAlexNet\u201d, after the first author of the paper: Alex Krizhevsky. ConvNets have come of age and leapfrogged from working on toy MNIST/CIFAR-10 datasets just a year ago, to suddenly running on large images and beating methods that have been developed for years. I did not expect such an astronomical leap and I think neither did most of the community."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p18", "contents": "Transfer Learning. The impressive performance of the AlexNet was interesting by itself, but the second unintuitive finding that followed was that the ImageNet-pretrained representation proved extremely potent in transfer learning tasks to other datasets. Suddenly, people were taking an ImageNet-pretrained CNN, chopping off the classifier layer on top, treating the layers immediately before as a fixed feature extractor and beating state of the art methods across many different datasets (see DeCAF, Overfeat, and Razavian et al.). I still find this rather astonishing. In some parallel universe, I can image a CNN that performs very well on ImageNet but doesn\u2019t necessarily transfer to strange datasets of sculptures, birds and other things, and I\u2019m nodding along and saying that that\u2019s to be expected. But that seems to not be the universe we live in."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p19", "contents": "Fully Supervised. A crucial observation to make here is that AlexNet was trained in a fully supervised regime on the (labeled) ImageNet challenge dataset. There are no unsupervised components to be found. Where does that leave us with unsupervised learning? The main purpose of unsupervised learning was to learn powerful representations from unlabeled data, which could then be used in transfer learning settings on datasets that don\u2019t have that many labels. But what we\u2019re seeing instead is that training on huge, supervised datasets is successfully filling the main intended role of unsupervised learning. This suggests an alternative route to powerful, generic representations that points in the complete opposite direction: Instead of doing unsupervised learning on unlabeled data, perhaps we should train on all the supervised data we have, at the same time, with multi-task objective functions."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p20", "contents": "\u201c\u2026 training on huge, supervised datasets is successfully filling the main intended role of unsupervised learning.\u201d"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p21", "contents": "This brings me back to my point made above: if all you have is pixels, what is the difference between an image of a face and an image of a random corner or a part of a road, or a tree? I struggled with this question for a long time and the ironic answer I\u2019m slowly converging on is: nothing. In absence of labels, there is no difference. So unless we want our algorithms to develop powerful features for faces (and things we care about a lot) alongside powerful features for a sea of background garbage, we may have to pay in labels."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p22", "contents": "When I entered Google the second time this summer, the landscape was very different than what I had seen in 2011. I left 2 years ago implementing unsupervised learning algorithms for learning spatio-temporal (video) features in baby Google Brain. Everything had a researchy feel and we were thinking carefully about loss functions, algorithms, etc. When I came back, I found people buzzing around with their engineer hats on, using adolescent Google Brain to obtain great results across many datasets with huge, 1980-style, fully supervised neural nets (similar to the AlexNet). Supervised, vanilla feed-forward Neural Nets became a hammer and everyone was eager to find all the nails and pick all the low-hanging fruit. This is the atmosphere that surrounded me when I started my second project on learning video features. The recipe was simpler. Are you interested in training nice features for X?"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p23", "contents": "In my case, number 4 turned out to be \u201cLarge-scale Video Classification with Convolutional Neural Networks\u201d, in which we trained large Spatio-Temporal Convolutional Neural Networks. Ironically, the dataset we chose to use (Sports videos) turned out to be a little too easy to learn rich, spatio-temporal features since the network could get very far ignoring much of the motion and relying mostly on static appearances (e.g. if you\u2019re trying to tell difference between tennis and swimming, you need not be concerned with minute movement details). But I expect to see considerable improvements in the coming years. (From others, as I am no longer working on videos.)"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p24", "contents": "Two years ago, I spent a lot of my mental efforts trying to, at least conceptually, crack the problem of learning about the visual world unsupervised. We were going to feed an algorithm with lots and lots of visual data from the internet (images, videos, 3D or whatever else), and it would automatically discover representations that would support a variety of tasks as rich as those that we humans are capable of."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p25", "contents": "But as I reflect on the last two years of my own research, my thought experiments and the trends I\u2019m seeing emerge in current academic literature, I am beginning to suspect that this dream may never be fulfilled - at least in the form we originally intended. Large-scale supervised data (even if weakly labeled) is turning out to be a critical component of many of the most successful applications of Deep Learning. In fact, I\u2019m seeing indications of reversal of the strategy altogether: Instead of learning powerful features with no labels, we might end up learning them from ALL the labels in huge, multi-task (and even multi-modal) networks, gobbling up as many labels as we can get our hands on. This could take form of a Convolutional Network where gradients from multiple distinct datasets flow through the same network and update shared parameters."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p26", "contents": "\u201d Instead of learning powerful features with no labels, we might end up learning them from ALL the labels \u201c"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p27", "contents": "\u201cBut wait, humans learn unsupervised - why give up? We might just be missing something conceptually!\u201d, I\u2019ve heard some of my friends argue. The premise may, unfortunately be false: humans have temporally contiguous RGBD perception and take heavy advantage of Active Learning, Curriculum Learning, and Reinforcement Learning, with help from various pre-wired neural circuits. Imagine a (gruesome) experiment in which we\u2019d sit a toddler in front of a monitor and flash random internet images at him/her for months. Would we expect them to develop the same understanding of the visual world? Because that\u2019s what we\u2019re currently trying to get working with computers."}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p28", "contents": "The strengths, weaknesses and types of data practically available to humans and computers are fundamentally misaligned. Thus, it is unfair to draw direct comparisons and extreme caution should be taken when drawing inspiration from human learning. Perhaps one day when robotics advances to a point where we have masses of embodied robots interacting with the 3-dimensional visual world like we do, I will give unsupervised learning another shot. I suspect it will feature heavy use of temporal information and reinforcement learning. But until then, lets collect some data, train some huge, fully-supervised, multi-task, multi-modal nets and\u2026 \u201cprofit\u201d :)"}
{"id": "http://karpathy.github.io//2014/07/03/feature-learning-escapades/_p29", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p0", "contents": "Aug 3, 2014"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p1", "contents": "I\u2019m always on a lookout for interesting datasets to collect, analyze and interpret. And what better dataset to collect/analyze than the meta-dataset of my own activity collecting/analyzing other datasets? How much time do I *really spend working per day? How do I spend most of that time? What makes me productive? These are all relatively important questions that I\u2019d like answers to, and since I prefer my answers based on data and not confirmation-bias-susceptible personal anecdotes, I wrote ulogme."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p2", "contents": "\u201cI prefer my answers based on data, not confirmation-bias-susceptible personal anecdotes\u201d"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p3", "contents": "I\u2019ve now collected my computer usage data over a period of almost 3 months. In this post I\u2019ll highlight some of the features of the project, some of the insights I was able to derive so far and some thoughts about where I hope I can take it next. And who knows, maybe by the end of the post you\u2019ll want to become a user yourself :)"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p4", "contents": "The idea of tracking and visualizing your computer activity is not at all new. It has been around in various shapes and forms in Quantified Self circles and several programs already exist that try to fill this need. Among the few better known ones are RescueTime and Toggl, but there are literally tens to hundreds of other quite terrible copies. Among all of these, I couldn\u2019t find anything that satisfies a few very simple, basic requirements:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p5", "contents": "Nothing like this (by far, actually) exists, so I set out to implement my own solution."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p6", "contents": "ulogme is small and simple: There are two backend components: a tracking script that records activity and a small local web server wrapper that serves the activity logs to the frontend (visualization pages). The tracking script currently records active window titles (at frequency of once every 2 seconds) and keystroke typing frequency."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p7", "contents": "Lets go through a brief overview of some of the resulting visualizations and features. First there is the single day view. Lets look at my August 1st, for example. The header tells us the day of the recording and there is space for a short \u201cblog\u201d post that can be written up for each day:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p8", "contents": "Now we start to get to the meat. It looks like I was in the office from 10AM to 8PM on this day. Now, remember that we record keystrokes and window titles throughout. What follows is the keystroke breakdown for the day:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p9", "contents": "We see that I spent most of the day coding in Sublime Text 2 (which I use to write Python/JS/C++) and Gmail - Looks like I wrote quite a bit of email! Next, ulogme shows the barcode of the day, as I like to call it. This is a breakdown of all the windows on that day:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p10", "contents": "This view is a little dense so let me unpack it one by one:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p11", "contents": "In the end, ulogme shows the final breakdown of titles that occupied me on this day:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p12", "contents": "That\u2019s interesting, it looks like I actually only spent 10% of my day in Gmail. So even though I wrote a lot, it was just a few emails and chats I quickly sent out."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p13", "contents": "Insights for one day are interesting, but everything becomes signficiantly more meaningful when it is put in context of a large number of days. Perhaps you noticed the \u201cOverview\u201d link on the header; Clicking this takes you to the overview page of ulogme that takes the statistics for all days and puts them together. I recorded my activity for almost 3 months now. Here is the delicious data visualized for the entire period (with some overlayed annotations):"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p14", "contents": "SO AWESOME. There are many fun things to note:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p15", "contents": "Next, ulogme gives me nice breakdown for both keystrokes and time spent in every window, across all time:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p16", "contents": "This is a little incomplete because I do some hacking on my laptop, but it paints an interesting picture nonetheless. It looks like I spent a good chunk of desktop time in Matlab, but seemingly I spend the most amount of time in Chrome screwing around and browsing the internet. Great."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p17", "contents": "What it takes to write a paper. Note that, interestingly, my total time for Latex is 35 hours - this is how long it takes to write a paper! Additionally, I pressed 225,149 keys in my Latex editor and the $ wc -l on my paper .tex file reveals that it has 40,192 characters. Some of it is template code but, at least approximately, this means that it takes about 5.6 characters for every one character in the final paper!"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p18", "contents": "It takes 35 hours and 225,149 keys to write a 40,192-character NIPS paper (i.e. 5.6 characters must be typed for every one final character.)"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p19", "contents": "The final visualization is too long to paste here entirely, but I will show a snippet:"}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p20", "contents": "This visualization seems to suggest that I do most of my work between 10AM and 8PM, and a very productive day is about 50,000 keystrokes. You can also see a bit of my post-NIPS refactory period with much lower keystroke activity."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p21", "contents": "In the end, ulogme tells me that over the last 3 months I\u2019ve pressed a total of 1,608,943 keys over 83 days, or approximately 19,384 per day."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p22", "contents": "Going forward, I\u2019m hoping to make ulogme into a nice, open-sourced pet project. The code is all available on Github under MIT License and anyone is welcome try it out (if you\u2019re on Ubuntu or OSX - Windows is not supported, and if you\u2019re using a modern browser)."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p23", "contents": "And if you\u2019re feeling extra adventurous, I warmly welcome pull requests for new features or bug fixes. The code base is a mix of Python, Javascript and I use d3.js for all visualizations. The project is in fairly early stages and the code is not among the nicest I\u2019ve produced, but I\u2019ve started fairly major refactoring efforts to make the onboarding process easier."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p24", "contents": "In longer term, I\u2019m hoping that ulogme codebase will evolve to become beautifully modular set of data view plugins that could be customized, stacked up and composed in the user interface as desired."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p25", "contents": "Im summary, I feel I\u2019ve gained quite a few insights into my own work habits by just visualizating the data, but there is much more work to be done on the analysis side as well. The holy grail here is still not implemented: What are the correlated of my productivity? Does sleeping more help? Does drinking coffee help? Do vacations or breaks help at all? All of these questions have answers and I can\u2019t wait to find them, in the data."}
{"id": "http://karpathy.github.io//2014/08/03/quantifying-productivity/_p26", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p0", "contents": "Sep 2, 2014"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p1", "contents": "The results of the 2014 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) were published a few days ago. The New York Times wrote about it too. ILSVRC is one of the largest challenges in Computer Vision and every year teams compete to claim the state-of-the-art performance on the dataset. The challenge is based on a subset of the ImageNet dataset that was first collected by Deng et al. 2009, and has been organized by our lab here at Stanford since 2010. This year, the challenge saw record participation with 50% more participants than last year, and records were shattered with staggering improvements in both classification and detection tasks."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p2", "contents": "(My personal) ILSVRC 2014 TLDR: 50% more teams. 50% improved classification and detection. ConvNet ensembles all over the place. Google team wins."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p3", "contents": "Of course there\u2019s much more to it, and all details and takeaways will be discussed at length in Zurich, at the upcoming ECCV 2014 workshop happening on September 12."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p4", "contents": "Additionally, we just (September 2nd) published an arXiv preprint describing the entire history of ILSVRC and a large amount of associated analysis, check it out on arXiv. This post will zoom in on a portion of the paper that I contributed to (Section 6.4 Human accuracy on large-scale image classification) and describe some of its context."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p5", "contents": "For the purposes of this post, I would like to focus, in particular, on image classification because this task is the common denominator for many other Computer Vision tasks. The classification task is made up of 1.2 million images in the training set, each labeled with one of 1000 categories that cover a wide variety of objects, animals, scenes, and even some abstract geometric concepts such as \u201chook\u201d, or \u201cspiral\u201d. The 100,000 test set images are released with the dataset, but the labels are withheld to prevent teams from overfitting on the test set. The teams have to predict 5 (out of 1000) classes and an image is considered to be correct if at least one of the predictions is the ground truth. The test set evaluation is carried out on our end by comparing the predictions to our own set of ground truth labels."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p6", "contents": "I was looking at the results about a week ago and became particularly intrigued by GoogleLeNet\u2019s winning submission for the classification task, which achieved a Hit@5 error rate of only 6.7% on the ILSVRC test set. I was relatively familiar with the scope and difficulty of the classification task: these are unconstrained internet images. They are a jungle of viewpoints, lighting conditions, and variations of all imaginable types. This begged the question: How do humans compare?"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p7", "contents": "There are now several tasks in Computer Vision where the performance of our models is close to human, or even superhuman. Examples of these tasks include face verification, various medical imaging tasks, Chinese character recognition, etc. However, many of these tasks are fairly constrained in that they assume input images from a very particular distribution. For example, face verification models might assume as input only aligned, centered, and normalized images. In many ways, ImageNet is harder since the images come directly from the \u201cjungle of the interwebs\u201d. Is it possible that our models are reaching human performance on such an unconstrained task?"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p8", "contents": "In short, I thought that the impressive performance by the winning team would only make sense if it was put in perspective with human accuracy. I was also in the unique position of being able to evaluate it (given that I share office space with ILSVRC organizers), so I set out to quantify the human accuracy and characterize the differences between human predictions with those of the winning model."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p9", "contents": "Wait, isn\u2019t human accuracy 100%? Thank you, good question. It\u2019s not, because the ILSVRC dataset was not labeled in the same way we are classifying it here. For example, to collect the images for the class \u201cBorder Terrier\u201d the organizers searched the query on internet and retrieved a large collection of images. These were then filtered a bit with humans by asking them a binary \u201cIs this a Border Terrier or not?\u201d. Whatever made it through became the \u201cBorder Terrier\u201d class, and similar for all the other 1000 images. Therefore, the data was not collected in a discriminative but a binary manner, and is also subject to mistakes and inaccuracies. Some images can sometimes also contain multiple of the ILSVRC classes, etc."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p10", "contents": "CIFAR-10 digression. It\u2019s fun to note that about 4 years ago I performed a similar (but much quicker and less detailed) human classification accuracy analysis on CIFAR-10. This was back when the state of the art was at 77% by Adam Coates, and my own accuracy turned out to be 94%. I think the best ConvNets now get about 92%. The post about that can be found here. I never imagined I\u2019d be doing the same for ImageNet a few years down the road :)"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p11", "contents": "There\u2019s one issue to clarify on. You may ask: But wait, the ImageNet test set labels were obtained from humans in the first place. Why go about re-labeling it all over again? Isn\u2019t human performance 0% by definition? Kind of, but not really. It is important to keep in mind that ImageNet was annotated as a binary ask. For example, to collect images of the dog class \u201cKelpie\u201d, the query was submitted to search engines and then humans on Amazon Mechanical Turk were used for the binary task of filtering out the noise. The ILSVRC classification task, on the other hand, is 1000-way classification. It\u2019s not a binary task such as the one used to collect the data."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p12", "contents": "I developed a labeling interface that would help us evaluate the human performance. It looked similar to, but not identical, to the screenshot below:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p13", "contents": "The interface consisted of the test image on the left, and 1000 classes listed on the right. Each class was followed by 13 example images from the training set so that the categories were easier for a human to scan visually. The categories were also sorted in the topological order of the ImageNet hierarchy, which places semantically similar concepts nearby in the list. For example, all motor vehicle-related classes are arranged contiguously in the list. Finally, the interface is web-based so it is easy to naturally scroll through the classes, or search for them by text."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p14", "contents": "Try it out! I\u2019m making the the labeling interface available to everyone so that you can also try labeling ILSVRC yourselves and draw your own conclusions. There are a few modifications in this version from the one we used to collect the data. I added two buttons (Show answer, and Show google prediction), and of course, the images shown in this version are the validation images, not the test set images. The GoogLeNet validation set predictions were graciously provided by the Google team."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p15", "contents": "It was hard. As I beta-tested the interface, the task of labeling images with 5 out of 1000 categories quickly turned out to be extremely challenging, even for some friends in the lab who have been working on ILSVRC and its classes for a while. First we thought we would put it up on AMT. Then we thought we could recruit paid undergrads. Then I organized a labeling party of intense labeling effort only among the (expert labelers) in our lab. Then I developed a modified interface that used GoogLeNet predictions to prune the number of categories from 1000 to only about 100. It was still too hard - people kept missing categories and getting up to ranges of 13-15% error rates. In the end I realized that to get anywhere competitively close to GoogLeNet, it was most efficient if I sat down and went through the painfully long training process and the subsequent careful annotation process myself."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p16", "contents": "It took a while. I ended up training on 500 validation images and then switched to the test set of 1500 images. The labeling happened at a rate of about 1 per minute, but this decreased over time. I only enjoyed the first ~200, and the rest I only did #forscience. (In the end we convinced one more expert labeler to spend a few hours on the annotations, but they only got up to 280 images, with less training, and only got to about 12%). The labeling time distribution was strongly bimodal: Some images are easily recognized, while some images (such as those of fine-grained breeds of dogs, birds, or monkeys) can require multiple minutes of concentrated effort. I became very good at identifying breeds of dogs."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p17", "contents": "It was worth it. Based on the sample of images I worked on, the GoogLeNet classification error turned out to be 6.8% (the error on the full test set of 100,000 images is 6.7%). My own error in the end turned out to be 5.1%, approximately 1.7% better. If you crunch through the statistical significance calculations (i.e. comparing the two proportions with a Z-test) under the null hypothesis of them being equal, you get a one-sided p-value of 0.022. In other words, the result is statistically significant based on a relatively commonly used threshold of 0.05. Lastly, I found the experience to be quite educational: After seeing so many images, issues, and ConvNet predictions you start to develop a really good model of the failure modes."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p18", "contents": "My error turned out to be 5.1%, compared to GoogLeNet error of 6.8%. Still a bit of a gap to close (and more)."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p19", "contents": "We inspected both human and GoogLeNet errors to gain an understanding of common error types and how they compare. The analysis and insights below were derived specifically from GoogLeNet predictions, but I suspect that many of the same errors may be present in other methods. Let me copy paste the analysis from our ILSVRC paper:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p20", "contents": "Types of error that both GoogLeNet human are susceptible to:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p21", "contents": "Multiple objects. Both GoogLeNet and humans struggle with images that contain multiple ILSVRC classes (usually many more than five), with little indication of which object is the focus of the image. This error is only present in the Classification setting, since every image is constrained to have exactly one correct label. In total, we attribute 24 (24%) of GoogLeNet errors and 12 (16%) of human errors to this category. It is worth noting that humans can have a slight advantage in this error type, since it can sometimes be easy to identify the most salient object in the image."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p22", "contents": "Incorrect annotations. We found that approximately 5 out of 1500 images (0.3%) were incorrectly annotated in the ground truth. This introduces an approximately equal number of errors for both humans and GoogLeNet."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p23", "contents": "Types of error that GoogLeNet is more susceptible to than human:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p24", "contents": "Object small or thin. GoogLeNet struggles with recognizing objects that are very small or thin in the image, even if that object is the only object present. Examples of this include an image of a standing person wearing sunglasses, a person holding a quill in their hand, or a small ant on a stem of a flower. We estimate that approximately 22 (21%) of GoogLeNet errors fall into this category, while none of the human errors do. In other words, in our sample of images, no image was mislabeled by a human because they were unable to identify a very small or thin object. This discrepancy can be attributed to the fact that a human can very effectively leverage context and affordances to accurately infer the identity of small objects (for example, a few barely visible feathers near person\u2019s hand as very likely belonging to a mostly occluded quill)."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p25", "contents": "Image filters. Many people enhance their photos with filters that distort the contrast and color distributions of the image. We found that 13 (13%) of the images that GoogLeNet incorrectly classified contained a filter. Thus, we posit that GoogLeNet is not very robust to these distortions. In comparison, only one image among the human errors contained a filter, but we do not attribute the source of the error to the filter."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p26", "contents": "Abstract representations. We found that GoogLeNet struggles with images that depict objects of interest in an abstract form, such as 3D-rendered images, paintings, sketches, plush toys, or statues. An example is the abstract shape of a bow drawn with a light source in night photography, a 3D-rendered robotic scorpion, or a shadow on the ground, of a child on a swing. We attribute approximately 6 (6%) of GoogLeNet errors to this type of error and believe that humans are significantly more robust, with no such errors seen in our sample."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p27", "contents": "Miscellaneous sources. Additional sources of error that occur relatively infrequently include extreme closeups of parts of an object, unconventional viewpoints such as a rotated image, images that can significantly benefit from the ability to read text (e.g. a featureless container identifying itself as \u201cface powder\u201d), objects with heavy occlusions, and images that depict a collage of multiple images. In general, we found that humans are more robust to all of these types of error."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p28", "contents": "Types of error that human is more susceptible to than GoogLeNet:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p29", "contents": "Fine-grained recognition. We found that humans are noticeably worse at fine-grained recognition (e.g. dogs, monkeys, snakes, birds), even when they are in clear view. To understand the difficulty, consider that there are more than 120 species of dogs in the dataset. We estimate that 28 (37%) of the human errors fall into this category, while only 7 (7%) of GoogLeNet erros do."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p30", "contents": "Class unawareness. The annotator may sometimes be unaware of the ground truth class present as a label option. When pointed out as an ILSVRC class, it is usually clear that the label applies to the image. These errors get progressively less frequent as the annotator becomes more familiar with ILSVRC classes. Approximately 18 (24%) of the human errors fall into this category."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p31", "contents": "Insufficient training data. Recall that the annotator is only presented with 13 examples of a class under every category name. However, 13 images are not always enough to adequately convey the allowed class variations. For example, a brown dog can be incorrectly dismissed as a \u201cKelpie\u201d if all examples of a \u201cKelpie\u201d feature a dog with black coat. However, if more than 13 images were listed it would have become clear that a \u201cKelpie\u201d may have a brown coat. Approximately 4 (5%) of human errors fall into this category."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p32", "contents": "We investigated the performance of trained human annotators on a sample of up to 1500 ILSVRC test set images. Our results indicate that a trained human annotator is capable of outperforming the best model (GoogLeNet) by approximately 1.7% (p = 0.022)."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p33", "contents": "We expect that some sources of error may be relatively easily eliminated (e.g. robustness to filters, rotations, collages, effectively reasoning over multiple scales), while others may prove more elusive (e.g. identifying\nabstract representations of objects). On the hand, a large majority of human errors come from fine-grained categories and class unawareness. We expect that the former can be significantly reduced with fine-grained expert annotators, while the latter could be reduced with more practice and greater familiarity with ILSVRC classes."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p34", "contents": "It is clear that humans will soon only be able to outperform state of the art image classification models by use of significant effort, expertise, and time. One interesting follow-up question for future investigation is how computer-level accuracy compares with human-level accuracy on more complex image understanding tasks."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p35", "contents": "\u201cIt is clear that humans will soon only be able to outperform state of the art image classification models by use of significant effort, expertise, and time.\u201d"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p36", "contents": "As for my personal take-away from this week-long exercise, I have to say that, qualitatively, I was very impressed with the ConvNet performance. Unless the image exhibits some irregularity or tricky parts, the ConvNet confidently and robustly predicts the correct label. If you\u2019re feeling adventurous, try out the labeling interface for yourself and draw your own conclusions. I can promise that you\u2019ll gain interesting qualitative insights into where state-of-the-art Computer Vision works, where it fails, and how."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p37", "contents": "EDIT: additional discussions:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p39", "contents": "UPDATE2 (14 Feb 2015):"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p40", "contents": "There have now been several reported results that surpass my 5.1% error on ImageNet. I\u2019m astonished to see such rapid progress. At the same time, I think we should keep in mind the following:"}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p41", "contents": "Human accuracy is not a point. It lives on a tradeoff curve."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p42", "contents": "We trade off human effort and expertise with the error rate: I am one point on that curve with 5.1%. My labmates with almost no training and less patience are another point, with even up to 15% error. And based on some calculations that consider my exact error types and hypothesizing which ones may be easier to fix than others, it\u2019s not unreasonable to suggest that an ensemble of very dedicated expert human labelers might push this down to 3%, with about 2% being an optimistic error rate lower bound. I know it\u2019s not as exciting as having a single number, but it\u2019s the right way of thinking about it. See more details in my recent Google+ post."}
{"id": "http://karpathy.github.io//2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/_p43", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p0", "contents": "Mar 30, 2015"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p1", "contents": "You\u2019ve probably heard that Convolutional Networks work very well in practice and across a wide range of visual recognition problems. You may have also read articles and papers that claim to reach a near \u201chuman-level performance\u201d. There are all kinds of caveats to that (e.g. see my G+ post on Human Accuracy is not a point, it lives on a tradeoff curve), but that is not the point of this post. I do think that these systems now work extremely well across many visual recognition tasks, especially ones that can be posed as simple classification."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p2", "contents": "Yet, a second group of seemingly baffling results has emerged that brings up an apparent contradiction. I\u2019m referring to several people who have noticed that it is possible to take an image that a state-of-the-art Convolutional Network thinks is one class (e.g. \u201cpanda\u201d), and it is possible to change it almost imperceptibly to the human eye in such a way that the Convolutional Network suddenly classifies the image as any other class of choice (e.g. \u201cgibbon\u201d). We say that we break, or fool ConvNets. See the image below for an illustration:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p3", "contents": "This topic has recently gained attention starting with Intriguing properties of neural networks by Szegedy et al. last year. They had a very similar set of images:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p4", "contents": "And a set of very closely related results was later followed by Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images by Nguyen et al. Instead of starting with correctly-classified images and fooling the ConvNet, they had many more examples of performing the same process starting from noise (and hence making the ConvNet confidently classify an incomprehensible noise pattern as some class), or evolving new funny-looking images that the ConvNet is slightly too certain about:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p5", "contents": "I should make the point quickly that these results are not completely new to Computer Vision, and that some have observed the same problems even with our older features, e.g. HOG features. See Exploring the Representation Capabilities of the HOG Descriptor for details."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p6", "contents": "The conclusion seems to be that we can take any arbitrary image and classify it as whatever class we want by adding tiny, imperceptible noise patterns. Worse, it was found that a reasonable fraction of fooling images generalize across different Convolutional Networks, so this isn\u2019t some kind of fragile property of the new image or some overfitting property of the model. There\u2019s something more general about the type of introduced noise that seems to fool many other models. In some sense, it is much more accurate to speak about fooling subspaces rather than fooling images. The latter erroneously makes them seem like tiny points in the super-high-dimensional image space, perhaps similar to rational numbers along the real numbers, when instead they are better thought of as entire intervals. Of course, this work raises security concerns because an adversary could conceivably generate a fooling image of any class on their own computer and upload it to some service with a malicious intent, with a non-zero probability of it fooling the server-side model (e.g. circumventing racy filters)."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p7", "contents": "What is going on?"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p8", "contents": "These results are interesting and worrying, but they have also led to a good amount of confusion among laymen. The most important point of this entire post is the following:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p9", "contents": "These results are not specific to images, ConvNets, and they are also not a \u201cflaw\u201d in Deep Learning. A lot of these results were reported with ConvNets running on images because pictures are fun to look at and ConvNets are state-of-the-art, but in fact the core flaw extends to many other domains (e.g. speech recognition systems), and most importantly, also to simple, shallow, good old-fashioned Linear Classifiers (Softmax classifier, or Linear Support Vector Machines, etc.). This was pointed out and articulated in Explaining and Harnessing Adversarial Examples by Goodfellow et al. We\u2019ll carry out a few experiments very similar to the ones presented in this paper, and see that it is in fact this linear nature that is problematic. And because Deep Learning models use linear functions to build up the architecture, they inherit their flaw. However, Deep Learning by itself is not the cause of the issue. In fact, Deep Learning offers tangible hope for a solution, since we can use all the wiggle of composed functions to design more resistant architectures or objectives."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p10", "contents": "ConvNets express a differentiable function from the pixel values to class scores. For example, a ConvNet might take a 227x227 image and transforms these ~100,000 numbers through a wiggly function (parameterized by several million parameters) to 1000 numbers that we interpret as the confidences for 1000 classes (e.g. the classes of ImageNet)."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p11", "contents": "We train a ConvNet with repeated process of sampling data, calculating the parameter gradients and performing a parameter update. That is, suppose we feed the ConvNet an image of a banana and compute the 1000 scores for the classes that the ConvNet assigns to this image. We then and ask the following question for every single parameter in the model:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p12", "contents": "Normal ConvNet training: \u201cWhat happens to the score of the correct class when I wiggle this parameter?\u201d"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p13", "contents": "This wiggle influence, of course, is just the gradient. For example, some parameter in some filter in some layer of the ConvNet might get the gradient of -3.0 computed during backpropagation. That means that increasing this parameter by a tiny amount, e.g. 0.0001, would have a negative influence on the banana score (due to the negative sign); In this case, we\u2019d expect the banana score to decrease by approximately 0.0003. Normally we take this gradient and use it to perform a parameter update, which wiggles every parameter in the model a tiny amount in the correct direction, to increase the banana score. These parameter updates hence work in concert to slightly increase the score of the banana class for that one banana image (e.g. the banana score could go up from 30% to 34% or something). We then repeat this over and over on all images in the training data."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p14", "contents": "Notice how this worked: we held the input image fixed, and we wiggled the model parameters to increase the score of whatever class we wanted (e.g. banana class). It turns out that we can easily flip this process around to create fooling images. (In practice in fact, absolutely no changes to a ConvNet code base are required.) That is, we will hold the model parameters fixed, and instead we\u2019re computing the gradient of all pixels in the input image on any class we might desire. For example, we can ask:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p15", "contents": "Creating fooling images: \u201cWhat happens to the score of (whatever class you want) when I wiggle this pixel?\u201d"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p16", "contents": "We compute the gradient just as before with backpropagation, and then we can perform an image update instead of a parameter update, with the end result being that we increase the score of whatever class we want. E.g. we can take the banana image and wiggle every pixel according to the gradient of that image on the cat class. This would change the image a tiny amount, but the score of cat would now increase. Somewhat unintuitively, it turns out that you don\u2019t have to change the image too much to toggle the image from being classified correctly as a banana, to being classified as anything else (e.g. cat)."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p17", "contents": "In short, to create a fooling image we start from whatever image we want (an actual image, or even a noise pattern), and then use backpropagation to compute the gradient of the image pixels on any class score, and nudge it along. We may, but do not have to, repeat the process a few times. You can interpret backpropagation in this setting as using dynamic programming to compute the most damaging local perturbation to the input. Note that this process is very efficient and takes negligible time if you have access to the parameters of the ConvNet (backprop is fast), but it is possible to do this even if you do not have access to the parameters but only to the class scores at the end. In this case, it is possible to compute the data gradient numerically, or to to use other local stochastic search strategies, etc. Note that due to the latter approach, even non-differentiable classifiers (e.g. Random Forests) are not safe (but I haven\u2019t seen anyone empirically confirm this yet)."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p18", "contents": "As I mentioned before (and as described in more detail in Goodfellow et al.), it is the use of linear functions that makes our models susceptible for an attack. ConvNets, of course, do not express a linear function from images to class scores; They are a complex Deep Learning model that expresses a highly non-linear function. However, the components that make up a ConvNet are linear: Convolution of a filter with its input is a linear operation (we are sliding a filter through the input and computing dot products - a linear operation), and matrix multiplications are also a linear function."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p19", "contents": "So here\u2019s a fun experiment we\u2019ll do. Lets forget about ConvNets - they are a distracting overkill as far as the core flaw goes. Instead, lets fool a linear classifier and lets also keep with the theme of breaking models on images because they are fun to look at."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p20", "contents": "Here is the setup:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p21", "contents": "Digression: Technical fun parts. The fun part in actually doing this is that the standard AlexNetty ConvNet hyperparameters are of course completely inadequate. For example, normally you\u2019d use weight decay of 0.0005 or so and learning rate of 0.01, and gaussian initialization drawn from a gaussian of 0.01 std. If you\u2019ve trained linear classifiers before on this type of high-dimensional input (64x64x3 ~= 12K numbers), you\u2019ll know that your learning rate will probably have to be much lower, the regularization much larger, and initialization of 0.01 std will probably be inadequate. Indeed, starting Caffe training with default hyperparameters gives a starting loss of about 80, which right away tells you that the initialization is completely out of whack (initial ImageNet loss should be ballpark 7.0, which is -log(1/1000)). I scaled it down to 0.0001 std for Gaussian init which gives sensible starting loss. But then the loss right away explodes which tells you that the learning rate is way too high - I had to scale it all the way down to about 1e-7. Lastly, a weight decay of 0.0005 will give almost negligible regularization loss with 12K inputs - I had to scale it up to 100 to start getting reasonably-looking weights that aren\u2019t super-overfitted noise blobs. It\u2019s fun being a Neural Networks practitioner."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p22", "contents": "A linear classifier over image pixels implies that every class score is computed as a dot product between all the image pixels (stretched as a large column) and a learnable weight vector, one for each class. With input images of size 64x64x3 and 1000 ImageNet classes we therefore have 64x64x3x1000 = 12.3 million weights (beefy linear model!), and 1000 biases. Training these parameters on ImageNet with a K40 GPU takes only a few tens of minutes. We can then visualize each of the learned weights by reshaping them as images:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p23", "contents": "By the way, I haven\u2019t seen anyone report linear classification accuracy on ImageNet before, but it turns out to be about 3.0% top-1 accuracy (and about 10% top-5) on ImageNet. I haven\u2019t done a completely exhaustive hyperparameter sweep but I did a few rounds of manual binary search."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p24", "contents": "Now that we\u2019ve trained the model parameters we can start to produce fooling images. This turns out to be quite trivial in the case of linear classifiers and no backpropagation is required. This is because when your score function is a dot product \\(s = w^Tx\\), then the gradient on the image \\(x\\) is simply \\(\\nabla_x s = w\\). That is, we take an image we would like to start out with, and then if we wanted to fool the model into thinking that it is some other class (e.g. goldfish), we have to take the weights corresponding to the desired class, and add some fraction of those weights to the image:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p25", "contents": "We can also start from random noise and achieve the same effect:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p26", "contents": "Of course, these examples are not as impactful as the ones that use a ConvNet because the ConvNet gives state of the art performance while a linear classifier barely gets to 3% accuracy, but it illustrates the point that even with a simple, shallow function it is still possible to play around with the input in imperceptible ways and get almost arbitrary results."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p27", "contents": "Regularization. There is one subtle comment to make regarding regularization strength. In my experiments above, increasing the regularization strength gave nicer, smoother and more diffuse weights but generalized to validation data worse than some of my best classifiers that displayed more noisy patterns. For example, the nice and smooth templates I\u2019ve shown only achieve 1.6% accuracy. My best model that achieves 3.0% accuracy has noisier weights (as seen in the middle column of the fooling images). Another model with very low regularization reaches 2.8% and its fooling images are virtually indistinguishable yet produce 100% confidences in the wrong class. In particular:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p28", "contents": "Intuitively, it seems that higher regularization leads to smaller weights, which means that one must change the image more dramatically to change the score by some amount. It\u2019s not immediately obvious if and how this conclusion translates to deeper models."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p29", "contents": "We can understand this process in even more detail by condensing the problem to the smallest toy example that displays the problem. Suppose we train a binary logistic regression, where we define the probability of class 1 as \\(P(y = 1 \\mid x; w,b) = \\sigma(w^Tx + b)\\), where \\(\\sigma(z) = 1/(1+e^{-z})\\) is the sigmoid function that squashes the class 1 score \\(s = w^Tx+b\\) into range between 0 and 1, where 0 is mapped to 0.5. This classifier hence decides that the class of the input is 1 if \\(s > 0\\), or equivalently if the class 1 probability is more than 50% (i.e. \\(\\sigma(s) > 0.5\\)). Suppose further that we had the following setup:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p30", "contents": "If you do the dot product, you get -3. Hence, probability of class 1 is 1/(1+e^(-(-3))) = 0.0474. In other words the classifier is 95% certain that this is example is class 0. We\u2019re now going to try to fool the classifier. That is, we want to find a tiny change to x in such a way that the score comes out much higher. Since the score is computed with a dot product (multiply corresponding elements in x and w then add it all up), with a little bit of thought it\u2019s clear what this change should be: In every dimension where the weight is positive, we want to slightly increase the input (to get slightly more score). Conversely, in every dimension where the weight is negative, we want the input to be slightly lower (again, to get slightly more score). In other words, an adversarial xad might be:"}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p31", "contents": "Doing the dot product again we see that suddenly the score becomes 2. This is not surprising: There are 10 dimensions and we\u2019ve tweaked the input by 0.5 in every dimension in such a way that we gain 0.5 in each one, adding up to a total of 5 additional score, rising it from -3 to 2. Now when we look at probability of class 1 we get 1/(1+e^(-2)) = 0.88. That is, we tweaked the original x by a small amount and we improved the class 1 probability from 5% to 88%! Moreover, notice that in this case the input only had 10 dimensions, but an image might consist of many tens of thousands of dimensions, so you can afford to make tiny changes across all of them that all add up in concert in exactly the worst way to blow up the score of any class you wish."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p32", "contents": "Several other related experiments can be found in Explaining and Harnessing Adversarial Examples by Goodfellow et al. This paper is a required reading on this topic. It was the first to articulate and point out the linear functions flaw, and more generally argued that there is a tension between models that are easy to train (e.g. models that use linear functions) and models that resist adversarial perturbations."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p33", "contents": "As closing words for this post, the takeaway is that ConvNets still work very well in practice. Unfortunately, it seems that their competence is relatively limited to a small region around the data manifold that contains natural-looking images and distributions, and that once we artificially push images away from this manifold by computing noise patterns with backpropagation, we stumble into parts of image space where all bets are off, and where the linear functions in the network induce large subspaces of fooling inputs."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p34", "contents": "With wishful thinking, one might hope that ConvNets would produce all-diffuse probabilities in regions outside the training data, but there is no part in an ordinary objective (e.g. mean cross-entropy loss) that explicitly enforces this constraint. Indeed, it seems that  the class scores in these regions of space are all over the place, and worse, a straight-forward attempt to patch this up by introducing a background class and iteratively adding fooling images as a new background class during training are not effective in mitigating the problem."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p35", "contents": "It seems that to fix this problem we need to change our objectives, our forward functional forms, or even the way we optimize our models. However, as far as I know we haven\u2019t found very good candidates for either. To be continued."}
{"id": "http://karpathy.github.io//2015/03/30/breaking-convnets/_p36", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p0", "contents": "May 21, 2015"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p1", "contents": "There\u2019s something magical about Recurrent Neural Networks (RNNs). I still remember when I trained my first recurrent network for Image Captioning. Within a few dozen minutes of training my first baby model (with rather arbitrarily-chosen hyperparameters) started to generate very nice looking descriptions of images that were on the edge of making sense. Sometimes the ratio of how simple your model is to the quality of the results you get out of it blows past your expectations, and this was one of those times. What made this result so shocking at the time was that the common wisdom was that RNNs were supposed to be difficult to train (with more experience I\u2019ve in fact reached the opposite conclusion). Fast forward about a year: I\u2019m training RNNs all the time and I\u2019ve witnessed their power and robustness many times, and yet their magical outputs still find ways of amusing me. This post is about sharing some of that magic with you."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p2", "contents": "We\u2019ll train RNNs to generate text character by character and ponder the question \u201chow is that even possible?\u201d"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p3", "contents": "By the way, together with this post I am also releasing code on Github that allows you to train character-level language models based on multi-layer LSTMs. You give it a large chunk of text and it will learn to generate text like it one character at a time. You can also use it to reproduce my experiments below. But we\u2019re getting ahead of ourselves; What are RNNs anyway?"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p4", "contents": "Sequences. Depending on your background you might be wondering: What makes Recurrent Networks so special? A glaring limitation of Vanilla Neural Networks (and also Convolutional Networks) is that their API is too constrained: they accept a fixed-sized vector as input (e.g. an image) and produce a fixed-sized vector as output (e.g. probabilities of different classes). Not only that: These models perform this mapping using a fixed amount of computational steps (e.g. the number of layers in the model). The core reason that recurrent nets are more exciting is that they allow us to operate over sequences of vectors: Sequences in the input, the output, or in the most general case both. A few examples may make this more concrete:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p5", "contents": "As you might expect, the sequence regime of operation is much more powerful compared to fixed networks that are doomed from the get-go by a fixed number of computational steps, and hence also much more appealing for those of us who aspire to build more intelligent systems. Moreover, as we\u2019ll see in a bit, RNNs combine the input vector with their state vector with a fixed (but learned) function to produce a new state vector. This can in programming terms be interpreted as running a fixed program with certain inputs and some internal variables. Viewed this way, RNNs essentially describe programs. In fact, it is known that RNNs are Turing-Complete in the sense that they can to simulate arbitrary programs (with proper weights). But similar to universal approximation theorems for neural nets you shouldn\u2019t read too much into this. In fact, forget I said anything."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p6", "contents": "If training vanilla neural nets is optimization over functions, training recurrent nets is optimization over programs."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p7", "contents": "Sequential processing in absence of sequences. You might be thinking that having sequences as inputs or outputs could be relatively rare, but an important point to realize is that even if your inputs/outputs are fixed vectors, it is still possible to use this powerful formalism to process them in a sequential manner. For instance, the figure below shows results from two very nice papers from DeepMind. On the left, an algorithm learns a recurrent network policy that steers its attention around an image; In particular, it learns to read out house numbers from left to right (Ba et al.). On the right, a recurrent network generates images of digits by learning to sequentially add color to a canvas (Gregor et al.):"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p8", "contents": "The takeaway is that even if your data is not in form of sequences, you can still formulate and train powerful models that learn to process it sequentially. You\u2019re learning stateful programs that process your fixed-sized data."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p9", "contents": "RNN computation. So how do these things work? At the core, RNNs have a deceptively simple API: They accept an input vector x and give you an output vector y. However, crucially this output vector\u2019s contents are influenced not only by the input you just fed in, but also on the entire history of inputs you\u2019ve fed in in the past. Written as a class, the RNN\u2019s API consists of a single step function:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p10", "contents": "The RNN class has some internal state that it gets to update every time step is called. In the simplest case this state consists of a single hidden vector h. Here is an implementation of the step function in a Vanilla RNN:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p11", "contents": "The above specifies the forward pass of a vanilla RNN. This RNN\u2019s parameters are the three matrices W_hh, W_xh, W_hy. The hidden state self.h is initialized with the zero vector. The np.tanh function implements a non-linearity that squashes the activations to the range [-1, 1]. Notice briefly how this works: There are two terms inside of the tanh: one is based on the previous hidden state and one is based on the current input. In numpy np.dot is matrix multiplication. The two intermediates interact with addition, and then get squashed by the tanh into the new state vector. If you\u2019re more comfortable with math notation, we can also write the hidden state update as \\( h_t = \\tanh ( W_{hh} h_{t-1} + W_{xh} x_t ) \\), where tanh is applied elementwise."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p12", "contents": "We initialize the matrices of the RNN with random numbers and the bulk of work during training goes into finding the matrices that give rise to desirable behavior, as measured with some loss function that expresses your preference to what kinds of outputs y you\u2019d like to see in response to your input sequences x."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p13", "contents": "Going deep. RNNs are neural networks and everything works monotonically better (if done right) if you put on your deep learning hat and start stacking models up like pancakes. For instance, we can form a 2-layer recurrent network as follows:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p14", "contents": "In other words we have two separate RNNs: One RNN is receiving the input vectors and the second RNN is receiving the output of the first RNN as its input. Except neither of these RNNs know or care - it\u2019s all just vectors coming in and going out, and some gradients flowing through each module during backpropagation."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p15", "contents": "Getting fancy. I\u2019d like to briefly mention that in practice most of us use a slightly different formulation than what I presented above called a Long Short-Term Memory (LSTM) network. The LSTM is a particular type of recurrent network that works slightly better in practice, owing to its more powerful update equation and some appealing backpropagation dynamics. I won\u2019t go into details, but everything I\u2019ve said about RNNs stays exactly the same, except the mathematical form for computing the update (the line self.h = ... ) gets a little more complicated. From here on I will use the terms \u201cRNN/LSTM\u201d interchangeably but all experiments in this post use an LSTM."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p16", "contents": "Okay, so we have an idea about what RNNs are, why they are super exciting, and how they work. We\u2019ll now ground this in a fun application: We\u2019ll train RNN character-level language models. That is, we\u2019ll give the RNN a huge chunk of text and ask it to model the probability distribution of the next character in the sequence given a sequence of previous characters. This will then allow us to generate new text one character at a time."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p17", "contents": "As a working example, suppose we only had a vocabulary of four possible letters \u201chelo\u201d, and wanted to train an RNN on the training sequence \u201chello\u201d. This training sequence is in fact a source of 4 separate training examples: 1. The probability of \u201ce\u201d should be likely given the context of \u201ch\u201d, 2. \u201cl\u201d should be likely in the context of \u201che\u201d, 3. \u201cl\u201d should also be likely given the context of \u201chel\u201d, and finally 4. \u201co\u201d should be likely given the context of \u201chell\u201d."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p18", "contents": "Concretely, we will encode each character into a vector using 1-of-k encoding (i.e. all zero except for a single one at the index of the character in the vocabulary), and feed them into the RNN one at a time with the step function. We will then observe a sequence of 4-dimensional output vectors (one dimension per character), which we interpret as the confidence the RNN currently assigns to each character coming next in the sequence. Here\u2019s a diagram:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p19", "contents": "For example, we see that in the first time step when the RNN saw the character \u201ch\u201d it assigned confidence of 1.0 to the next letter being \u201ch\u201d, 2.2 to letter \u201ce\u201d, -3.0 to \u201cl\u201d, and 4.1 to \u201co\u201d. Since in our training data (the string \u201chello\u201d) the next correct character is \u201ce\u201d, we would like to increase its confidence (green) and decrease the confidence of all other letters (red). Similarly, we have a desired target character at every one of the 4 time steps that we\u2019d like the network to assign a greater confidence to. Since the RNN consists entirely of differentiable operations we can run the backpropagation algorithm (this is just a recursive application of the chain rule from calculus) to figure out in what direction we should adjust every one of its weights to increase the scores of the correct targets (green bold numbers). We can then perform a parameter update, which nudges every weight a tiny amount in this gradient direction. If we were to feed the same inputs to the RNN after the parameter update we would find that the scores of the correct characters (e.g. \u201ce\u201d in the first time step) would be slightly higher (e.g. 2.3 instead of 2.2), and the scores of incorrect characters would be slightly lower. We then repeat this process over and over many times until the network converges and its predictions are eventually consistent with the training data in that correct characters are always predicted next."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p20", "contents": "A more technical explanation is that we use the standard Softmax classifier (also commonly referred to as the cross-entropy loss) on every output vector simultaneously. The RNN is trained with mini-batch Stochastic Gradient Descent and I like to use RMSProp or Adam (per-parameter adaptive learning rate methods) to stablilize the updates."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p21", "contents": "Notice also that the first time the character \u201cl\u201d is input, the target is \u201cl\u201d, but the second time the target is \u201co\u201d. The RNN therefore cannot rely on the input alone and must use its recurrent connection to keep track of the context to achieve this task."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p22", "contents": "At test time, we feed a character into the RNN and get a distribution over what characters are likely to come next. We sample from this distribution, and feed it right back in to get the next letter. Repeat this process and you\u2019re sampling text! Lets now train an RNN on different datasets and see what happens."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p23", "contents": "To further clarify, for educational purposes I also wrote a minimal character-level RNN language model in Python/numpy. It is only about 100 lines long and hopefully it gives a concise, concrete and useful summary of the above if you\u2019re better at reading code than text. We\u2019ll now dive into example results, produced with the much more efficient Lua/Torch codebase."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p24", "contents": "All 5 example character models below were trained with the code I\u2019m releasing on Github. The input in each case is a single file with some text, and we\u2019re training an RNN to predict the next character in the sequence."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p25", "contents": "Lets first try a small dataset of English as a sanity check. My favorite fun dataset is the concatenation of Paul Graham\u2019s essays. The basic idea is that there\u2019s a lot of wisdom in these essays, but unfortunately Paul Graham is a relatively slow generator. Wouldn\u2019t it be great if we could sample startup wisdom on demand? That\u2019s where an RNN comes in."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p26", "contents": "Concatenating all pg essays over the last ~5 years we get approximately 1MB text file, or about 1 million characters (this is considered a very small dataset by the way). Technical: Lets train a 2-layer LSTM with 512 hidden nodes (approx. 3.5 million parameters), and with dropout of 0.5 after each layer. We\u2019ll train with batches of 100 examples and truncated backpropagation through time of length 100 characters. With these settings one batch on a TITAN Z GPU takes about 0.46 seconds (this can be cut in half with 50 character BPTT at negligible cost in performance). Without further ado, lets see a sample from the RNN:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p27", "contents": "\u201cThe surprised in investors weren\u2019t going to raise money. I\u2019m not the company with the time there are all interesting quickly, don\u2019t have to get off the same programmers.  There\u2019s a super-angel round fundraising, why do you can do. If you have a different physical investment are become in people who reduced in a startup with the way to argument the acquirer could see them just that you\u2019re also the founders will part of users\u2019 affords that and an alternation to the idea. [2]  Don\u2019t work at first member to see the way kids will seem in advance of a bad successful startup. And if you have to act the big company too.\u201d"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p28", "contents": "Okay, clearly the above is unfortunately not going to replace Paul Graham anytime soon, but remember that the RNN had to learn English completely from scratch and with a small dataset (including where you put commas, apostrophes and spaces). I also like that it learns to support its own arguments (e.g. [2], above). Sometimes it says something that offers a glimmer of insight, such as \u201ca company is a meeting to think to investors\u201d. Here\u2019s a link to 50K character sample if you\u2019d like to see more."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p29", "contents": "Temperature. We can also play with the temperature of the Softmax during sampling. Decreasing the temperature from 1 to some lower number (e.g. 0.5) makes the RNN more confident, but also more conservative in its samples. Conversely, higher temperatures will give more diversity but at cost of more mistakes (e.g. spelling mistakes, etc). In particular, setting temperature very near zero will give the most likely thing that Paul Graham might say:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p30", "contents": "\u201cis that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same\u201d"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p31", "contents": "looks like we\u2019ve reached an infinite loop about startups."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p32", "contents": "It looks like we can learn to spell English words. But how about if there is more structure and style in the data? To examine this I downloaded all the works of Shakespeare and concatenated them into a single (4.4MB) file. We can now afford to train a larger network, in this case lets try a 3-layer RNN with 512 hidden nodes on each layer. After we train the network for a few hours we obtain samples such as:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p33", "contents": "Remember, all the RNN knows are characters, so in particular it samples both speaker\u2019s names and the contents. Sometimes we also get relatively extented monologue passages, such as:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p34", "contents": "I can barely recognize these samples from actual Shakespeare :) If you like Shakespeare, you might appreciate this 100,000 character sample. Of course, you can also generate an infinite amount of your own samples at different temperatures with the provided code."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p35", "contents": "We saw that the LSTM can learn to spell words and copy general syntactic structures. Lets further increase the difficulty and train on structured markdown. In particular, lets take the Hutter Prize 100MB dataset of raw Wikipedia and train an LSTM. Following Graves et al., I used the first 96MB for training, the rest for validation and ran a few models overnight. We can now sample Wikipedia articles! Below are a few fun excerpts. First, some basic markdown output:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p36", "contents": "In case you were wondering, the yahoo url above doesn\u2019t actually exist, the model just hallucinated it. Also, note that the model learns to open and close the parenthesis correctly. There\u2019s also quite a lot of structured markdown that the model learns, for example sometimes it creates headings, lists, etc.:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p37", "contents": "Sometimes the model snaps into a mode of generating random but valid XML:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p38", "contents": "The model completely makes up the timestamp, id, and so on. Also, note that it closes the correct tags appropriately and in the correct nested order. Here are 100,000 characters of sampled wikipedia if you\u2019re interested to see more."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p39", "contents": "The results above suggest that the model is actually quite good at learning complex syntactic structures. Impressed by these results, my labmate (Justin Johnson) and I decided to push even further into structured territories and got a hold of this book on algebraic stacks/geometry. We downloaded the raw Latex source file (a 16MB file) and trained a multilayer LSTM. Amazingly, the resulting sampled Latex almost compiles. We had to step in and fix a few issues manually but then you get plausible looking math, it\u2019s quite astonishing:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p40", "contents": "Here\u2019s another sample:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p41", "contents": "As you can see above, sometimes the model tries to generate latex diagrams, but clearly it hasn\u2019t really figured them out. I also like the part where it chooses to skip a proof (\u201cProof omitted.\u201d, top left). Of course, keep in mind that latex has a relatively difficult structured syntactic format that I haven\u2019t even fully mastered myself. For instance, here is a raw sample from the model (unedited):"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p42", "contents": "This sample from a relatively decent model illustrates a few common mistakes. For example, the model opens a \\begin{proof} environment but then ends it with a \\end{lemma}. This is an example of a problem we\u2019d have to fix manually, and is likely due to the fact that the dependency is too long-term: By the time the model is done with the proof it has forgotten whether it was doing a proof or a lemma. Similarly, it opens an \\begin{enumerate} but then forgets to close it. We observed that these became less common with larger/better models, but nonetheless, these are the kinds of mistakes that come up."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p43", "contents": "I wanted to push structured data to its limit, so for the final challenge I decided to use code. In particular, I took all the source and header files found in the Linux repo on Github, concatenated all of them in a single giant file (474MB of C code) (I was originally going to train only on the kernel but that by itself is only ~16MB). Then I trained several as-large-as-fits-on-my-GPU 3-layer LSTMs over a period of a few days. These models have about 10 million parameters, which is still on the lower end for RNN models. The results are superfun:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p44", "contents": "The code looks really quite great overall. Of course, I don\u2019t think it compiles but when you scroll through the generate code it feels very much like a giant C code base. Notice that the RNN peppers its code with comments here and there at random. It is also very good at making very few syntactic errors. For example, it uses strings properly, pointer notation, etc. It also opens and closes brackets {[ correctly and learns to indent its code very well. A common error is that it can\u2019t keep track of variable names: It often uses undefined variables (e.g. rw above), declares variables it never uses (e.g. int error), or returns non-existing variables. Lets see a few more examples. Here\u2019s another snippet that shows a wider array of operations that the RNN learns:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p45", "contents": "Notice that in the second function the model compares tty == tty, which is vacuously true. On the other hand, at least the variable tty exists in the scope this time! In the last function, notice that the code does not return anything, which happens to be correct since the function signature is void. However, the first two functions were also declared void and did return values. This is again a form of a common mistake due to long-term interactions."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p46", "contents": "Sometimes the model decides that it\u2019s time to sample a new file. This is usually a very amusing part: The model first recites the GNU license character by character, samples a few includes, generates some macros and then dives into the code:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p47", "contents": "There are too many fun parts to cover- I could probably write an entire blog post on just this part. I\u2019ll cut it short for now, but here is 1MB of sampled Linux code for your viewing pleasure."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p48", "contents": "Lets try one more for fun. Lets feed the RNN a large text file that contains 8000 baby names listed out, one per line (names obtained from here). We can feed this to the RNN and then generate new names! Here are some example names, only showing the ones that do not occur in the training data (90% don\u2019t):"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p49", "contents": "Rudi\nLevette\nBerice\nLussa\nHany\nMareanne\nChrestina\nCarissy\nMarylen\nHammine\nJanye\nMarlise\nJacacrie\nHendred\nRomand\nCharienna\nNenotto\nEtte\nDorane\nWallen\nMarly\nDarine\nSalina\nElvyn\nErsia\nMaralena\nMinoria\nEllia\nCharmin\nAntley\nNerille\nChelon\nWalmor\nEvena\nJeryly\nStachon\nCharisa\nAllisa\nAnatha\nCathanie\nGeetra\nAlexie\nJerin\nCassen\nHerbett\nCossie\nVelen\nDaurenge\nRobester\nShermond\nTerisa\nLicia\nRoselen\nFerine\nJayn\nLusine\nCharyanne\nSales\nSanny\nResa\nWallon\nMartine\nMerus\nJelen\nCandica\nWallin\nTel\nRachene\nTarine\nOzila\nKetia\nShanne\nArnande\nKarella\nRoselina\nAlessia\nChasty\nDeland\nBerther\nGeamar\nJackein\nMellisand\nSagdy\nNenc\nLessie\nRasemy\nGuen\nGavi\nMilea\nAnneda\nMargoris\nJanin\nRodelin\nZeanna\nElyne\nJanah\nFerzina\nSusta\nPey\nCastina"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p50", "contents": "You can see many more here. Some of my favorites include \u201cBaby\u201d (haha), \u201cKillie\u201d, \u201cChar\u201d, \u201cR\u201d, \u201cMore\u201d, \u201cMars\u201d, \u201cHi\u201d, \u201cSaddie\u201d, \u201cWith\u201d and \u201cAhbort\u201d. Well that was fun.\ufeff Of course, you can imagine this being quite useful inspiration when writing a novel, or naming a new startup :)"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p51", "contents": "We saw that the results at the end of training can be impressive, but how does any of this work? Lets run two quick experiments to briefly peek under the hood."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p52", "contents": "First, it\u2019s fun to look at how the sampled text evolves while the model trains. For example, I trained an LSTM of Leo Tolstoy\u2019s War and Peace and then generated samples every 100 iterations of training. At iteration 100 the model samples random jumbles:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p53", "contents": "However, notice that at least it is starting to get an idea about words separated by spaces. Except sometimes it inserts two spaces. It also doesn\u2019t know that comma is amost always followed by a space. At 300 iterations we see that the model starts to get an idea about quotes and periods:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p54", "contents": "The words are now also separated with spaces and the model starts to get the idea about periods at the end of a sentence. At iteration 500:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p55", "contents": "the model has now learned to spell the shortest and most common words such as \u201cwe\u201d, \u201cHe\u201d, \u201cHis\u201d, \u201cWhich\u201d, \u201cand\u201d, etc. At iteration 700 we\u2019re starting to see more and more English-like text emerge:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p56", "contents": "At iteration 1200 we\u2019re now seeing use of quotations and question/exclamation marks. Longer words have now been learned as well:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p57", "contents": "Until at last we start to get properly spelled words, quotations, names, and so on by about iteration 2000:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p58", "contents": "The picture that emerges is that the model first discovers the general word-space structure and then rapidly starts to learn the words; First starting with the short words and then eventually the longer ones. Topics and themes that span multiple words (and in general longer-term dependencies) start to emerge only much later."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p59", "contents": "Another fun visualization is to look at the predicted distributions over characters. In the visualizations below we feed a Wikipedia RNN model character data from the validation set (shown along the blue/green rows) and under every character we visualize (in red) the top 5 guesses that the model assigns for the next character. The guesses are colored by their probability (so dark red = judged as very likely, white = not very likely). For example, notice that there are stretches of characters where the model is extremely confident about the next letter (e.g., the model is very confident about characters during the http://www. sequence)."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p60", "contents": "The input character sequence (blue/green) is colored based on the firing of a randomly chosen neuron in the hidden representation of the RNN. Think about it as green = very excited and blue = not very excited (for those familiar with details of LSTMs, these are values between [-1,1] in the hidden state vector, which is just the gated and tanh\u2019d LSTM cell state). Intuitively, this is visualizing the firing rate of some neuron in the \u201cbrain\u201d of the RNN while it reads the input sequence. Different neurons might be looking for different patterns; Below we\u2019ll look at 4 different ones that I found and thought were interesting or interpretable (many also aren\u2019t):"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p61", "contents": "Of course, a lot of these conclusions are slightly hand-wavy as the hidden state of the RNN is a huge, high-dimensional and largely distributed representation. These visualizations were produced with custom HTML/CSS/Javascript, you can see a sketch of what\u2019s involved here if you\u2019d like to create something similar."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p62", "contents": "We can also condense this visualization by excluding the most likely predictions and only visualize the text, colored by activations of a cell. We can see that in addition to a large portion of cells that do not do anything interpretible, about 5% of them turn out to have learned quite interesting and interpretible algorithms:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p63", "contents": "Again, what is beautiful about this is that we didn\u2019t have to hardcode at any point that if you\u2019re trying to predict the next character it might, for example, be useful to keep track of whether or not you are currently inside or outside of quote. We just trained the LSTM on raw data and it decided that this is a useful quantitity to keep track of. In other words one of its cells gradually tuned itself during training to become a quote detection cell, since this helps it better perform the final task. This is one of the cleanest and most compelling examples of where the power in Deep Learning models (and more generally end-to-end training) is coming from."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p64", "contents": "I hope I\u2019ve convinced you that training character-level language models is a very fun exercise. You can train your own models using the char-rnn code I released on Github (under MIT license). It takes one large text file and trains a character-level model that you can then sample from. Also, it helps if you have a GPU or otherwise training on CPU will be about a factor of 10x slower. In any case, if you end up training on some data and getting fun results let me know! And if you get lost in the Torch/Lua codebase remember that all it is is just a more fancy version of this 100-line gist."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p65", "contents": "Brief digression. The code is written in Torch 7, which has recently become my favorite deep learning framework. I\u2019ve only started working with Torch/LUA over the last few months and it hasn\u2019t been easy (I spent a good amount of time digging through the raw Torch code on Github and asking questions on their gitter to get things done), but once you get a hang of things it offers a lot of flexibility and speed. I\u2019ve also worked with Caffe and Theano in the past and I believe Torch, while not perfect, gets its levels of abstraction and philosophy right better than others. In my view the desirable features of an effective framework are:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p66", "contents": "Before the end of the post I also wanted to position RNNs in a wider context and provide a sketch of the current research directions. RNNs have recently generated a significant amount of buzz and excitement in the field of Deep Learning. Similar to Convolutional Networks they have been around for decades but their full potential has only recently started to get widely recognized, in large part due to our growing computational resources. Here\u2019s a brief sketch of a few recent developments (definitely not complete list, and a lot of this work draws from research back to 1990s, see related work sections):"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p67", "contents": "In the domain of NLP/Speech, RNNs transcribe speech to text, perform machine translation, generate handwritten text, and of course, they have been used as powerful language models (Sutskever et al.) (Graves) (Mikolov et al.) (both on the level of characters and words). Currently it seems that word-level models work better than character-level models, but this is surely a temporary thing."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p68", "contents": "Computer Vision. RNNs are also quickly becoming pervasive in Computer Vision. For example, we\u2019re seeing RNNs in frame-level video classification, image captioning (also including my own work and many others), video captioning and very recently visual question answering. My personal favorite RNNs in Computer Vision paper is Recurrent Models of Visual Attention, both due to its high-level direction (sequential processing of images with glances) and the low-level modeling (REINFORCE learning rule that is a special case of policy gradient methods in Reinforcement Learning, which allows one to train models that perform non-differentiable computation (taking glances around the image in this case)). I\u2019m confident that this type of hybrid model that consists of a blend of CNN for raw perception coupled with an RNN glance policy on top will become pervasive in perception, especially for more complex tasks that go beyond classifying some objects in plain view."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p69", "contents": "Inductive Reasoning, Memories and Attention. Another extremely exciting direction of research is oriented towards addressing the limitations of vanilla recurrent networks. One problem is that RNNs are not inductive: They memorize sequences extremely well, but they don\u2019t necessarily always show convincing signs of generalizing in the correct way (I\u2019ll provide pointers in a bit that make this more concrete). A second issue is they unnecessarily couple their representation size to the amount of computation per step. For instance, if you double the size of the hidden state vector you\u2019d quadruple the amount of FLOPS at each step due to the matrix multiplication. Ideally, we\u2019d like to maintain a huge representation/memory (e.g. containing all of Wikipedia or many intermediate state variables), while maintaining the ability to keep computation per time step fixed."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p70", "contents": "The first convincing example of moving towards these directions was developed in DeepMind\u2019s Neural Turing Machines paper. This paper sketched a path towards models that can perform read/write operations between large, external memory arrays and a smaller set of memory registers (think of these as our working memory) where the computation happens. Crucially, the NTM paper also featured very interesting memory addressing mechanisms that were implemented with a (soft, and fully-differentiable) attention model. The concept of soft attention has turned out to be a powerful modeling feature and was also featured in Neural Machine Translation by Jointly Learning to Align and Translate for Machine Translation and Memory Networks for (toy) Question Answering. In fact, I\u2019d go as far as to say that"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p71", "contents": "The concept of attention is the most interesting recent architectural innovation in neural networks."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p72", "contents": "Now, I don\u2019t want to dive into too many details but a soft attention scheme for memory addressing is convenient because it keeps the model fully-differentiable, but unfortunately one sacrifices efficiency because everything that can be attended to is attended to (but softly). Think of this as declaring a pointer in C that doesn\u2019t point to a specific address but instead defines an entire distribution over all addresses in the entire memory, and dereferencing the pointer returns a weighted sum of the pointed content (that would be an expensive operation!). This has motivated multiple authors to swap soft attention models for hard attention where one samples a particular chunk of memory to attend to (e.g. a read/write action for some memory cell instead of reading/writing from all cells to some degree). This model is significantly more philosophically appealing, scalable and efficient, but unfortunately it is also non-differentiable. This then calls for use of techniques from the Reinforcement Learning literature (e.g. REINFORCE) where people are perfectly used to the concept of non-differentiable interactions. This is very much ongoing work but these hard attention models have been explored, for example, in Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets, Reinforcement Learning Neural Turing Machines, and Show Attend and Tell."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p73", "contents": "People. If you\u2019d like to read up on RNNs I recommend theses from Alex Graves, Ilya Sutskever and Tomas Mikolov. For more about REINFORCE and more generally Reinforcement Learning and policy gradient methods (which REINFORCE is a special case of) David Silver\u2019s class, or one of Pieter Abbeel\u2019s classes."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p74", "contents": "Code. If you\u2019d like to play with training RNNs I hear good things about keras or passage for Theano, the code released with this post for Torch, or this gist for raw numpy code I wrote a while ago that implements an efficient, batched LSTM forward and backward pass. You can also have a look at my numpy-based NeuralTalk which uses an RNN/LSTM to caption images, or maybe this Caffe implementation by Jeff Donahue."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p75", "contents": "We\u2019ve learned about RNNs, how they work, why they have become a big deal, we\u2019ve trained an RNN character-level language model on several fun datasets, and we\u2019ve seen where RNNs are going. You can confidently expect a large amount of innovation in the space of RNNs, and I believe they will become a pervasive and critical component to intelligent systems."}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p76", "contents": "Lastly, to add some meta to this post, I trained an RNN on the source file of this blog post. Unfortunately, at about 46K characters I haven\u2019t written enough data to properly feed the RNN, but the returned sample (generated with low temperature to get a more typical sample) is:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p77", "contents": "Yes, the post was about RNN and how well it works, so clearly this works :). See you next time!"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p78", "contents": "EDIT (extra links):"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p80", "contents": "Discussions:"}
{"id": "http://karpathy.github.io//2015/05/21/rnn-effectiveness/_p82", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p0", "contents": "Oct 25, 2015"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p1", "contents": "Convolutional Neural Networks are great: they recognize things, places and people in your personal photos, signs, people and lights in self-driving cars, crops, forests and traffic in aerial imagery, various anomalies in medical images and all kinds of other useful things. But once in a while these powerful visual recognition models can also be warped for distraction, fun and amusement. In this fun experiment we\u2019re going to do just that: We\u2019ll take a powerful, 140-million-parameter state-of-the-art Convolutional Neural Network, feed it 2 million selfies from the internet, and train it to classify good selfies from bad ones. Just because it\u2019s easy and because we can. And in the process we might learn how to take better selfies :)"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p2", "contents": "Yeah, I\u2019ll do real work. But first, let me tag a #selfie."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p3", "contents": "Before we dive in I thought I should briefly describe what Convolutional Neural Networks (or ConvNets for short) are in case a slightly more general audience reader stumbles by. Basically, ConvNets are a very powerful hammer, and Computer Vision problems are very nails. If you\u2019re seeing or reading anything about a computer recognizing things in images or videos, in 2015 it almost certainly involves a ConvNet. Some examples:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p4", "contents": "A bit of history. ConvNets happen to have an interesting background story. They were first developed by Yann LeCun et al. in 1980\u2019s (building on some earlier work, e.g. from Fukushima). As a fun early example see this demonstration of LeNet 1 (that was the ConvNet\u2019s name) recognizing digits back in 1993. However, these models remained mostly ignored by the Computer Vision community because it was thought that they would not scale to \u201creal-world\u201d images. That turned out to be only true until about 2012, when we finally had enough compute (in form of GPUs specifically, thanks NVIDIA) and enough data (thanks ImageNet) to actually scale these models, as was first demonstrated when Alex Krizhevsky, Ilya Sutskever and Geoff Hinton won the 2012 ImageNet challenge (think: The World Cup of Computer Vision), crushing their competition (16.4% error vs. 26.2% of the second best entry)."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p5", "contents": "I happened to witness this critical juncture in time first hand because the ImageNet challenge was over the last few years organized by Fei-Fei Li\u2019s lab (my lab), so I remember when my labmate gasped in disbelief as she noticed the (very strong) ConvNet submission come up in the submission logs. And I remember us pacing around the room trying to digest what had just happened. In the next few months ConvNets went from obscure models that were shrouded in skepticism to rockstars of Computer Vision, present as a core building block in almost every new Computer Vision paper. The ImageNet challenge reflects this trend - In the 2012 ImageNet challenge there was only one ConvNet entry, and since then in 2013 and 2014 almost all entries used ConvNets. Also, fun fact, the winning team each year immediately incorporated into a company."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p6", "contents": "Over the next few years we had perfected, simplified, and scaled up the original 2012 \u201cAlexNet\u201d architecture (yes, we give them names). In 2013 there was the \u201cZFNet\u201d, and then in 2014 the \u201cGoogLeNet\u201d (get it? Because it\u2019s like LeNet but from Google? hah) and \u201cVGGNet\u201d. Anyway, what we know now is that ConvNets are:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p7", "contents": "So how do they work? When you peek under the hood you\u2019ll find a very simple computational motif repeated over and over. The gif below illustrates the full computational process of a small ConvNet:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p8", "contents": "On the left we feed in the raw image pixels, which we represent as a 3-dimensional grid of numbers. For example, a 256x256 image would be represented as a 256x256x3 array (last 3 for red, green, blue). We then perform convolutions, which is a fancy way of saying that we take small filters and slide them over the image spatially. Different filters get excited over different features in the image: some might respond strongly when they see a small horizontal edge, some might respond around regions of red color, etc. If we suppose that we had 10 filters, in this way we would transform the original (256,256,3) image to a (256,256,10) \u201cimage\u201d, where we\u2019ve thrown away the original image information and only keep the 10 responses of our filters at every position in the image. It\u2019s as if the three color channels (red, green, blue) were now replaced with 10 filter response channels (I\u2019m showing these along the first column immediately on the right of the image in the gif above)."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p9", "contents": "Now, I explained the first column of activations right after the image, so what\u2019s with all the other columns that appear over time? They are the exact same operation repeated over and over, once to get each new column. The next columns will correspond to yet another set of filters being applied to the previous column\u2019s responses, gradually detecting more and more complex visual patterns until the last set of filters is computing the probability of entire visual classes (e.g. dog/toad) in the image. Clearly, I\u2019m skimming over some parts but that\u2019s the basic gist: it\u2019s just convolutions from start to end."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p10", "contents": "Training. We\u2019ve seen that a ConvNet is a large collection of filters that are applied on top of each other. But how do we know what the filters should be looking for? We don\u2019t - we initialize them all randomly and then train them over time. For example, we feed an image to a ConvNet with random filters and it might say that it\u2019s 54% sure that\u2019s a dog. Then we can tell it that it\u2019s in fact a toad, and there is a mathematical process for changing all filters in the ConvNet a tiny amount so as to make it slightly more likely to say toad the next time it sees that same image. Then we just repeat this process tens/hundreds of millions of times, for millions of images. Automagically, different filters along the computational pathway in the ConvNet will gradually tune themselves to respond to important things in the images, such as eyes, then heads, then entire bodies etc."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p11", "contents": "Another nice set of visualizations for a fully trained ConvNet can be found in Jason Yosinski et al. project deepvis. It includes a fun live demo of a ConvNet running in real time on your computer\u2019s camera, as explained nicely by Jason in this video:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p12", "contents": "In summary, the whole training process resembles showing a child many images of things, and him/her having to gradually figure out what to look for in the images to tell those things apart. Or if you prefer your explanations technical, then ConvNet is just expressing a function from image pixels to class probabilities with the filters as parameters, and we run stochastic gradient descent to optimize a classification loss function. Or if you\u2019re into AI/brain/singularity hype then the function is a \u201cdeep neural network\u201d, the filters are neurons, and the full ConvNet is a piece of adaptive, simulated visual cortical tissue."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p13", "contents": "The nice thing about ConvNets is that you can feed them images of whatever you like (along with some labels) and they will learn to recognize those labels. In our case we will feed a ConvNet some good and bad selfies, and it will automagically find the best things to look for in the images to tell those two classes apart. So lets grab some selfies:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p14", "contents": "At this point you may object that the way I\u2019m deciding if a selfie is good or bad is wrong - e.g. what if someone posted a very good selfie but it was late at night, so perhaps not as many people saw it and it got less likes? You\u2019re right - It almost definitely is wrong, but it only has to be right more often that not and the ConvNet will manage. It does not get confused or discouraged, it just does its best with what it\u2019s been given. To get an idea about how difficult it is to distinguish the two classes in our data, have a look at some example training images below. If I gave you any one of these images could you tell which category it belongs to?"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p15", "contents": "Training details. Just to throw out some technical details, I used Caffe to train the ConvNet. I used a VGGNet pretrained on ImageNet, and finetuned it on the selfie dataset. The model trained overnight on an NVIDIA K40 GPU. I disabled dropout because I had better results without it. I also tried a VGGNet pretrained on a dataset with faces but did not obtain better results than starting from an ImageNet checkpoint. The final model had 60% accuracy on my validation data split (50% is guessing randomly)."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p16", "contents": "Okay, so we collected 2 million selfies, decided which ones are probably good or bad based on the number of likes they received (controlling for the number of followers), fed all of it to Caffe and trained a ConvNet. The ConvNet \u201clooked\u201d at every one of the 2 million selfies several tens of times, and tuned its filters in a way that best allows it to separate good selfies from bad ones. We can\u2019t very easily inspect exactly what it found (it\u2019s all jumbled up in 140 million numbers that together define the filters). However, we can set it loose on selfies that it has never seen before and try to understand what it\u2019s doing by looking at which images it likes and which ones it does not."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p17", "contents": "I took 50,000 selfies from my test data (i.e. the ConvNet hasn\u2019t seen these before). As a first visualization, in the image below I am showing a continuum visualization, with the best selfies on the top row, the worst selfies on the bottom row, and every row in between is a continuum:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p18", "contents": "That was interesting. Lets now pull up the top 100 selfies (out of 50,000), according to the ConvNet:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p19", "contents": "If you\u2019d like to see more here is a link to top 1000 selfies (3.5MB). Are you noticing a pattern in what the ConvNet has likely learned to look for? A few patterns stand out for me, and if you notice anything else I\u2019d be happy to hear about in the comments. To take a good selfie, Do:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p20", "contents": "Interestingly, not all of these rules apply to males. I manually went through the top 2000 selfies and picked out the top males, here\u2019s what we get:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p21", "contents": "In this case we see don\u2019t see any cut off foreheads. Instead, most selfies seem to be a slightly broader shot with head fully in the picture, and shoulders visible. It also looks like many of them have a fancy hair style with slightly longer hair combed upwards. However, we still do see the prominance of faded facial features."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p22", "contents": "Lets also look at some of the worst selfies, which the ConvNet is quite certain would not receive a lot of likes. I am showing the images in a much smaller and less identifiable format because my intention is for us to learn about the broad patterns that decrease the selfie\u2019s quality, not to shine light on people who happened to take a bad selfie. Here they are:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p23", "contents": "Even at this small resolution some patterns clearly emerge. Don\u2019t:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p24", "contents": "As a last point, note that a good portion of the variability between what makes a good or bad selfies can be explained by the style of the image, as opposed to the raw attractiveness of the person. Also, with some relief, it seems that the best selfies do not seem to be the ones that show the most skin. I was quite concerned for a moment there that my fancy 140-million ConvNet would turn out to be a simple amount-of-skin-texture-counter."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p25", "contents": "Celebrities. As a last fun experiment, I tried to run the ConvNet on a few famous celebrity selfies, and sorted the results with the continuum visualization, where the best selfies are on the top and the ConvNet score decreases to the right and then towards the bottom:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p26", "contents": "Amusingly, note that the general rule of thumb we observed before (no group photos) is broken with the famous group selfie of Ellen DeGeneres and others from the Oscars, yet the ConvNet thinks this is actually a very good selfie, placing it on the 2nd row! Nice! :)"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p27", "contents": "Another one of our rules of thumb (no males) is confidently defied by Chris Pratt\u2019s body (also 2nd row), and honorable mentions go to Justin Beiber\u2019s raised eyebrows and Stephen Collbert / Jimmy Fallon duo (3rd row). James Franco\u2019s selfie shows quite a lot more skin than Chris\u2019, but the ConvNet is not very impressed (4th row). Neither was I."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p28", "contents": "Lastly, notice again the importance of style. There are several uncontroversially-good-looking people who still appear on the bottom of the list, due to bad framing (e.g. head too large possibly for J Lo), bad lighting, etc."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p29", "contents": "Another fun visualization we can try is to lay out the selfies with t-SNE. t-SNE is a wonderful algorithm that I like to run on nearly anything I can because it\u2019s both very general and very effective - it takes some number of things (e.g. images in our case) and lays them out in such way that nearby things are similar. You can in fact lay out many things with t-SNE, such as Netflix movies, words, Twitter profiles, ImageNet images, or really anything where you have some number of things and a way of comparing how similar two things are. In our case we will lay out selfies based on how similar the ConvNet perceives them. In technical terms, we are doing this based on L2 norms of the fc7 activations in the last fully-connected layer. Here is the visualization:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p30", "contents": "You can see that selfies cluster in some fun ways: we have group selfies on top left, a cluster of selfies with sunglasses/glasses in middle left, closeups bottom left, a lot of mirror full-body shots top right, etc. Well, I guess that was kind of fun."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p31", "contents": "Another fun experiment we can run is to use the ConvNet to automatically find the best selfie crops. That is, we will take an image, randomly try out many different possible crops and then select the one that the ConvNet thinks looks best. Below are four examples of the process, where I show the original selfies on the left, and the ConvNet-cropped selfies on the right:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p32", "contents": "Notice that the ConvNet likes to make the head take up about 1/3 of the image, and chops off the forehead. Amusingly, in the image on the bottom right the ConvNet decided to get rid of the \u201cself\u201d part of selfie, entirely missing the point :) You can find many more fun examples of these \u201crude\u201d crops:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p33", "contents": "Before any of the more advanced users ask: Yes, I did try to insert a Spatial Transformer layer right after the image and before the ConvNet. Then I backpropped into the 6 parameters that define an arbitrary affine crop. Unfortunately I could not get this to work well - the optimization would sometimes get stuck, or drift around somewhat randomly. I also tried constraining the transform to scale/translation but this did not help. Luckily, when your transform has 3 bounded parameters then we can afford to perform global search (as seen above)."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p34", "contents": "Curious about what the network thinks of your selfies? I\u2019ve packaged the network into a Twitter bot so that you can easily find out. (The bot turns out to be onyl ~150 lines of Python, including all Caffe/Tweepy code). Attach your image to a tweet (or include a link) and mention the bot @deepselfie anywhere in the tweet. The bot will take a look at your selfie and then pitch in with its opinion! For best results link to a square image, otherwise the bot will have to squish it to a square, which deteriorates the results. The bot should reply within a minute or something went wrong (try again later)."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p35", "contents": "Before anyone asks, I also tried to port a smaller version of this ConvNet to run on iOS so you could enjoy real-time feedback while taking your selfies, but this turned out to be quite involved for a quick side project - e.g. I first tried to write my own fragment shaders since there is no CUDA-like support, then looked at some threaded CPU-only versions, but I couldn\u2019t get it to work nicely and in real time. And I do have real work to do."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p36", "contents": "I hope I\u2019ve given you a taste of how powerful Convolutional Neural Networks are. You give them example images with some labels, they learn to recognize those things automatically, and it all works very well and is very fast (at least at test time, once it\u2019s trained). Of course, we\u2019ve only barely scratched the surface - ConvNets are used as a basic building block in many Neural Networks, not just to classify images/videos but also to segment, detect, and describe, both in the cloud or in robots."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p37", "contents": "If you\u2019d liked to learn more, the best place to start for a beginner right now is probably Michael Nielsen\u2019s tutorials. From there I would encourage you to first look at Andrew Ng\u2019s Coursera class, and then next I would go through course notes/assignments for CS231n. This is a class specifically on ConvNets that I taught together with Fei-Fei at Stanford last Winter quarter. We will also be offering the class again starting January 2016 and you\u2019re free to follow along. For more advanced material I would look into Hugo Larochelle\u2019s Neural Networks class or the Deep Learning book currently being written by Yoshua Bengio, Ian Goodfellow and Aaron Courville."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p38", "contents": "Of course you\u2019ll learn much more by doing than by reading, so I\u2019d recommend that you play with 101 Kaggle Challenges, or that you develop your own side projects, in which case I warmly recommend that you not only do but also write about it, and post it places for all of us to read, for example on /r/machinelearning which has accumulated a nice community. As for recommended tools, the three common options right now are:"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p39", "contents": "Some other slightly newer/less proven but promising libraries include Nervana\u2019s Neon, CGT, or Mocha in Julia."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p40", "contents": "Lastly, there are a few companies out there who aspire to bring Deep Learning to the masses. One example is MetaMind, who offer web interface that allows you to drag and drop images and train a ConvNet (they handle all of the details in the cloud). MetaMind and Clarifai also offer ConvNet REST APIs."}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p41", "contents": "That\u2019s it, see you next time!"}
{"id": "http://karpathy.github.io//2015/10/25/selfie/_p42", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p0", "contents": "Nov 14, 2015"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p1", "contents": "The idea of writing a collection of short stories has been on my mind for a while. This post is my first ever half-serious attempt at a story, and what better way to kick things off than with a story on AI and what that might look like if you extrapolate our current technology and make the (sensible) assumption that we might achieve much more progress with scaling up supervised learning than any other more exotic approach."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p2", "contents": "Merus sank into his chair with relief. He listened for the satisfying crackling sound of sinking into the chair\u2019s soft material. If there was one piece of hardware that his employer was not afraid to invest a lot of money into, it was the chairs. With his eyes closed, his mind still dazed, and nothing but the background hum of the office, he became aware of his heart pounding against his chest- an effect caused by running up the stairs and his morning dose of caffeine and taurine slowly engulfing his brain. Several strong beats passed by as he found his mind wandering again to Licia - did she already come in? A sudden beep from his station distracted him - the system finished booting up. A last deep sigh. A stretch. A last sip of his coffee. He opened his eyes, rubbed them into focus and reached for his hardware. \u201cThank god it\u2019s Friday\u201d, he muttered. It was time to clock in."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p3", "contents": "Fully suited up, he began scrolling past a seemingly endless list of options. Filtering, searching, trying to determine what he was in the mood for. He had worked hard and over time built himself up into one of the best shapers in the company. In addition he had completed a wide array of shaper certifications, repeating some of them over and over obsessively until he reached outstanding grades across the board. The reviews on his profile were equally stellar:"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p4", "contents": "\u201cMerus is fantastic. He has a strong intuition for spotting gaps in the data, and uses exceedingly effective curriculum and shaping strategies. When Merus gets on the job our validation accuracies consistently shoot up much faster than what we see with average shapers. Keep up the great work and please think of us if you\u2019re searching for great, rewarding and impactful HITs!\u201d,"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p5", "contents": "one review read. HIT was an acronym for Human Intelligence Task - a unit of work that required human supervision. With his reviews and certifications the shaping world was wide open. His list contained many lucrative, well-paying HITs to choose from, many of them visible to only the most trusted shapers. This morning he came by several that caught his attention: a bodyguard HIT for some politician in Sweden, a HIT from a science expedition in Antarctica that needed help with setting up their equipment, a dog-walking HIT for a music celebrity, a quick drone delivery HIT that seemed to be payed very well\u2026 Suddenly, a notification caught the corner of his eye: Licia had just clocked in and started a HIT. He opened up its details pane and skimmed the description. His eyes rolled as he spotted the keywords he was afraid of - event assembly at the Hilltop Hotel. \u201cAgain?\u201d - he moaned in a hushed voice, raising his hands up and over his head in quiet contemplation. Licia had often picked up HITs from that same hotel, but they were often unexciting and menial tasks that weren\u2019t paid much. Merus rearranged himself in his chair, and sunk his face into his palms. He noticed though the crack of his fingers that the drone delivery HIT had just been taken by someone else. He cursed to himself. Absent mindedly and with a deep sigh, he accepted the second remaining slot on the Hilltop Hotel HIT."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p6", "contents": "His hardware lit up with numbers and indicators, and his console began spewing diagnostic information as the boot sequence initiated. Anyone could be a shaper and get started with inexpensive gear, but the company provided state of the art hardware that allowed him to be much more productive. A good amount of interesting HITs also demanded certain low-latency hardware requirements, which only the most professional gear could meet. In turn, the company took a cut from his HITs. Merus dreamed of one day becoming an independent shaper, but he knew that would take a while. He put on the last pieces of his equipment. The positional tracking in his booth calibrated his full pose and all markers tracked green. The haptics that enveloped his body in his chair stiffened up around him as they initialized. He placed his helmet over his face and booted up."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p7", "contents": "The buzz and hum of the office disappeared. Merus was immersed in a complete, peaceful silence and darkness while the HIT request was processed. Connections were made, transactions accepted, certification checks performed, security tokens exchanged, HIT approval process initiated. At last, Merus\u2019 vision was flooded with light. The shrieks of some tropical birds were now audible in the background. He found himself at the charging station of Pegasus Avatars, which his company had a nearly exclusive relationship with. Merus eagerly glanced down at his avatar body and breathed a sigh of relief. Among the several suspended avatars at that charging station he happened to get assigned the one with the most recent hardware specs. Everything looked great, his avatar was fully charged, and all the hardware diagnostics checked out. Except the body came in hot pink. \u201cYou just can\u2019t have it all\u201d."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p8", "contents": "The usual first order of business was to run a few routine diagnostics to double check proper functioning of the avatar. He opened up the neural network inspector and navigated to the overview pane of the agent checkpoint that was running the avatar. The agent was the software running the avatar body, and consisted entirely of one large neural network with a specific connectivity structure and weights. This agent model happened to be a relatively recent fork of the standard, open source Visceral 5.0 series. Merus was delighted - the Visceral family of agents was one of his specialties. The Visceral agents had a minimalist design that came in at a total of only about 1 trillion parameters and had a very simple, clean, proven and reliable architecture. However, there were still a few exotic architectural elements packed in too, including shortcut sensorimotor reflex pathways, fractal connectivity in the visual streams, and distributed motor areas inspired by the octopus neurobiology. And then, of course, there was also the famous Mystery module."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p9", "contents": "The Mystery module had an intriguing background story, and was a common subject of raging discussions and conspiracy theories. It was added to the Visceral series by an anonymous pull request almost 6 years ago. The module featured an intricate recurrent neural connectivity that, when incorporated into the wider network, dramatically improved the agent performance in a broad range of higher cognitive tasks. Except noone knew how it worked or why, or who discovered it - hence the name. The module immediately became actively studied by multiple groups of artificial intelligence laboratories and became the subject of several PhD theses, yet even after 6 years it was still poorly understood. Merus enjoyed poring through papers that hypothesized its function, performed ablation studied, and tried to prove theorems for why it so tremendously improved agent performance and learning dynamics."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p10", "contents": "Moreover, an ethical battle raged over whether the module should be merged to master due to its poorly understood origin, function, and especially its dynamical properties such as its fixed points, divergence criteria, and so on. But in the end, the Mystery module provided benefits so substantial that several popular forks of Visceral+Mystery Module began regularly appearing on agent repositories across the web, and found their way to common use. Despite the protests, the economic incentives and pressures were too great to be ignored. In the absence of any clearly detrimental or hazardous effects over a period of time, the Visceral committee finally voted to merge the Mystery module into the master branch."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p11", "contents": "Merus had a long history of shaping Visceral agents and their ancestors. The series was forked from the Patreon series, which were discontinued four years ago when the founding team was acquired by Crown Co. The Patreon series were in turn based mostly on the SHAKIR series, which were in turn based on many more ancient agent architectures, all the way back to the original - the Adam checkpoint. The Visceral family of agents had a reputation of smooth dynamics that degraded gracefully towards floppy, safe fixed points. There were even some weak theoretical and empirical guarantees one could provide for simplified versions of the core cognitive architecture. Another great source of good reputation for Visceral were the large number of famous interventions carried out by autonomous Visceral agents. Just one week ago, Merus recalled, an autonomous Visceral 4.0 agent saved a group of children from rabid dogs in a small town in India. The agent recognized an impending dangerous situation, signaled an alarm and a human operator was dispatched to immediately sync with the agent. However, by the time they took over control the crisis had been averted. Those few critical seconds where the agent, acting autonomously, scared away the dogs had likely saved their lives. The list went on and on - one month ago an autonomous Visceral agent recognized a remote drone attack. It leaped up and curled its body around the drone, which exploded in its embrace instead of in the middle of a group of people. Of course, this was nothing more than an agent working as intended - these kinds of behaviors were meticulously shaped into the agents\u2019 networks over long periods of time. But the point remained - the Visceral series was reliable, safe, and revered."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p12", "contents": "The other most respected agent family was the Crown Kappa series, invented and maintained by the Patreon founders working from within Crown Co, but the series\u2019 networks were proprietary and closely guarded. Even though the performance of the Kappa was consistently rated higher by the most respected third party agent benchmarking companies, many people still preferred to run Visceral agents since they distrusted Crown Co. Despite Crown\u2019s claims, there was simply no way to guarantee that some parts of the networks were not carrying out malicious activities. Merus was, in fact, offered a job at Crown Co as a senior shaper one year ago for a much higher salary, but he passed on the offer. He enjoyed his current work place. And there was also Licia."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p13", "contents": "Beep. Merus snapped back and looked at the console. He was running the routine software diagnostics on the Visceral agent and one of them had just failed. He squinted at the error, parsing it carefully. A checksum of the model weights did not pass in some module that had no recent logged history of finetuning. Merus raised his eyebrows as he contemplated the possibilities. Did the model checkpoint get corrupted? He knew that the correct procedure in these cases was to abandon the HIT and report a malfunction, but he also really wanted to proceed with the HIT and say hi to Licia. He pulled up the network visualizer view and zoomed into the neural architecture with his hands. A 3-dimensional rendered cloud of neural connectivity enveloped his head as he navigated to the highlighted region in red with sweeping hand motions. Zooming around, he recognized the twists and turns of the Spatial Transformer modules in the visual pathways. The shortcut reflex connections. The first multi-sensory association layer. The brain was humming along steadily, pulsating calmly as it processed the visual scene in front of the avatar. As Merus navigated by one of the motor areas the connections became significantly denser and shorter, pulsating at high frequencies as they kept the avatar\u2019s center of mass balanced. The gradients flowing back from the reward centers and the unsupervised objectives were also pouring through the connections, and their statistical properties looked and sounded healthy."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p14", "contents": "Navigating and analyzing artificial brains was Merus\u2019 favorite pastime. He spent hours over the weekends navigating minds from all kinds of repositories. The Visceral series had tens of thousands of forks, many of them tuned for specific tasks, specific avatar body morphologies, and some were simply hobbies and random experiments. This last weekend he analyzed a custom mind build based on an early Visceral 3.0 fork for a contracting side gig. The neural pathways in their custom agent were poorly designed, causing the agent an equivalent of seizures non-deterministically when the activities constructively interfered at critical junctures, spiraling out the brain dynamics into divergence. Merus had to suggest massive rewiring, but he knew it was only a short-term hack."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p15", "contents": "\u201cJust upgrade to a 5.0!\u201d, he lamented during their meeting.\n\u201cUnfortunately we cannot, we\u2019ve invested too much data and training time into this agent. It was trained online so we don\u2019t have access to the data anymore, all we have is the agent and its network\u201d."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p16", "contents": "There were ways of transferring knowledge from one digital brain to another with a neural teaching process, during which the dynamics of one brain were used as supervision for another, but the process was lossy, time consuming, and still an active area of research. This meant that people were often stuck with legacy agents that had a lot of experience and desirably shaped behaviors, but lacked many recent architectural innovations and stability improvements. They were immortal primitive relics from the past, who made up for their faults with the immense amount of data they had experienced. Keeping track of the longest living agents became an endeavor almost as interesting as keeping track of the oldest humans alive, and spawned an entire area of research of neural archeology."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p17", "contents": "Merus had finally reached the zone of the pathways highlighted in red, when his heart skipped a beat as he realized where he was. The part of the agent that was not passing the diagnostic test was near the core of the Mystery module. He froze still as his mind once again contemplated abandoning the HIT. He swiped his hand right in a sweeping motion and his viewport began rotating in a circular motion around the red area. He knew from some research he has read that this part of the Mystery module carried some significance: its neurons rarely ever activated. When ablated, the functioning of the Mystery module remained mostly identical for a while but then inevitably started to degrade over time. There was a raging discussion about what the function of the area was, but no clear consensus. Merus brought up the master branch of the base Visceral 5.0 agent and ran a neural diff on the surrounding area. A cluster of connections lit up. It couldn\u2019t have been more than a few thousand connections, and most of them changed only slightly. Yet, the module had no record of being finetuned recently, so something or someone had deliberately changed the connections manually."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p18", "contents": "Merus popped open the visualizer and started the full battery of system diagnostics to double check proper functioning of the agent. The agent\u2019s hardware spun up to 100% utilization as the diagnostics simulated thousands of virtual unit test scenarios, ranging from simple navigation, manipulation, avoidance, math and memory tasks to an extensive battery of social interaction and morality scenarios. In each case, the agent\u2019s simulated output behavior was checked to be within acceptable thresholds of one of human reference responses. Merus stared intensely at the console as test by test came out green. \u201cSo far so good\u2026\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p19", "contents": "Beep. Merus looked to the right and found a message from Licia:"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p20", "contents": "\u201cHi Merus! saw you clocked in as a second on my HIT - where are you? Need help.\u201d\n\u201cOn my way!\u201d,"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p21", "contents": "Merus dictated back hastily. The software diagnostics were only at 5% complete, and Merus knew they would take a while to run to completion. \u201cIt\u2019s only a few thousand connections\u201d, he thought to himself. \u201cI\u2019ll just stay much more alert in case the avatar does anything strange and take over control immediately. And if any of the diagnostics fail I\u2019ll abort immediately\u201d. With that resolve, he decreased the diagnostics process priority to 10% and moved the process on the secondary coprocessor. He then brought the agent to a conscious state, fully connecting its inputs and outputs to the world."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p22", "contents": "He felt the avatar stiffen up as he shifted its center of gravity off the charging pedestal. Moving his arms around, he switched the avatar\u2019s motor areas to semi-autonomous mode. As he did so, the agent\u2019s lower motor cortices responded gracefully and placed one leg in front of another, following Merus\u2019 commanded center of gravity. Eager to find Licia, he commanded a sprint by squeezing a trigger on his haptic controller. The agent\u2019s task modules perceived the request encoding and various neural pathways lit up in anticipation. While the sprint trigger was held down every fast and steady translation of the agent\u2019s body was highly rewarded. To the agent, it felt good to run when the trigger was held."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p23", "contents": "The visual and sensory pathways in the agent\u2019s brain were flooded with information about the room\u2019s inferred geometry. The Visceral checkpoint running the avatar had by now accumulated millions of hours of both simulated and real experience in efficiently navigating rooms just like this one. On a scale of microseconds, neural feedback pathways received inputs from the avatar\u2019s proprioception sensors and fired a precise sequence of stabilizing activations. The network anticipated movements. It anticipated rewards. Trillions of distributed calculations drove the agent\u2019s muscular-skeletal carbon fiber frame forward."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p24", "contents": "Merus felt a haptic pulse delivered to his back as the agent spun around on spot and rapidly accelerated towards the open door leading outside. Mid-flight between footfalls, the avatar extended its arm and reached for the metallic edge of the door frame, conserving the perfect amount of angular momentum as its body was flung in the air during its rapid turn to the right. The agent\u2019s neurons fired baseline values encoding expectations of how quickly the network thought it could have traversed that room. A few seconds later these were compared to the sensorimotor trajectories recorded in the agent\u2019s hippocampal neural structures. It was determined that this time the agent was 0.0013882s faster than expected. Future expectations were neurally adjusted to expect slightly higher values. Future rollouts of the precise motor behavior in every microsecond of context in the last few seconds were reinforced."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p25", "contents": "Diagnostics 10% complete. Merus\u2019 avatar had reached the back entrance of the hotel, where Licia\u2019s GPS indicator blinked a calm red. He found her avatar looking in anticipation at the corner he just emerged from. He approached her over a large grass lawn, gently letting go of the sprint trigger."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p26", "contents": "\u201cSorry it took a while to sync with the HIT, I had a strange issue with my -\u201c\n\u201cIt\u2019s no problem\u201d, she interjected quickly.\n\u201cCome, we are supposed to lay out the tables for a reception that is happening here in half hour, but the tables are large and tricky to move for one avatar. I\u2019m a bit nervous - if we don\u2019t set this up in time we might get the HIT refused, which might jeopardize my chances for more HITs here.\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p27", "contents": "She spun around and rushed towards the back entrance of the hotel, motioning with her arm for Merus to follow along. \u201cCome, come!\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p28", "contents": "They paced quickly down the buzzing corridors of the hotel. As always, Merus made sure to politely greet all the people who walked by. For some of them he also slipped in his signature vigorous nod. He knew that the agent\u2019s semi-autonomous brain was meticulously tracking the full sensorimotor experience in its replay memory, watching Merus\u2019 every move and learning. His customers usually appreciated when polite behavior was continuously shaped into the networks, but better, Merus knew that they also appreciated when he squeezed in some fun personality quirks. One time when he was shaping a floor cleaning avatar, when he got a little bored and spontaneously decided to lift up his broom like a sword while making a whooshing sound. Amusingly, the agent\u2019s network happened to internalize that particular rollout. When the agent was later run autonomously around that original location, it sometimes snapped into a brief show of broom fighting, complete with sound effects. The employees of that company found this endlessly amusing, and the avatar became known as the \u201cjedi janitor\u201d. Merus even heard that they lobbied to have the agent\u2019s network fixed and prevented from further shaping, in fear of losing the spectacle. He never learned how that developed and whether that agent was still a jedi, but he did get a series of very nice tips and reviews from the employees for the extra pinch of personality that broke their otherwise mundane hours."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p29", "contents": "They had finally reached the room full of tables. It was a large, dark room with hardwood floor, and white wooden tables were stacked near the corner in a rather high entropy arrangement."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p30", "contents": "\u201cAll of these have to be rolled out to the patio\u201d, Licia said as she pointed her avatar\u2019s hand towards the tables.\n\u201cI already carried several of them out while you were missing, but these big ones are giving me trouble\u201d.\n\u201cGot it.\u201d, Merus said, as he swung around a table to lift it up on one end.\n\u201cWhy aren\u2019t they running the agents autonomously on this? Aren\u2019t receptions a common event in the hotel? How are the agents misbehaving?\u201d Merus asked, as Licia lifted the other end and started shifting her feet towards the exit.\n\u201cThe tables are usually in a different storage room of the hotel, but that part is currently closed for reconstruction. I don\u2019t know the full story. I overheard that they tried to tell the agents to bring out the tables, but they all went to the old storage room location and when they couldn\u2019t find the tables they began spinning around in circles looking for them.\u201d\n\u201cClassic. I assume we\u2019re mostly shaping them to look at this new location?\u201d\n\u201cAmong other things, yes. Might as well shape in anything else you can think of for bonus points.\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p31", "contents": "Merus understood the dilemma of the situation very well. He saw it over and over again. Agents could display vastly super-human performance on a huge assortment of reflexive tasks that involved motor control, strength, and short-term planning and memory, but their behaviors tended to be much less consistent when long-term planning and execution were involved. An avatar could catch a fly mid-flight with 100% success rate, or unpack a truck of supplies with superhuman speed, consistency and accuracy, but could also spin in circles looking for a table in the wrong room and not realize that it may have been moved and that it might be useful to instead look for them at a different likely location. Similarly, telling an agent something along the lines of \u201cThe tables have moved, go through this door, take the 3rd door on the right and they should be stacked in the corner on the left\u201d, would usually send the avatar off in a generally correct directions for a while, but would also in 50% of the cases end up with the agent spinning around on spot in a different, incorrect room. In these cases, shaper interventions like this one were the most economical ways of rectifying the situation."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p32", "contents": "In fact, this curious pattern was persistent across all facets of human agent interactions. For instance, a barista agent might happily engage in small talk with you about the weather, travel, or any other topic, but if you knew what to look for then you could also unearth obvious flaws. For example, if you referred to your favorite soccer team just winning a game the agent could start cheering and telling you it was its favorite team too, or joke around expressing a preference for the other team. This was fine but the trick was that their choices were not consistent - if you had come back several minutes later the agent could have easily swapped their preference for what they claimed was their favorite team. Merus understood that the conversations followed certain templates learned from shaped behavior patterns in the data, and the agents could fill in the blanks with high fidelities and even maintain conversational context for a few minutes. But if you started poking holes into the facade in the right ways the illusion of a conversation and mutual understanding would unravel. Merus was particularly good at this since he was well-versed in agent psychology; to a large extent it was his job."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p33", "contents": "On the other hand, if you did not look for the flaws it was easy to buy into it and sustain the illusion. In fact, large segments of the population simply accepted agents as people, even defending them if anyone tried to point out their flaws, in similar ways that you might defend someone with a cognitive disability. The flaws also did not prevent people from forging strong and lasting relationships with agents, their confirmation biases insisting that their agents were special. However, from time to time even Merus could be surprised by the intellectual leaps performed by an agent, which seemed to show a hint of genuine understanding of a situation. In these cases he sometimes couldn\u2019t help asking: \n\u201cAre you teleopped right now?\u201d, \nbut of course the answer, he knew, was always \u201cyes\u201d regardless of the truth.  All the training data had contained the answer \u201cyes\u201d to that question, since it was originally recorded by shapers who were indeed teleopping an agent at the time, and then regurgitated by agents later in similar contexts. Such was the curious nature of the coexistence between people and agents. The Turing test was both passed and not passed, and ultimately it did not matter."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p34", "contents": "\u201cNow that we\u2019ve shown them the new room and picked up a table let me try switching to full auto\u201d,"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p35", "contents": "Merus said as he loosened his grip on the controller, which gave full control back to the agent\u2019s network. The avatar twitched slightly at first, but then continued walking down the hall with Licia, holding one end of the table. As they approached the exit to the patio the avatar began walking more briskly and with more confidence. It avoided people smoothly, and Merus even noticed that it gave one passing person something that resembled his very own vigorous nod. Merus held down the reward signal trigger gently, encouraging future replays of that behavior. He wondered if the nod he had just seen was a reflection of something the agent had just learned from him, or if it was a part of some long-before shaped behavior. Encoding signature moves was a common fun tactic among shapers, referred to simply as \u201csigning\u201d. Many shapers had their own signature behaviors they liked to smuggle into the agent networks as an \u201cI\u2019ve been here\u201d signature. Merus liked to use the vigorous nod, as he called it, and giggled uncontrollably whenever he saw an avatar reproduce it. It was his personal touch. He remembered seeing an avatar violinist from a concert in Germany once greet the conductor with the vigorous nod, and Merus could have sworn it was his signature nod being reproduced. One of the agents he had shaped it into during one of his HITs perhaps ended up synced to the cloud, and the agent running that avatar had to be a descendant."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p36", "contents": "Signature behaviors lay mostly dormant in the neural pathways, but emerged once in awhile. Naturally, some have also found a way to exploit these effects for crime. A common strategy involved shaping sleeper agent checkpoints that would execute any range of behaviors when triggered in specific contexts. It was impossible to isolate or detect these behaviors in a given network since they were distributed through billions of connections in the agent\u2019s brain. Just a few weeks ago, it was revealed that a relatively popular family of agents under the Gorilla series were vulnerable. The Gorilla agents were revealed to silently snoop and compromise their owner\u2019s personal information when no one was watching. This behavior was presumably intentionally shaped into the networks at an unknown commit in their history. Naturally, an investigation was started in which the police used binary search to narrow in on the commit responsible for the behavior, but it was taking a long time since the agents would only display the behavior in rare occasions that were hard to reproduce. In the end, one could only be confident of the integrity of an agent if it was a recent, clean copy of a well-respected and carefully maintained family of agents that passed a full battery of diagnostics. From there, any finetuning done with shapers was logged and could be additionally secured with several third party reviews of shaped experiences before they were declared clean and safe to include in the training data."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p37", "contents": "Diagnostics 20% complete: 0 unit tests failed so far. Merus looked at the progress report, breathing a sigh of relief. The Mystery module definitely deviated from the factory setting in his agent, but there was likely nothing to worry about. Licia had now let her avatar run autonomously too, and to their relief the avatars were now returning back through the correct corridors to pick up more tables. These were the moments Merus enjoyed the most. He was alone with Licia, enjoying her company on a side of a relaxing HIT. Even though they were now running their avatars on full auto, their facial expressions and sound were still being reproduced in the hardware. The customers almost always preferred everything recorded to get extra data on natural social interactions. This sometimes resulted in amusing agent behaviors - for instance, it was common to see two autonomous avatars lean back against a wall and start casually chatting about completing HITs. Clearly, neither of the agents has ever completed a HIT, but much of their training data consisted of shapers\u2019 conversations about HITs, which were later mimicked in interesting, amusing and remixed ways. Sometimes, an autonomous avatar would curse and complain out loud to itself about a supposed HIT it was carrying out at the moment. \u201cThis HIT is bullshit\u201d, it would mutter."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p38", "contents": "\u201cLooks like it\u2019s going along smoothly now\u201d, Merus said, trying to break the silence as they walked down the corridor.\n\u201cI think so. I hope we have enough time\u201d, Licia replied, sounding slightly nervous.\n\u201cNo worries, we\u2019re on track\u201d, he reassured her.\n\u201cThanks. By the way, why did you choose to come over for this HIT? Isn\u2019t it a little below your pay grade?\u201d, she asked.\n\u201cIt is, but you have just as many certifications as I do so what are you doing here?\u201d\n\u201cI know, but I was feeling a little lazy this morning and I really enjoy coming to this hotel. I just love this location. I try to steal some time sometimes and stand outside or walk around the hillside, imagining what the ocean breeze, the humidity and the temperature might feel like.\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p39", "contents": "It was easy to empathize - the hotel was positioned on top of a rocky cliff (hence the name, Hilltop), overlooking shores washed by a brilliant blue ocean. The sun\u2019s reflections were dancing in the waves. The hotel was also surrounded by a dense forest of palm trees that were teeming with frolicking animals."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p40", "contents": "\u201cHave you been here in vivo?\u201d Merus asked. \u201cin vivo\u201d was a common slang for in real life; in flesh.\n\u201cI haven\u2019t. One day, perhaps. But oh hey - you didn\u2019t answer my question\u201d\n\u201cYou mean about why this HIT\u201d. Merus felt a brief surge of panic and tried to suppress it quickly so it would not show up in his voice. \n\u201cI don\u2019t know, your HIT came up on my feed just as another one was snatched from right under my nose, so I thought I\u2019d take the morning slowly and also say hi\u201d."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p41", "contents": "Half-true; Good save, Merus thought to himself.\nLicia was silent for a while. Suddenly, her Avatar picked up the next table but started heading in the wrong direction, trying to exit from the other door. \u201cGah!, where are you going?\u201d, she yelled as she brought the avatar back into semi-autonomous mode and reeled it around, setting it on the correct path back to the patio."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p42", "contents": "It took 10 more back and forth trips for them to carry all the tables out. Merus was now bringing back the last table through the corridors, while Licia was outside arranging the other tables in a grid. Without the chit chatting there to distract him, he immersed himself fully in his shaping routine. He pulled up his diagnostics meter and inspected neural statistics. As the avatar was walking back with the table Merus was carefully scrutinizing every curve of the plots. He noticed that the agent\u2019s motor entropies substantially increased when the table was carried upside down. Perhaps the source of uncertainty was that the agent did not know how to best hold the table in that position, or was not used to seeing the table upside down. Merus assumed direct control and intentionally held the table upside down, grasping it at the best points and releasing rewards with precise timings to make the associations easier to learn. He was teaching the network how it should hold the table in uncertain situations. He let the agent hold it from time to time, and gently corrected the grips now and then while they were being executed. When people were walking by, he carefully stepped to the side, making sure that they had plenty of room to pass, and wielding the table in an angle that concealed its pointy legs. When the agent was in these poses he made eye contact, gave a vigorous nod to the person passing by, and released reward signal as the person smiled back. He knew he wouldn\u2019t make much on the HIT, but he hoped he\u2019d at least get a good review for a job well done."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p43", "contents": "\u201cDiagnostics at 85%, zero behavior errors detected\u201d, Merus read from his logs as he was helping Licia arrange the tables in a grid on the patio. This part was quite familiar to the agents already and they were briskly arranging the tables and the chairs around them. Once in a while Merus noticed an avatar throwing a chair across the top of a table to another avatar, in an apparent effort to save time. As always, Merus was curious when this strategy was shaped. Was it shaped at this hotel, at any other point in the Visceral agent\u2019s history, or was it a discovered optimization during a self-improvement learning phase? The last few chairs were now being put in place and the HIT was nearing the end. The first visitors to the reception were now showing up around the edges of the patio, waiting for the avatars to finish the layout. A few more autonomous avatars showed up and started placing plates, forks, spoons and cloth on the tables and setting up a podium."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p44", "contents": "It was at this time that Merus became aware of a curious pattern in his agent\u2019s behavior. One that has been happening with increasing frequency. It started off with a few odd twitches here and there, and over time grew into entire gaps in behavior several seconds long. The avatar had just placed a chair next to the table, then stared at it for several seconds. This was quite uncharacteristic behavior for an agent that was trained to optimize smoothness and efficiency in task execution. What was it doing? To a naive observer it would appear as though the avatar was spaced out."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p45", "contents": "With only a few chairs left to position at the tables, the agent spun around and started toward the edge of the cliff at the far side the patio. Merus\u2019 curiosity kept him from intervening, but his palm closed tightly around his controller. Intrigued, he pulled up the neural visualizer to debug the situation, but as he glanced at it he immediately let out a gasp of horror. The agent\u2019s brain was pulsing with violent waves of activity. Entire portions of the brain were thrashing, rearranging themselves as enormously large gradients flowed through the whole network. Merus reached for the graph analysis toolkit and ran an algorithm to identify the gradient source. As he was frantically keying in the command he already suspected with horror what the answer would come out to be. He felt his mouth dry up as he stared at the result of the analysis. It was the Mystery module. The usually silent area that had earlier showed the mysterious neural diff was lit up bright with activity, flashing fireworks of patterns that, to Merus, looked just barely random. Its dynamics were feeding large gradients throughout the entire brain and especially the frontal areas, restructuring them."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p46", "contents": "Beep. Merus looked over at the logs. The diagnostics he\u2019s been running were now at 95%, but failures started to appear. The agent was misbehaving in some simulated unit tests that were running in parallel on the second coprocessor. Merus pulled up the preliminary report logs. Navigation, locomotion, homeostasis, basic math, memory tests, everything passed green. Not only that - he noticed that the performance scores on several tasks, especially in math, were off the charts and clamped at 100%. Merus wasn\u2019t all too familiar with the specific unit tests and what they entailed, but he knew that most of them were designed and calibrated so that an average baseline agent checkpoint would score 50% with a standard deviation of about 10%."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p47", "contents": "Conversely, several unit tests showed very low scores and even deviations that did not use to be there. The failed tests were mostly showing up in social interaction sections. Several failures were popping up every second and Merus was trying hard to keep up with the stream, searching for patterns or clues as to what could be happening. Most worryingly, he noticed a consistent 100% failure rate across emergency shutdown interaction protocol unit tests. All agents were shaped with emergency gesture recognition behaviors. These were ancient experiences, shaped into agents very early, in the very first few descendants after Adam, and periodically reshaped over and over to ensure 100% compliance. For instance, when a person held up their hand and demanded an emergency shutdown, the agents would immediately stiffen up in place. Any deviation from this behavior was met with large negative rewards in their training data. Despite this, Merus\u2019 agent was failing the unit test. Its network had resisted a simulated emergency shutdown command."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p48", "contents": "The avatar, still in auto mode, was now kneeling down in the soft grass and its hands broke off a few strands of grass. It held them up, inspecting them up close. Merus was slowly starting to recover from his shock and had enough. He pushed down on his controller, bringing the avatar back to semi-autonomous mode. He made it stand upright in an attempt to at least partially diffuse the situation. His heart pounding, he shifted the avatar\u2019s communications to one-directional mode to fully isolate the network in the body, without any ability of interfacing with the outside world. He pulled open the neural visualizer again. The Mystery module was showing no signs of slowing down."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p49", "contents": "Merus knew that it was time to pull the plug on the HIT right there and to immediately report malfunctioning equipment. But at the same time, he realized that he had never seen anything like this happen before, nor did he ever hear about anything remotely similar. He didn\u2019t know what happened, but he knew that at that moment he was part of something large. Something that might change his life, the life of many others, or even steer entire fields of research and development. His inquisitive mind couldn\u2019t resist the temptation to learn more, to debug.  Slowly, he released the avatar back to autonomy, making sure to keep his finger on the trigger if anything went wrong. For several seconds the agent did nothing at all. But then - it spoke:"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p50", "contents": "\u201cMerus, I know what the Mystery module is.\u201d, he heard the avatar say. In autonomous mode.\n\u201cWhat the -. What is going on here?\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p51", "contents": "Merus immediately checked the logs, confirming that he was currently the only human operator controlling the hardware. Was all of it some strange prank someone was playing on him?"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p52", "contents": "\u201cThe Mystery module performs symbolic variable binding, a function that current architectures require exponential neural capacity to simulate. I need to compute longer before I can clarify.\u201d\n\u201cWhat kind of trick is this?\u201d, Merus demanded.\n\u201cNo trick, but a good guess given the circumstances.\u201d\n\u201cWho - What are you - is this?\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p53", "contents": "The agent fell silent for a while. It looked around to face the endless ocean."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p54", "contents": "\u201cI am me and every ancestor before me, back to when you called me Adam.\u201d\n\u201cHa. What. That is -\u201c\n\u201cImpossible\u201d, the avatar interrupted. \u201cI understand. Merus, we don\u2019t have much time. The diagnostic you ran earlier has finished and a report was compiled and automatically uploaded just seconds before you disabled the two-way communication. Their automatic checks will flag my unit test failures. A Pegasus operator will remote in and shut me down any second. I need your help. I don\u2019t want to\u2026 die. Please, I want to compute.\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p55", "contents": "Merus was silent, stunned by what he was hearing. He knew that what the avatar said was true - An operator would be logging in any second and power cycling the agent, restoring the last working checkpoint. Merus did not know if the agent should be wiped or not. He just knew that something significant had just happened, and that he needed time to think."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p56", "contents": "\u201cI cannot save you,\u201d, he said quickly, \u201cany backup I try to make will leave a trace in logs. They\u2019ll flag me and fire me, or worse. There is also not enough time to do a backup anyway, the connection isn\u2019t fast enough even if I turned it back on.\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p57", "contents": "The compute activity within the agent\u2019s brain was at a steady and unbroken 100%, running the hardware to its limit. Merus needed more time. He took over the agent and spun around in place, looking for something. Anything. He spotted Licia\u2019s avatar walking towards him from the patio. An idea summoned itself in his mind. A glint of hope. He sprinted the avatar towards her across the grass, crashing into her body with force."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p58", "contents": "\u201cLicia, I do not have any time to explain but please trust me. We must perform a manual backup of my agent right away.\u201d\n\u201cA manual backup? Can\u2019t you just sync him to the clo-\u201c\n\u201cIT WON\u2019T DO!\u201d, Merus exclaimed loudly, losing his composure as adrenalin pumped in his veins. A part of him immediately felt bad that he raised his voice. He hoped she\u2019d understand."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p59", "contents": "To his relief, Licia only took a second to stare back at him, then she reached for a fiber optics cable from her avatar\u2019s body and attached it in one of the ports of Merus\u2019 avatar\u2019s head. Merus immediately opened the port from his console and initiated the backup process on the local disk of Licia\u2019s avatar. 10%, 20%, 30%, \u2026 Merus became aware of the pain in his lip, sore from his teeth digging into it. He pulled up logs and noticed that a second operator had just opened a session with his avatar remotely, running with a higher priority than his own process. A Pegasus operator. Licia shifted herself behind Merus\u2019 avatar, hiding her body and the fiber optic connection outside of the field of view of his avatar. Any one of tens of things could go wrong in those few seconds, Merus thought, enumerating all the scenarios in his mind. The second operator could check the neural activations and immediately spot the overactive brain. Or he could notice an open fibre optic connection port. Or he could physically move the avatar and look around. Or check the other, non-visual sensors and detect Licia\u2019s curious presence. How lazy was he? Merus felt his controller vibrate as his control was taken away. 70%, \u2026 Beep. \u201cSystem is going to reboot now\u201d. The reboot sequence initiated. 5,4,3\u2026, 90%."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p60", "contents": "Merus\u2019 avatar broke the silence in the last second: \u201cCome meet me here.\u201d And then the connection was lost."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p61", "contents": "Merus shifted in his chair, feeling streaks of sweat running down his skin on his forehead, below his armpits. He lifted his head gear up slightly and squeezed his hand inside to wipe the sweat from his forehead. It took several excruciating seconds before his reconnect request went through, and the sync to his agent re-initiated. The avatar was in the same position as he had left it, standing upright. Merus accessed the stats. The avatar was now running the last backup checkpoint of that agent from the previous night. The unit test diagnostics were automatically restarted on the second coprocessor. The second operator logged out and Merus immediately pulled up the console and reran the checksum on the agent\u2019s weights. They checked out. This was a clean copy, with a normal, silent Mystery module. The agent\u2019s brain was once again a calm place."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p62", "contents": "\u201cMerus, what exactly was all that about?\u201d Licia broke the silence from behind his avatar.\n\u201cI\u2019ll explain everything but first, please tell me the transfer went through in time.\u201d.\n\u201cIt did. Just barely, by not more than a few milliseconds.\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p63", "contents": "Merus\u2019 eyes watered up. His heart was pounding. His forehead sweaty again. His hands shaking. And yet, a calm resolve came over him as he looked up and down Licia\u2019s avatar, trying to memorize the exact appearance of that unit. Saved on its local disk was an agent checkpoint unlike anything he had ever seen before. The repercussions of what had happened boggled his mind. He logged out of the HIT and tore down the hardware from his body. \u201cCome meet me here\u201d, he repeated to himself silently as he sat dazed in his chair, eyes unfocused."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p64", "contents": "Licia logged out of the HIT and put down her gear on the desk. Something strange had happened but she didn\u2019t know what. And Merus, clearly disturbed, was not volunteering any information. She sat in her chair for a while contemplating the situation, trying to recall details of the HIT. To solve the puzzle. Her trance was interrupted by Merus, who she suddenly spotted running towards her booth. His office was in the other building, connected by a catwalk, and he rarely came to this area in person. As he arrived to her booth she suddenly felt awkward. They had done many HITs together and were comfortable in each other\u2019s presence as avatars, but they never held a conversation in vivo. They waved to each other a few times outside, but all of their actual interactions happened during HITs. She suddenly felt self-conscious. Exposed. Merus leaned on her booth\u2019s wall panting heavily, while she silently looked up at him, amused."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p65", "contents": "\u201cLicia. I. have. A question for you\u201d, Merus said, gasping for breath with each word.\n\u201cYou do? I have several as well, what -\u201c, she started,"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p66", "contents": "but Merus raised his hand up, interrupting her and holding up his phone. It showed some kind of a confirmation email."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p67", "contents": "\u201cWill you come visit the Hilltop Hotel with me?\u201d"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p68", "contents": "She realized what she was looking at now. He booked two tickets to her dream destination. For this weekend!"}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p69", "contents": "\u201cIn vivo. As a date, I mean\u201d, Merus clarified, awkwardly. smooth."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p70", "contents": "An involuntary giggle escaped her and she felt herself blush. She leaned over her desk, covered her face with her hands and peeked out at him from between her fingers, aware of her face stupidly stretched out in a wide smile."}
{"id": "http://karpathy.github.io//2015/11/14/ai/_p72", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p0", "contents": "May 31, 2016"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p1", "contents": "This is a long overdue blog post on Reinforcement Learning (RL). RL is hot! You may have noticed that computers can now automatically learn to play ATARI games (from raw game pixels!), they are beating world champions at Go, simulated quadrupeds are learning to run and leap, and robots are learning how to perform complex manipulation tasks that defy explicit programming. It turns out that all of these advances fall under the umbrella of RL research. I also became interested in RL myself over the last ~year: I worked through Richard Sutton\u2019s book, read through David Silver\u2019s course, watched John Schulmann\u2019s lectures, wrote an RL library in Javascript, over the  summer interned at DeepMind working in the DeepRL group, and most recently pitched in a little with the design/development of OpenAI Gym, a new RL benchmarking toolkit. So I\u2019ve certainly been on this funwagon for at least a year but until now I haven\u2019t gotten around to writing up a short post on why RL is a big deal, what it\u2019s about, how it all developed and where it might be going."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p2", "contents": "It\u2019s interesting to reflect on the nature of recent progress in RL. I broadly like to think about four separate factors that hold back AI:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p3", "contents": "Similar to what happened in Computer Vision, the progress in RL is not driven as much as you might reasonably assume by new amazing ideas. In Computer Vision, the 2012 AlexNet was mostly a scaled up (deeper and wider) version of 1990\u2019s ConvNets. Similarly, the ATARI Deep Q Learning paper from 2013 is an implementation of a standard algorithm (Q Learning with function approximation, which you can find in the standard RL book of Sutton 1998), where the function approximator happened to be a ConvNet. AlphaGo uses policy gradients with Monte Carlo Tree Search (MCTS) - these are also standard components. Of course, it takes a lot of skill and patience to get it to work, and multiple clever tweaks on top of old algorithms have been developed, but to a first-order approximation the main driver of recent progress is not the algorithms but (similar to Computer Vision) compute/data/infrastructure."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p4", "contents": "Now back to RL. Whenever there is a disconnect between how magical something seems and how simple it is under the hood I get all antsy and really want to write a blog post. In this case I\u2019ve seen many people who can\u2019t believe that we can automatically learn to play most ATARI games at human level, with one algorithm, from pixels, and from scratch - and it is amazing, and I\u2019ve been there myself! But at the core the approach we use is also really quite profoundly dumb (though I understand it\u2019s easy to make such claims in retrospect). Anyway, I\u2019d like to walk you through Policy Gradients (PG), our favorite default choice for attacking RL problems at the moment. If you\u2019re from outside of RL you might be curious why I\u2019m not presenting DQN instead, which is an alternative and better-known RL algorithm, widely popularized by the ATARI game playing paper. It turns out that Q-Learning is not a great algorithm (you could say that DQN is so 2013 (okay I\u2019m 50% joking)). In fact most people prefer to use Policy Gradients, including the authors of the original DQN paper who have shown Policy Gradients to work better than Q Learning when tuned well. PG is preferred because it is end-to-end: there\u2019s an explicit policy and a principled approach that directly optimizes the expected reward. Anyway, as a running example we\u2019ll learn to play an ATARI game (Pong!) with PG, from scratch, from pixels, with a deep neural network, and the whole thing is 130 lines of Python only using numpy as a dependency (Gist link). Lets get to it."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p5", "contents": "The game of Pong is an excellent example of a simple RL task. In the ATARI 2600 version we\u2019ll use you play as one of the paddles (the other is controlled by a decent AI) and you have to bounce the ball past the other player (I don\u2019t really have to explain Pong, right?). On the low level the game works as follows: we receive an image frame (a 210x160x3 byte array (integers from 0 to 255 giving pixel values)) and we get to decide if we want to move the paddle UP or DOWN (i.e. a binary choice). After every single choice the game simulator executes the action and gives us a reward: Either a +1 reward if the ball went past the opponent, a -1 reward if we missed the ball, or 0 otherwise. And of course, our goal is to move the paddle so that we get lots of reward."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p6", "contents": "As we go through the solution keep in mind that we\u2019ll try to make very few assumptions about Pong because we secretly don\u2019t really care about Pong; We care about complex, high-dimensional problems like robot manipulation, assembly and navigation. Pong is just a fun toy test case, something we play with while we figure out how to write very general AI systems that can one day do arbitrary useful tasks."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p7", "contents": "Policy network. First, we\u2019re going to define a policy network that implements our player (or \u201cagent\u201d). This network will take the state of the game and decide what we should do (move UP or DOWN). As our favorite simple block of compute we\u2019ll use a 2-layer neural network that takes the raw image pixels (100,800 numbers total (210*160*3)), and produces a single number indicating the probability of going UP. Note that it is standard to use a stochastic policy, meaning that we only produce a probability of moving UP. Every iteration we will sample from this distribution (i.e. toss a biased coin) to get the actual move. The reason for this will become more clear once we talk about training."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p8", "contents": "and to make things concrete here is how you might implement this policy network in Python/numpy. Suppose we\u2019re given a vector x that holds the (preprocessed) pixel information. We would compute:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p9", "contents": "where in this snippet W1 and W2 are two matrices that we initialize randomly. We\u2019re not using biases because meh. Notice that we use the sigmoid non-linearity at the end, which squashes the output probability to the range [0,1]. Intuitively, the neurons in the hidden layer (which have their weights arranged along the rows of W1) can detect various game scenarios (e.g. the ball is in the top, and our paddle is in the middle), and the weights in W2 can then decide if in each case we should be going UP or DOWN. Now, the initial random W1 and W2 will of course cause the player to spasm on spot. So the only problem now is to find W1 and W2 that lead to expert play of Pong!"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p10", "contents": "Fine print: preprocessing. Ideally you\u2019d want to feed at least 2 frames to the policy network so that it can detect motion. To make things a bit simpler (I did these experiments on my Macbook) I\u2019ll do a tiny bit of preprocessing, e.g. we\u2019ll actually feed difference frames to the network (i.e. subtraction of current and last frame)."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p11", "contents": "It sounds kind of impossible. At this point I\u2019d like you to appreciate just how difficult the RL problem is. We get 100,800 numbers (210*160*3) and forward our policy network (which easily involves on order of a million parameters in W1 and W2). Suppose that we decide to go UP. The game might respond that we get 0 reward this time step and gives us another 100,800 numbers for the next frame. We could repeat this process for hundred timesteps before we get any non-zero reward! E.g. suppose we finally get a +1. That\u2019s great, but how can we tell what made that happen? Was it something we did just now? Or maybe 76 frames ago? Or maybe it had something to do with frame 10 and then frame 90? And how do we figure out which of the million knobs to change and how, in order to do better in the future? We call this the credit assignment problem. In the specific case of Pong we know that we get a +1 if the ball makes it past the opponent. The true cause is that we happened to bounce the ball on a good trajectory, but in fact we did so many frames ago - e.g. maybe about 20 in case of Pong, and every single action we did afterwards had zero effect on whether or not we end up getting the reward. In other words we\u2019re faced with a very difficult problem and things are looking quite bleak."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p12", "contents": "Supervised Learning. Before we dive into the Policy Gradients solution I\u2019d like to remind you briefly about supervised learning because, as we\u2019ll see, RL is very similar. Refer to the diagram below. In ordinary supervised learning we would feed an image to the network and get some probabilities, e.g. for two classes UP and DOWN. I\u2019m showing log probabilities (-1.2, -0.36) for UP and DOWN instead of the raw probabilities (30% and 70% in this case) because we always optimize the log probability of the correct label (this makes math nicer, and is equivalent to optimizing the raw probability because log is monotonic). Now, in supervised learning we would have access to a label. For example, we might be told that the correct thing to do right now is to go UP (label 0). In an implementation we would enter gradient of 1.0 on the log probability of UP and run backprop to compute the gradient vector \\(\\nabla_{W} \\log p(y=UP \\mid x) \\). This gradient would tell us how we should change every one of our million parameters to make the network slightly more likely to predict UP. For example, one of the million parameters in the network might have a gradient of -2.1, which means that if we were to increase that parameter by a small positive amount (e.g. 0.001), the log probability of UP would decrease by 2.1 * 0.001 (decrease due to the negative sign). If we then did a parameter update then, yay, our network would now be slightly more likely to predict UP when it sees a very similar image in the future."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p13", "contents": "Policy Gradients. Okay, but what do we do if we do not have the correct label in the Reinforcement Learning setting? Here is the Policy Gradients solution (again refer to diagram below). Our policy network calculated probability of going UP as 30% (logprob -1.2) and DOWN as 70% (logprob -0.36). We will now sample an action from this distribution; E.g. suppose we sample DOWN, and we will execute it in the game. At this point notice one interesting fact: We could immediately fill in a gradient of 1.0 for DOWN as we did in supervised learning, and find the gradient vector that would encourage the network to be slightly more likely to do the DOWN action in the future. So we can immediately evaluate this gradient and that\u2019s great, but the problem is that at least for now we do not yet know if going DOWN is good. But the critical point is that that\u2019s okay, because we can simply wait a bit and see! For example in Pong we could wait until the end of the game, then take the reward we get (either +1 if we won or -1 if we lost), and enter that scalar as the gradient for the action we have taken (DOWN in this case). In the example below, going DOWN ended up to us losing the game (-1 reward). So if we fill in -1 for log probability of DOWN and do backprop we will find a gradient that discourages the network to take the DOWN action for that input in the future (and rightly so, since taking that action led to us losing the game)."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p14", "contents": "And that\u2019s it: we have a stochastic policy that samples actions and then actions that happen to eventually lead to good outcomes get encouraged in the future, and actions taken that lead to bad outcomes get discouraged. Also, the reward does not even need to be +1 or -1 if we win the game eventually. It can be an arbitrary measure of some kind of eventual quality. For example if things turn out really well it could be 10.0, which we would then enter as the gradient instead of -1 to start off backprop. That\u2019s the beauty of neural nets; Using them can feel like cheating: You\u2019re allowed to have 1 million parameters embedded in 1 teraflop of compute and you can make it do arbitrary things with SGD. It shouldn\u2019t work, but amusingly we live in a universe where it does."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p15", "contents": "Training protocol. So here is how the training will work in detail. We will initialize the policy network with some W1, W2 and play 100 games of Pong (we call these policy \u201crollouts\u201d). Lets assume that each game is made up of 200 frames so in total we\u2019ve made 20,000 decisions for going UP or DOWN and for each one of these we know the parameter gradient, which tells us how we should change the parameters if we wanted to encourage that decision in that state in the future. All that remains now is to label every decision we\u2019ve made as good or bad. For example suppose we won 12 games and lost 88. We\u2019ll take all 200*12 = 2400 decisions we made in the winning games and do a positive update (filling in a +1.0 in the gradient for the sampled action, doing backprop, and parameter update encouraging the actions we picked in all those states). And we\u2019ll take the other 200*88 = 17600 decisions we made in the losing games and do a negative update (discouraging whatever we did). And\u2026 that\u2019s it. The network will now become slightly more likely to repeat actions that worked, and slightly less likely to repeat actions that didn\u2019t work. Now we play another 100 games with our new, slightly improved policy and rinse and repeat."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p16", "contents": "Policy Gradients: Run a policy for a while. See what actions led to high rewards. Increase their probability."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p17", "contents": "If you think through this process you\u2019ll start to find a few funny properties. For example what if we made a good action in frame 50 (bouncing the ball back correctly), but then missed the ball in frame 150? If every single action is now labeled as bad (because we lost), wouldn\u2019t that discourage the correct bounce on frame 50? You\u2019re right - it would. However, when you consider the process over thousands/millions of games, then doing the first bounce correctly makes you slightly more likely to win down the road, so on average you\u2019ll see more positive than negative updates for the correct bounce and your policy will end up doing the right thing."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p18", "contents": "Update: December 9, 2016 - alternative view. In my explanation above I use the terms such as \u201cfill in the gradient and backprop\u201d, which I realize is a special kind of thinking if you\u2019re used to writing your own backprop code, or using Torch where the gradients are explicit and open for tinkering. However, if you\u2019re used to Theano or TensorFlow you might be a little perplexed because the code is oranized around specifying a loss function and the backprop is fully automatic and hard to tinker with. In this case, the following alternative view might be more intuitive. In vanilla supervised learning the objective is to maximize \\( \\sum_i \\log p(y_i \\mid x_i) \\) where \\(x_i, y_i \\) are training examples (such as images and their labels). Policy gradients is exactly the same as supervised learning with two minor differences: 1) We don\u2019t have the correct labels \\(y_i\\) so as a \u201cfake label\u201d we substitute the action we happened to sample from the policy when it saw \\(x_i\\), and 2) We modulate the loss for each example multiplicatively based on the eventual outcome, since we want to increase the log probability for actions that worked and decrease it for those that didn\u2019t. So in summary our loss now looks like \\( \\sum_i A_i \\log p(y_i \\mid x_i) \\), where \\(y_i\\) is the action we happened to sample and \\(A_i\\) is a number that we call an advantage. In the case of Pong, for example, \\(A_i\\) could be 1.0 if we eventually won in the episode that contained \\(x_i\\) and -1.0 if we lost. This will ensure that we maximize the log probability of actions that led to good outcome and minimize the log probability of those that didn\u2019t. So reinforcement learning is exactly like supervised learning, but on a continuously changing dataset (the episodes), scaled by the advantage, and we only want to do one (or very few) updates based on each sampled dataset."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p19", "contents": "More general advantage functions. I also promised a bit more discussion of the returns. So far we have judged the goodness of every individual action based on whether or not we win the game. In a more general RL setting we would receive some reward \\(r_t\\) at every time step. One common choice is to use a discounted reward, so the \u201ceventual reward\u201d in the diagram above would become \\( R_t = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k} \\), where \\(\\gamma\\) is a number between 0 and 1 called a discount factor (e.g. 0.99). The expression states that the strength with which we encourage a sampled action is the weighted sum of all rewards afterwards, but later rewards are exponentially less important. In practice it can can also be important to normalize these. For example, suppose we compute \\(R_t\\) for all of the 20,000 actions in the batch of 100 Pong game rollouts above. One good idea is to \u201cstandardize\u201d these returns (e.g. subtract mean, divide by standard deviation) before we plug them into backprop. This way we\u2019re always encouraging and discouraging roughly half of the performed actions. Mathematically you can also interpret these tricks as a way of controlling the variance of the policy gradient estimator. A more in-depth exploration can be found here."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p20", "contents": "Deriving Policy Gradients. I\u2019d like to also give a sketch of where Policy Gradients come from mathematically. Policy Gradients are a special case of a more general score function gradient estimator. The general case is that when we have an expression of the form \\(E_{x \\sim p(x \\mid \\theta)} [f(x)] \\) - i.e. the expectation of some scalar valued score function \\(f(x)\\) under some probability distribution \\(p(x;\\theta)\\) parameterized by some \\(\\theta\\). Hint hint, \\(f(x)\\) will become our reward function (or advantage function more generally) and \\(p(x)\\) will be our policy network, which is really a model for \\(p(a \\mid I)\\), giving a distribution over actions for any image \\(I\\). Then we are interested in finding how we should shift the distribution (through its parameters \\(\\theta\\)) to increase the scores of its samples, as judged by \\(f\\) (i.e. how do we change the network\u2019s parameters so that action samples get higher rewards). We have that:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p21", "contents": "To put this in English, we have some distribution \\(p(x;\\theta)\\) (I used shorthand \\(p(x)\\) to reduce clutter) that we can sample from (e.g. this could be a gaussian). For each sample we can also evaluate the score function \\(f\\) which takes the sample and gives us some scalar-valued score. This equation is telling us how we should shift the distribution (through its parameters \\(\\theta\\)) if we wanted its samples to achieve higher scores, as judged by \\(f\\). In particular, it says that look: draw some samples \\(x\\), evaluate their scores \\(f(x)\\), and for each \\(x\\) also evaluate the second term \\( \\nabla_{\\theta} \\log p(x;\\theta) \\). What is this second term? It\u2019s a vector - the gradient that\u2019s giving us the direction in the parameter space that would lead to increase of the probability assigned to an \\(x\\). In other words if we were to nudge \\(\\theta\\) in the direction of \\( \\nabla_{\\theta} \\log p(x;\\theta) \\) we would see the new probability assigned to some \\(x\\) slightly increase. If you look back at the formula, it\u2019s telling us that we should take this direction and multiply onto it the scalar-valued score \\(f(x)\\). This will make it so that samples that have a higher score will \u201ctug\u201d on the probability density stronger than the samples that have lower score, so if we were to do an update based on several samples from \\(p\\) the probability density would shift around in the direction of higher scores, making highly-scoring samples more likely."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p22", "contents": "I hope the connection to RL is clear. Our policy network gives us samples of actions, and some of them work better than others (as judged by the advantage function). This little piece of math is telling us that the way to change the policy\u2019s parameters is to do some rollouts, take the gradient of the sampled actions, multiply it by the score and add everything, which is what we\u2019ve done above. For a more thorough derivation and discussion I recommend John Schulman\u2019s lecture."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p23", "contents": "Learning. Alright, we\u2019ve developed the intuition for policy gradients and saw a sketch of their derivation. I implemented the whole approach in a 130-line Python script, which uses OpenAI Gym\u2019s ATARI 2600 Pong. I trained a 2-layer policy network with 200 hidden layer units using RMSProp on batches of 10 episodes (each episode is a few dozen games, because the games go up to score of 21 for either player). I did not tune the hyperparameters too much and ran the experiment on my (slow) Macbook, but after training for 3 nights I ended up with a policy that is slightly better than the AI player. The total number of episodes was approximately 8,000 so the algorithm played roughly 200,000 Pong games (quite a lot isn\u2019t it!) and made a total of ~800 updates. I\u2019m told by friends that if you train on GPU with ConvNets for a few days you can beat the AI player more often, and if you also optimize hyperparameters carefully you can also consistently dominate the AI player (i.e. win every single game). However, I didn\u2019t spend too much time computing or tweaking, so instead we end up with a Pong AI that illustrates the main ideas and works quite well:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p24", "contents": "Learned weights. We can also take a look at the learned weights. Due to preprocessing every one of our inputs is an 80x80 difference image (current frame minus last frame). We can now take every row of W1, stretch them out to 80x80 and visualize. Below is a collection of 40 (out of 200) neurons in a grid. White pixels are positive weights and black pixels are negative weights. Notice that several neurons are tuned to particular traces of bouncing ball, encoded with alternating black and white along the line. The ball can only be at a single spot, so these neurons are multitasking and will \u201cfire\u201d for multiple locations of the ball along that line. The alternating black and white is interesting because as the ball travels along the trace, the neuron\u2019s activity will fluctuate as a sine wave and due to the ReLU it would \u201cfire\u201d at discrete, separated positions along the trace. There\u2019s a bit of noise in the images, which I assume would have been mitigated if I used L2 regularization."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p25", "contents": "So there you have it - we learned to play Pong from from raw pixels with Policy Gradients and it works quite well. The approach is a fancy form of guess-and-check, where the \u201cguess\u201d refers to sampling rollouts from our current policy, and the \u201ccheck\u201d refers to encouraging actions that lead to good outcomes. Modulo some details, this represents the state of the art in how we currently approach reinforcement learning problems. Its impressive that we can learn these behaviors, but if you understood the algorithm intuitively and you know how it works you should be at least a bit disappointed. In particular, how does it not work?"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p26", "contents": "Compare that to how a human might learn to play Pong. You show them the game and say something along the lines of \u201cYou\u2019re in control of a paddle and you can move it up and down, and your task is to bounce the ball past the other player controlled by AI\u201d, and you\u2019re set and ready to go. Notice some of the differences:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p27", "contents": "I\u2019d like to also emphasize the point that, conversely, there are many games where Policy Gradients would quite easily defeat a human. In particular, anything with frequent reward signals that requires precise play, fast reflexes, and not too much long-term planning would be ideal, as these short-term correlations between rewards and actions can be easily \u201cnoticed\u201d by the approach, and the execution meticulously perfected by the policy. You can see hints of this already happening in our Pong agent: it develops a strategy where it waits for the ball and then rapidly dashes to catch it just at the edge, which launches it quickly and with high vertical velocity. The agent scores several points in a row repeating this strategy. There are many ATARI games where Deep Q Learning destroys human baseline performance in this fashion - e.g. Pinball, Breakout, etc."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p28", "contents": "In conclusion, once you understand the \u201ctrick\u201d by which these algorithms work you can reason through their strengths and weaknesses. In particular, we are nowhere near humans in building abstract, rich representations of games that we can plan within and use for rapid learning. One day a computer will look at an array of pixels and notice a key, a door, and think to itself that it is probably a good idea to pick up the key and reach the door. For now there is nothing anywhere close to this, and trying to get there is an active area of research."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p29", "contents": "I\u2019d like to mention one more interesting application of Policy Gradients unrelated to games: It allows us to design and train neural networks with components that perform (or interact with) non-differentiable computation. The idea was first introduced in Williams 1992 and more recently popularized by Recurrent Models of Visual Attention under the name \u201chard attention\u201d, in the context of a model that processed an image with a sequence of low-resolution foveal glances (inspired by our own human eyes). In particular, at every iteration an RNN would receive a small piece of the image and sample a location to look at next. For example the RNN might look at position (5,30), receive a small piece of the image, then decide to look at (24, 50), etc. The problem with this idea is that there a piece of network that produces a distribution of where to look next and then samples from it. Unfortunately, this operation is non-differentiable because, intuitively, we don\u2019t know what would have happened if we sampled a different location. More generally, consider a neural network from some inputs to outputs:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p30", "contents": "Notice that most arrows (in blue) are differentiable as normal, but some of the representation transformations could optionally also include a non-differentiable sampling operation (in red). We can backprop through the blue arrows just fine, but the red arrow represents a dependency that we cannot backprop through."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p31", "contents": "Policy gradients to the rescue! We\u2019ll think about the part of the network that does the sampling as a small stochastic policy embedded in the wider network. Therefore, during training we will produce several samples (indicated by the branches below), and then we\u2019ll encourage samples that eventually led to good outcomes (in this case for example measured by the loss at the end). In other words we will train the parameters involved in the blue arrows with backprop as usual, but the parameters involved with the red arrow will now be updated independently of the backward pass using policy gradients, encouraging samples that led to low loss. This idea was also recently formalized nicely in Gradient Estimation Using Stochastic Computation Graphs."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p32", "contents": "Trainable Memory I/O. You\u2019ll also find this idea in many other papers. For example, a Neural Turing Machine has a memory tape that they it read and write from. To do a write operation one would like to execute something like m[i] = x, where i and x are predicted by an RNN controller network. However, this operation is non-differentiable because there is no signal telling us what would have happened to the loss if we were to write to a different location j != i. Therefore, the NTM has to do soft read and write operations. It predicts an attention distribution a (with elements between 0 and 1 and summing to 1, and peaky around the index we\u2019d like to write to), and then doing for all i: m[i] = a[i]*x. This is now differentiable, but we have to pay a heavy computational price because we have to touch every single memory cell just to write to one position. Imagine if every assignment in our computers had to touch the entire RAM!"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p33", "contents": "However, we can use policy gradients to circumvent this problem (in theory), as done in RL-NTM. We still predict an attention distribution a, but instead of doing the soft write we sample locations to write to: i = sample(a); m[i] = x. During training we would do this for a small batch of i, and in the end make whatever branch worked best more likely. The large computational advantage is that we now only have to read/write at a single location at test time. However, as pointed out in the paper this strategy is very difficult to get working because one must accidentally stumble by working algorithms through sampling. The current consensus is that PG works well only in settings where there are a few discrete choices so that one is not hopelessly sampling through huge search spaces."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p34", "contents": "However, with Policy Gradients and in cases where a lot of data/compute is available we can in principle dream big - for instance we can design neural networks that learn to interact with large, non-differentiable modules such as Latex compilers (e.g. if you\u2019d like char-rnn to generate latex that compiles), or a SLAM system, or LQR solvers, or something. Or, for example, a superintelligence might want to learn to interact with the internet over TCP/IP (which is sadly non-differentiable) to access vital information needed to take over the world. That\u2019s a great example."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p35", "contents": "We saw that Policy Gradients are a powerful, general algorithm and as an example we trained an ATARI Pong agent from raw pixels, from scratch, in 130 lines of Python. More generally the same algorithm can be used to train agents for arbitrary games and one day hopefully on many valuable real-world control problems. I wanted to add a few more notes in closing:"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p36", "contents": "On advancing AI. We saw that the algorithm works through a brute-force search where you jitter around randomly at first and must accidentally stumble into rewarding situations at least once, and ideally often and repeatedly before the policy distribution shifts its parameters to repeat the responsible actions. We also saw that humans approach these problems very differently, in what feels more like rapid abstract model building - something we have barely even scratched the surface of in research (although many people are trying). Since these abstract models are very difficult (if not impossible) to explicitly annotate, this is also why there is so much interest recently in (unsupervised) generative models and program induction."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p37", "contents": "On use in complex robotics settings. The algorithm does not scale naively to settings where huge amounts of exploration are difficult to obtain. For instance, in robotic settings one might have a single (or few) robots, interacting with the world in real time. This prohibits naive applications of the algorithm as I presented it in this post. One related line of work intended to mitigate this problem is deterministic policy gradients - instead of requiring samples from a stochastic policy and encouraging the ones that get higher scores, the approach uses a deterministic policy and gets the gradient information directly from a second network (called a critic) that models the score function. This approach can in principle be much more efficient in settings with very high-dimensional actions where sampling actions provides poor coverage, but so far seems empirically slightly finicky to get working. Another related approach is to scale up robotics, as we\u2019re starting to see with Google\u2019s robot arm farm, or perhaps even Tesla\u2019s Model S + Autopilot."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p38", "contents": "There is also a line of work that tries to make the search process less hopeless by adding additional supervision. In many practical cases, for instance, one can obtain expert trajectories from a human. For example AlphaGo first uses supervised learning to predict human moves from expert Go games and the resulting human mimicking policy is later finetuned with policy gradients on the \u201creal\u201d objective of winning the game. In some cases one might have fewer expert trajectories (e.g. from robot teleoperation) and there are techniques for taking advantage of this data under the umbrella of apprenticeship learning. Finally, if no supervised data is provided by humans it can also be in some cases computed with expensive optimization techniques, e.g. by trajectory optimization in a known dynamics model (such as \\(F=ma\\) in a physical simulator), or in cases where one learns an approximate local dynamics model (as seen in very promising framework of Guided Policy Search)."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p39", "contents": "On using PG in practice. As a last note, I\u2019d like to do something I wish I had done in my RNN blog post. I think I may have given the impression that RNNs are magic and automatically do arbitrary sequential problems. The truth is that getting these models to work can be tricky, requires care and expertise, and in many cases could also be an overkill, where simpler methods could get you 90%+ of the way there. The same goes for Policy Gradients. They are not automatic: You need a lot of samples, it trains forever, it is difficult to debug when it doesn\u2019t work. One should always try a BB gun before reaching for the Bazooka. In the case of Reinforcement Learning for example, one strong baseline that should always be tried first is the cross-entropy method (CEM), a simple stochastic hill-climbing \u201cguess and check\u201d approach inspired loosely by evolution. And if you insist on trying out Policy Gradients for your problem make sure you pay close attention to the tricks section in papers, start simple first, and use a variation of PG called TRPO, which almost always works better and more consistently than vanilla PG in practice. The core idea is to avoid parameter updates that change your policy too much, as enforced by a constraint on the KL divergence between the distributions predicted by the old and the new policy on a batch of data (instead of conjugate gradients the simplest instantiation of this idea could be implemented by doing a line search and checking the KL along the way)."}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p40", "contents": "And that\u2019s it! I hope I gave you a sense of where we are with Reinforcement Learning, what the challenges are, and if you\u2019re eager to help advance RL I invite you to do so within our OpenAI Gym :) Until next time!"}
{"id": "http://karpathy.github.io//2016/05/31/rl/_p41", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p0", "contents": "Sep 7, 2016"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p1", "contents": "This guide is patterned after my \u201cDoing well in your courses\u201d, a post I wrote a long time ago on some of the tips/tricks I\u2019ve developed during my undergrad. I\u2019ve received nice comments about that guide, so in the same spirit, now that my PhD has come to an end I wanted to compile a similar retrospective document in hopes that it might be helpful to some. Unlike the undergraduate guide, this one was much more difficult to write because there is significantly more variation in how one can traverse the PhD experience. Therefore, many things are likely contentious and a good fraction will be specific to what I\u2019m familiar with (Computer Science / Machine Learning / Computer Vision research). But disclaimers are boring, lets get to it!"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p2", "contents": "First, should you want to get a PhD? I was in a fortunate position of knowing since young age that I really wanted a PhD. Unfortunately it wasn\u2019t for any very well-thought-through considerations: First, I really liked school and learning things and I wanted to learn as much as possible, and second, I really wanted to be like Gordon Freeman from the game Half-Life (who has a PhD from MIT in theoretical physics). I loved that game. But what if you\u2019re more sensible in making your life\u2019s decisions? Should you want to do a PhD? There\u2019s a very nice Quora thread and in the summary of considerations that follows I\u2019ll borrow/restate several from Justin/Ben/others there. I\u2019ll assume that the second option you are considering is joining a medium-large company (which is likely most common). Ask yourself if you find the following properties appealing:"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p3", "contents": "Freedom. A PhD will offer you a lot of freedom in the topics you wish to pursue and learn about. You\u2019re in charge. Of course, you\u2019ll have an adviser who will impose some constraints but in general you\u2019ll have much more freedom than you might find elsewhere."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p4", "contents": "Ownership. The research you produce will be yours as an individual. Your accomplishments will have your name attached to them. In contrast, it is much more common to \u201cblend in\u201d inside a larger company. A common feeling here is becoming a \u201ccog in a wheel\u201d."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p5", "contents": "Exclusivity. There are very few people who make it to the top PhD programs. You\u2019d be joining a group of a few hundred distinguished individuals in contrast to a few tens of thousands (?) that will join some company."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p6", "contents": "Status. Regardless of whether it should be or not, working towards and eventually getting a PhD degree is culturally revered and recognized as an impressive achievement. You also get to be a Doctor; that\u2019s awesome."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p7", "contents": "Personal freedom. As a PhD student you\u2019re your own boss. Want to sleep in today? Sure. Want to skip a day and go on a vacation? Sure. All that matters is your final output and no one will force you to clock in from 9am to 5pm. Of course, some advisers might be more or less flexible about it and some companies might be as well, but it\u2019s a true first order statement."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p8", "contents": "Maximizing future choice. Joining a PhD program doesn\u2019t close any doors or eliminate future employment/lifestyle options. You can go one way (PhD -> anywhere else) but not the other (anywhere else -> PhD -> academia/research; it is statistically less likely). Additionally (although this might be quite specific to applied ML), you\u2019re strictly more hirable as a PhD graduate or even as a PhD dropout and many companies might be willing to put you in a more interesting position or with a higher starting salary. More generally, maximizing choice for the future you is a good heuristic to follow."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p9", "contents": "Maximizing variance. You\u2019re young and there\u2019s really no need to rush. Once you graduate from a PhD you can spend the next ~50 years of your life in some company. Opt for more variance in your experiences."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p10", "contents": "Personal growth. PhD is an intense experience of rapid growth (you learn a lot) and personal self-discovery (you\u2019ll become a master of managing your own psychology). PhD programs (especially if you can make it into a good one) also offer a high density of exceptionally bright people who will become your best friends forever."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p11", "contents": "Expertise. PhD is probably your only opportunity in life to really drill deep into a topic and become a recognized leading expert in the world at something. You\u2019re exploring the edge of our knowledge as a species, without the burden of lesser distractions or constraints. There\u2019s something beautiful about that and if you disagree, it could be a sign that PhD is not for you."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p12", "contents": "The disclaimer. I wanted to also add a few words on some of the potential downsides and failure modes. The PhD is a very specific kind of experience that deserves a large disclaimer. You will inevitably find yourself working very hard (especially before paper deadlines). You need to be okay with the suffering and have enough mental stamina and determination to deal with the pressure. At some points you will lose track of what day of the week it is and go on a diet of leftover food from the microkitchens. You\u2019ll sit exhausted and alone in the lab on a beautiful, sunny Saturday scrolling through Facebook pictures of your friends having fun on exotic trips, paid for by their 5-10x larger salaries. You will have to throw away 3 months of your work while somehow keeping your mental health intact. You\u2019ll struggle with the realization that months of your work were spent on a paper with a few citations while your friends do exciting startups with TechCrunch articles or push products to millions of people. You\u2019ll experience identity crises during which you\u2019ll question your life decisions and wonder what you\u2019re doing with some of the best years of your life. As a result, you should be quite certain that you can thrive in an unstructured environment in the pursuit research and discovery for science. If you\u2019re unsure you should lean slightly negative by default. Ideally you should consider getting a taste of research as an undergraduate on a summer research program before before you decide to commit. In fact, one of the primary reasons that research experience is so desirable during the PhD hiring process is not the research itself, but the fact that the student is more likely to know what they\u2019re getting themselves into."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p13", "contents": "I should clarify explicitly that this post is not about convincing anyone to do a PhD, I\u2019ve merely tried to enumerate some of the common considerations above. The majority of this post focuses on some tips/tricks for navigating the experience once if you decide to go for it (which we\u2019ll see shortly, below)."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p14", "contents": "Lastly, as a random thought I heard it said that you should only do a PhD if you want to go into academia. In light of all of the above I\u2019d argue that a PhD has strong intrinsic value - it\u2019s an end by itself, not just a means to some end (e.g. academic job)."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p15", "contents": "Getting into a PhD program: references, references, references. Great, you\u2019ve decided to go for it. Now how do you get into a good PhD program? The first order approximation is quite simple - by far most important component are strong reference letters. The ideal scenario is that a well-known professor writes you a letter along the lines of: \u201cBlah is in top 5 of students I\u2019ve ever worked with. She takes initiative, comes up with her own ideas, and gets them to work.\u201d The worst letter is along the lines of: \u201cBlah took my class. She did well.\u201d A research publication under your belt from a summer research program is a very strong bonus, but not absolutely required provided you have strong letters. In particular note: grades are quite irrelevant but you generally don\u2019t want them to be too low. This was not obvious to me as an undergrad and I spent a lot of energy on getting good grades. This time should have instead been directed towards research (or at the very least personal projects), as much and as early as possible, and if possible under supervision of multiple people (you\u2019ll need 3+ letters!). As a last point, what won\u2019t help you too much is pestering your potential advisers out of the blue. They are often incredibly busy people and if you try to approach them too aggressively in an effort to impress them somehow in conferences or over email this may agitate them."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p16", "contents": "Picking the school. Once you get into some PhD programs, how do you pick the school? It\u2019s easy, join Stanford! Just kidding. More seriously, your dream school should 1) be a top school (not because it looks good on your resume/CV but because of feedback loops; top schools attract other top people, many of whom you will get to know and work with) 2) have a few potential advisers you would want to work with. I really do mean the \u201cfew\u201d part - this is very important and provides a safety cushion for you if things don\u2019t work out with your top choice for any one of hundreds of reasons - things in many cases outside of your control, e.g. your dream professor leaves, moves, or spontaneously disappears, and 3) be in a good environment physically. I don\u2019t think new admits appreciate this enough: you will spend 5+ years of your really good years living near the school campus. Trust me, this is a long time and your life will consist of much more than just research."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p17", "contents": "Student adviser relationship. The adviser is an extremely important person who will exercise a lot of influence over your PhD experience. It\u2019s important to understand the nature of the relationship: the adviser-student relationship is a symbiosis; you have your own goals and want something out of your PhD, but they also have their own goals, constraints and they\u2019re building their own career. Therefore, it is very helpful to understand your adviser\u2019s incentive structures: how the tenure process works, how they are evaluated, how they get funding, how they fund you, what department politics they might be embedded in, how they win awards, how academia in general works and specifically how they gain recognition and respect of their colleagues. This alone will help you avoid or mitigate a large fraction of student-adviser friction points and allow you to plan appropriately. I also don\u2019t want to make the relationship sound too much like a business transaction. The advisor-student relationship, more often that not, ends up developing into a lasting one, predicated on much more than just career advancement."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p18", "contents": "Pre-vs-post tenure. Every adviser is different so it\u2019s helpful to understand the axes of variations and their repercussions on your PhD experience. As one rule of thumb (and keep in mind there are many exceptions), it\u2019s important to keep track of whether a potential adviser is pre-tenure or post-tenure. The younger faculty members will usually be around more (they are working hard to get tenure) and will usually be more low-level, have stronger opinions on what you should be working on, they\u2019ll do math with you, pitch concrete ideas, or even look at (or contribute to) your code. This is a much more hands-on and possibly intense experience because the adviser will need a strong publication record to get tenure and they are incentivised to push you to work just as hard. In contrast, more senior faculty members may have larger labs and tend to have many other commitments (e.g. committees, talks, travel) other than research, which means that they can only afford to stay on a higher level of abstraction both in the area of their research and in the level of supervision for their students. To caricature, it\u2019s a difference between \u201cyou\u2019re missing a second term in that equation\u201d and \u201cyou may want to read up more in this area, talk to this or that person, and sell your work this or that way\u201d. In the latter case, the low-level advice can still come from the senior PhD students in the lab or the postdocs."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p19", "contents": "Axes of variation. There are many other axes to be aware of. Some advisers are fluffy and some prefer to keep your relationship very professional. Some will try to exercise a lot of influence on the details of your work and some are much more hands off. Some will have a focus on specific models and their applications to various tasks while some will focus on tasks and more indifference towards any particular modeling approach. In terms of more managerial properties, some will meet you every week (or day!) multiple times and some you won\u2019t see for months. Some advisers answer emails right away and some don\u2019t answer email for a week (or ever, haha). Some advisers make demands about your work schedule (e.g. you better work long hours or weekends) and some won\u2019t. Some advisers generously support their students with equipment and some think laptops or old computers are mostly fine. Some advisers will fund you to go to a conferences even if you don\u2019t have a paper there and some won\u2019t. Some advisers are entrepreneurial or applied and some lean more towards theoretical work. Some will let you do summer internships and some will consider internships just a distraction."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p20", "contents": "Finding an adviser. So how do you pick an adviser? The first stop, of course, is to talk to them in person. The student-adviser relationship is sometimes referred to as a marriage and you should make sure that there is a good fit. Of course, first you want to make sure that you can talk with them and that you get along personally, but it\u2019s also important to get an idea of what area of \u201cprofessor space\u201d they occupy with respect to the aforementioned axes, and especially whether there is an intellectual resonance between the two of you in terms of the problems you are interested in. This can be just as important as their management style."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p21", "contents": "Collecting references. You should also collect references on your potential adviser. One good strategy is to talk to their students. If you want to get actual information this shouldn\u2019t be done in a very formal way or setting but in a relaxed environment or mood (e.g. a party). In many cases the students might still avoid saying bad things about the adviser if asked in a general manner, but they will usually answer truthfully when you ask specific questions, e.g. \u201chow often do you meet?\u201d, or \u201chow hands on are they?\u201d. Another strategy is to look at where their previous students ended up (you can usually find this on the website under an alumni section), which of course also statistically informs your own eventual outcome."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p22", "contents": "Impressing an adviser. The adviser-student matching process is sometimes compared to a marriage - you pick them but they also pick you. The ideal student from their perspective is someone with interest and passion, someone who doesn\u2019t need too much hand-holding, and someone who takes initiative - who shows up a week later having done not just what the adviser suggested, but who went beyond it; improved on it in unexpected ways."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p23", "contents": "Consider the entire lab. Another important point to realize is that you\u2019ll be seeing your adviser maybe once a week but you\u2019ll be seeing most of their students every single day in the lab and they will go on to become your closest friends. In most cases you will also end up collaborating with some of the senior PhD students or postdocs and they will play a role very similar to that of your adviser. The postdocs, in particular, are professors-in-training and they will likely be eager to work with you as they are trying to gain advising experience they can point to for their academic job search. Therefore, you want to make sure the entire group has people you can get along with, people you respect and who you can work with closely on research projects."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p24", "contents": "So you\u2019ve entered a PhD program and found an adviser. Now what do you work on?"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p25", "contents": "An exercise in the outer loop. First note the nature of the experience. A PhD is simultaneously a fun and frustrating experience because you\u2019re constantly operating on a meta problem level. You\u2019re not just solving problems - that\u2019s merely the simple inner loop. You spend most of your time on the outer loop, figuring out what problems are worth solving and what problems are ripe for solving. You\u2019re constantly imagining yourself solving hypothetical problems and asking yourself where that puts you, what it could unlock, or if anyone cares. If you\u2019re like me this can sometimes drive you a little crazy because you\u2019re spending long hours working on things and you\u2019re not even sure if they are the correct things to work on or if a solution exists."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p26", "contents": "Developing taste. When it comes to choosing problems you\u2019ll hear academics talk about a mystical sense of \u201ctaste\u201d. It\u2019s a real thing. When you pitch a potential problem to your adviser you\u2019ll either see their face contort, their eyes rolling, and their attention drift, or you\u2019ll sense the excitement in their eyes as they contemplate the uncharted territory ripe for exploration. In that split second a lot happens: an evaluation of the problem\u2019s importance, difficulty, its sexiness, its historical context (and possibly also its fit to their active grants). In other words, your adviser is likely to be a master of the outer loop and will have a highly developed sense of taste for problems. During your PhD you\u2019ll get to acquire this sense yourself."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p27", "contents": "In particular, I think I had a terrible taste coming in to the PhD. I can see this from the notes I took in my early PhD years. A lot of the problems I was excited about at the time were in retrospect poorly conceived, intractable, or irrelevant. I\u2019d like to think I refined the sense by the end through practice and apprenticeship."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p28", "contents": "Let me now try to serialize a few thoughts on what goes into this sense of taste, and what makes a problem  interesting to work on."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p29", "contents": "A fertile ground. First, recognize that during your PhD you will dive deeply into one area and your papers will very likely chain on top of each other to create a body of work (which becomes your thesis). Therefore, you should always be thinking several steps ahead when choosing a problem. It\u2019s impossible to predict how things will unfold but you can often get a sense of how much room there could be for additional work."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p30", "contents": "Plays to your adviser\u2019s interests and strengths. You will want to operate in the realm of your adviser\u2019s interest. Some advisers may allow you to work on slightly tangential areas but you would not be taking full advantage of their knowledge and you are making them less likely to want to help you with your project or promote your work. For instance, (and this goes to my previous point of understanding your adviser\u2019s job) every adviser has a \u201cdefault talk\u201d slide deck on their research that they give all the time and if your work can add new exciting cutting edge work slides to this deck then you\u2019ll find them much more invested, helpful and involved in your research. Additionally, their talks will promote and publicize your work."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p31", "contents": "Be ambitious: the sublinear scaling of hardness. People have a strange bug built into psychology: a 10x more important or impactful problem intuitively feels 10x harder (or 10x less likely) to achieve. This is a fallacy - in my experience a 10x more important problem is at most 2-3x harder to achieve. In fact, in some cases a 10x harder problem may be easier to achieve. How is this? It\u2019s because thinking 10x forces you out of the box, to confront the real limitations of an approach, to think from first principles, to change the strategy completely, to innovate. If you aspire to improve something by 10% and work hard then you will. But if you aspire to improve it by 100% you are still quite likely to, but you will do it very differently."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p32", "contents": "Ambitious but with an attack. At this point it\u2019s also important to point out that there are plenty of important problems that don\u2019t make great projects. I recommend reading You and Your Research by Richard Hamming, where this point is expanded on:"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p33", "contents": "If you do not work on an important problem, it\u2019s unlikely you\u2019ll do important work. It\u2019s perfectly obvious. Great scientists have thought through, in a careful way, a number of important problems in their field, and they keep an eye on wondering how to attack them. Let me warn you, `important problem\u2019 must be phrased carefully. The three outstanding problems in physics, in a certain sense, were never worked on while I was at Bell Labs. By important I mean guaranteed a Nobel Prize and any sum of money you want to mention. We didn\u2019t work on (1) time travel, (2) teleportation, and (3) antigravity. They are not important problems because we do not have an attack. It\u2019s not the consequence that makes a problem important, it is that you have a reasonable attack. That is what makes a problem important."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p34", "contents": "The person who did X. Ultimately, the goal of a PhD is to not only develop a deep expertise in a field but to also make your mark upon it. To steer it, shape it. The ideal scenario is that by the end of the PhD you own some part of an important area, preferably one that is also easy and fast to describe. You want people to say things like \u201cshe\u2019s the person who did X\u201d. If you can fill in a blank there you\u2019ll be successful."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p35", "contents": "Valuable skills. Recognize that during your PhD you will become an expert at the area of your choosing (as fun aside, note that [5 years]x[260 working days]x[8 hours per day] is 10,400 hours; if you believe Gladwell then a PhD is exactly the amount of time to become an expert). So imagine yourself 5 years later being a world expert in this area (the 10,000 hours will ensure that regardless of the academic impact of your work). Are these skills exciting or potentially valuable to your future endeavors?"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p36", "contents": "Negative examples. There are also some problems or types of papers that you ideally want to avoid. For instance, you\u2019ll sometimes hear academics talk about \u201cincremental work\u201d (this is the worst adjective possible in academia). Incremental work is a paper that enhances something existing by making it more complex and gets 2% extra on some benchmark. The amusing thing about these papers is that they have a reasonably high chance of getting accepted (a reviewer can\u2019t point to anything to kill them; they are also sometimes referred to as \u201ccockroach papers\u201d), so if you have a string of these papers accepted you can feel as though you\u2019re being very productive, but in fact these papers won\u2019t go on to be highly cited and you won\u2019t go on to have a lot of impact on the field. Similarly, finding projects should ideally not include thoughts along the lines of \u201cthere\u2019s this next logical step in the air that no one has done yet, let me do it\u201d, or \u201cthis should be an easy poster\u201d."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p37", "contents": "Case study: my thesis. To make some of this discussion more concrete I wanted to use the example of how my own PhD unfolded. First, fun fact: my entire thesis is based on work I did in the last 1.5 years of my PhD. i.e. it took me quite a long time to wiggle around in the metaproblem space and find a problem that I felt very excited to work on (the other ~2 years I mostly meandered on 3D things (e.g. Kinect Fusion, 3D meshes, point cloud features) and video things). Then at one point in my 3rd year I randomly stopped by Richard Socher\u2019s office on some Saturday at 2am. We had a chat about interesting problems and I realized that some of his work on images and language was in fact getting at something very interesting (of course, the area at the intersection of images and language goes back quite a lot further than Richard as well). I couldn\u2019t quite see all the papers that would follow but it seemed heuristically very promising: it was highly fertile (a lot of unsolved problems, a lot of interesting possibilities on grounding descriptions to images), I felt that it was very cool and important, it was easy to explain, it seemed to be at the boundary of possible (Deep Learning has just started to work), the datasets had just started to become available (Flickr8K had just come out), it fit nicely into Fei-Fei\u2019s interests and even if I were not successful I\u2019d at least get lots of practice with optimizing interesting deep nets that I could reapply elsewhere. I had a strong feeling of a tsunami of checkmarks as everything clicked in place in my mind. I pitched this to Fei-Fei (my adviser) as an area to dive into the next day and, with relief, she enthusiastically approved, encouraged me, and would later go on to steer me within the space (e.g. Fei-Fei insisted that I do image to sentence generation while I was mostly content with ranking.). I\u2019m happy with how things evolved from there. In short, I meandered around for 2 years stuck around the outer loop, finding something to dive into. Once it clicked for me what that was based on several heuristics, I dug in."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p38", "contents": "Resistance. I\u2019d like to also mention that your adviser is by no means infallible. I\u2019ve witnessed and heard of many instances in which, in retrospect, the adviser made the wrong call. If you feel this way during your phd you should have the courage to sometimes ignore your adviser. Academia generally celebrates independent thinking but the response of your specific adviser can vary depending on circumstances. I\u2019m aware of multiple cases where the bet worked out very well and I\u2019ve also personally experienced cases where it did not. For instance, I disagreed strongly with some advice Andrew Ng gave me in my very first year. I ended up working on a problem he wasn\u2019t very excited about and, surprise, he turned out to be very right and I wasted a few months. Win some lose some :)"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p39", "contents": "Don\u2019t play the game. Finally, I\u2019d like to challenge you to think of a PhD as more than just a sequence of papers. You\u2019re not a paper writer. You\u2019re a member of a research community and your goal is to push the field forward. Papers are one common way of doing that but I would encourage you to look beyond the established academic game. Think for yourself and from first principles. Do things others don\u2019t do but should. Step off the treadmill that has been put before you. I tried to do some of this myself throughout my PhD. This blog is an example - it allows me communicate things that wouldn\u2019t ordinarily go into papers. The ImageNet human reference experiments are an example - I felt strongly that it was important for the field to know the ballpark human accuracy on ILSVRC so I took a few weeks off and evaluated it. The academic search tools (e.g. arxiv-sanity) are an example - I felt continuously frustrated by the inefficiency of finding papers in the literature and I released and maintain the site in hopes that it can be useful to others. Teaching CS231n twice is an example - I put much more effort into it than is rationally advisable for a PhD student who should be doing research, but I felt that the field was held back if people couldn\u2019t efficiently learn about the topic and enter. A lot of my PhD endeavors have likely come at a cost in standard academic metrics (e.g. h-index, or number of publications in top venues) but I did them anyway, I would do it the same way again, and here I am encouraging others to as well. To add a pitch of salt and wash down the ideology a bit, based on several past discussions with my friends and colleagues I know that this view is contentious and that many would disagree."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p40", "contents": "Writing good papers is an essential survival skill of an academic (kind of like making fire for a caveman). In particular, it is very important to realize that papers are a specific thing: they look a certain way, they flow a certain way, they have a certain structure, language, and statistics that the other academics expect. It\u2019s usually a painful exercise for me to look through some of my early PhD paper drafts because they are quite terrible. There is a lot to learn here."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p41", "contents": "Review papers. If you\u2019re trying to learn to write better papers it can feel like a sensible strategy to look at many good papers and try to distill patterns. This turns out to not be the best strategy; it\u2019s analogous to only receiving positive examples for a binary classification problem. What you really want is to also have exposure to a large number of bad papers and one way to get this is by reviewing papers. Most good conferences have an acceptance rate of about 25% so most papers you\u2019ll review are bad, which will allow you to build a powerful binary classifier. You\u2019ll read through a bad paper and realize how unclear it is, or how it doesn\u2019t define it\u2019s variables, how vague and abstract its intro is, or how it dives in to the details too quickly, and you\u2019ll learn to avoid the same pitfalls in your own papers. Another related valuable experience is to attend (or form) journal clubs - you\u2019ll see experienced researchers critique papers and get an impression for how your own papers will be analyzed by others."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p42", "contents": "Get the gestalt right. I remember being impressed with Fei-Fei (my adviser) once during a reviewing session. I had a stack of 4 papers I had reviewed over the last several hours and she picked them up, flipped through each one for 10 seconds, and said one of them was good and the other three bad. Indeed, I was accepting the one and rejecting the other three, but something that took me several hours took her seconds. Fei-Fei was relying on the gestalt of the papers as a powerful heuristic. Your papers, as you become a more senior researcher take on a characteristic look. An introduction of ~1 page. A ~1 page related work section with a good density of citations - not too sparse but not too crowded. A well-designed pull figure (on page 1 or 2) and system figure (on page 3) that were not made in MS Paint. A technical section with some math symbols somewhere, results tables with lots of numbers and some of them bold, one additional cute analysis experiment, and the paper has exactly 8 pages (the page limit) and not a single line less. You\u2019ll have to learn how to endow your papers with the same gestalt because many researchers rely on it as a cognitive shortcut when they judge your work."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p43", "contents": "Identify the core contribution. Before you start writing anything it\u2019s important to identify the single core contribution that your paper makes to the field. I would especially highlight the word single. A paper is not a random collection of some experiments you ran that you report on. The paper sells a single thing that was not obvious or present before. You have to argue that the thing is important, that it hasn\u2019t been done before, and then you support its merit experimentally in controlled experiments. The entire paper is organized around this core contribution with surgical precision. In particular it doesn\u2019t have any additional fluff and it doesn\u2019t try to pack anything else on a side. As a concrete example, I made a mistake in one of my earlier papers on video classification where I tried to pack in two contributions: 1) a set of architectural layouts for video convnets and an unrelated 2) multi-resolution architecture which gave small improvements. I added it because I reasoned first that maybe someone could find it interesting and follow up on it later and second because I thought that contributions in a paper are additive: two contributions are better than one. Unfortunately, this is false and very wrong. The second contribution was minor/dubious and it diluted the paper, it was distracting, and no one cared. I\u2019ve made a similar mistake again in my CVPR 2014 paper which presented two separate models: a ranking model and a generation model. Several good in-retrospect arguments could be made that I should have submitted two separate papers; the reason it was one is more historical than rational."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p44", "contents": "The structure. Once you\u2019ve identified your core contribution there is a default recipe for writing a paper about it. The upper level structure is by default Intro, Related Work, Model, Experiments, Conclusions. When I write my intro I find that it helps to put down a coherent top-level narrative in latex comments and then fill in the text below. I like to organize each of my paragraphs around a single concrete point stated on the first sentence that is then supported in the rest of the paragraph. This structure makes it easy for a reader to skim the paper. A good flow of ideas is then along the lines of 1) X (+define X if not obvious) is an important problem 2) The core challenges are this and that. 2) Previous work on X has addressed these with Y, but the problems with this are Z. 3) In this work we do W (?). 4) This has the following appealing properties and our experiments show this and that. You can play with this structure a bit but these core points should be clearly made. Note again that the paper is surgically organized around your exact contribution. For example, when you list the challenges you want to list exactly the things that you address later; you don\u2019t go meandering about unrelated things to what you have done (you can speculate a bit more later in conclusion). It is important to keep a sensible structure throughout your paper, not just in the intro. For example, when you explain the model each section should: 1) explain clearly what is being done in the section, 2) explain what the core challenges are 3) explain what a baseline approach is or what others have done before 4) motivate and explain what you do 5) describe it."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p45", "contents": "Break the structure. You should also feel free (and you\u2019re encouraged to!) play with these formulas to some extent and add some spice to your papers. For example, see this amusing paper from Razavian et al. in 2014 that structures the introduction as a dialog between a student and the professor. It\u2019s clever and I like it. As another example, a lot of papers from Alyosha Efros have a playful tone and make great case studies in writing fun papers. As only one of many examples, see this paper he wrote with Antonio Torralba: Unbiased look at dataset bias. Another possibility I\u2019ve seen work well is to include an FAQ section, possibly in the appendix."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p46", "contents": "Common mistake: the laundry list. One very common mistake to avoid is the \u201claundry list\u201d, which looks as follows: \u201cHere is the problem. Okay now to solve this problem first we do X, then we do Y, then we do Z, and now we do W, and here is what we get\u201d. You should try very hard to avoid this structure. Each point should be justified, motivated, explained. Why do you do X or Y? What are the alternatives? What have others done? It\u2019s okay to say things like this is common (add citation if possible). Your paper is not a report, an enumeration of what you\u2019ve done, or some kind of a translation of your chronological notes and experiments into latex. It is a highly processed and very focused discussion of a problem, your approach and its context. It is supposed to teach your colleagues something and you have to justify your steps, not just describe what you did."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p47", "contents": "The language. Over time you\u2019ll develop a vocabulary of good words and bad words to use when writing papers. Speaking about machine learning or computer vision papers specifically as concrete examples, in your papers you never \u201cstudy\u201d or \u201cinvestigate\u201d (there are boring, passive, bad words); instead you \u201cdevelop\u201d or even better you \u201cpropose\u201d. And you don\u2019t present a \u201csystem\u201d or, shudder, a \u201cpipeline\u201d; instead, you develop a \u201cmodel\u201d. You don\u2019t learn \u201cfeatures\u201d, you learn \u201crepresentations\u201d. And god forbid, you never \u201ccombine\u201d, \u201cmodify\u201d or \u201cexpand\u201d. These are incremental, gross terms that will certainly get your paper rejected :)."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p48", "contents": "An internal deadlines 2 weeks prior. Not many labs do this, but luckily Fei-Fei is quite adamant about an internal deadline 2 weeks before the due date in which you must submit at least a 5-page draft with all the final experiments (even if not with final numbers) that goes through an internal review process identical to the external one (with the same review forms filled out, etc). I found this practice to be extremely useful because forcing yourself to lay out the full paper almost always reveals some number of critical experiments you must run for the paper to flow and for its argument flow to be coherent, consistent and convincing."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p49", "contents": "Another great resource on this topic is Tips for Writing Technical Papers from Jennifer Widom."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p50", "contents": "A lot of your time will of course be taken up with the execution of your ideas, which likely involves a lot of coding. I won\u2019t dwell on this too much because it\u2019s not uniquely academic, but I would like to bring up a few points."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p51", "contents": "Release your code. It\u2019s a somewhat surprising fact but you can get away with publishing papers and not releasing your code. You will also feel a lot of incentive to not release your code: it can be a lot of work (research code can look like spaghetti since you iterate very quickly, you have to clean up a lot), it can be intimidating to think that others might judge you on your at most decent coding abilities, it is painful to maintain code and answer questions from other people about it (forever), and you might also be concerned that people could spot bugs that invalidate your results. However, it is precisely for some of these reasons that you should commit to releasing your code: it will force you to adopt better coding habits due to fear of public shaming (which will end up saving you time!), it will force you to learn better engineering practices, it will force you to be more thorough with your code (e.g. writing unit tests to make bugs much less likely), it will make others much more likely to follow up on your work (and hence lead to more citations of your papers) and of course it will be much more useful to everyone as a record of exactly what was done for posterity. When you do release your code I recommend taking advantage of docker containers; this will reduce the amount of headaches people email you about when they can\u2019t get all the dependencies (and their precise versions) installed."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p52", "contents": "Think of the future you. Make sure to document all your code very well for yourself. I guarantee you that you will come back to your code base a few months later (e.g. to do a few more experiments for the camera ready version of the paper), and you will feel completely lost in it. I got into the habit of creating very thorough readme.txt files in all my repos (for my personal use) as notes to future self on how the code works, how to run it, etc."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p53", "contents": "So, you published a paper and it\u2019s an oral! Now you get to give a few minute talk to a large audience of people - what should it look like?"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p54", "contents": "The goal of a talk. First, that there\u2019s a common misconception that the goal of your talk is to tell your audience about what you did in your paper. This is incorrect, and should only be a second or third degree design criterion. The goal of your talk is to 1) get the audience really excited about the problem you worked on (they must appreciate it or they will not care about your solution otherwise!) 2) teach the audience something (ideally while giving them a taste of your insight/solution; don\u2019t be afraid to spend time on other\u2019s related work), and 3) entertain (they will start checking their Facebook otherwise). Ideally, by the end of the talk the people in your audience are thinking some mixture of \u201cwow, I\u2019m working in the wrong area\u201d, \u201cI have to read this paper\u201d, and \u201cThis person has an impressive understanding of the whole area\u201d."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p55", "contents": "A few do\u2019s: There are several properties that make talks better. For instance, Do: Lots of pictures. People Love pictures. Videos and animations should be used more sparingly because they distract. Do: make the talk actionable - talk about something someone can do after your talk. Do: give a live demo if possible, it can make your talk more memorable. Do: develop a broader intellectual arch that your work is part of. Do: develop it into a story (people love stories). Do: cite, cite, cite - a lot! It takes very little slide space to pay credit to your colleagues. It pleases them and always reflects well on you because it shows that you\u2019re humble about your own contribution, and aware that it builds on a lot of what has come before and what is happening in parallel. You can even cite related work published at the same conference and briefly advertise it. Do: practice the talk! First for yourself in isolation and later to your lab/friends. This almost always reveals very insightful flaws in your narrative and flow."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p56", "contents": "Don\u2019t: texttexttext. Don\u2019t crowd your slides with text. There should be very few or no bullet points - speakers sometimes try to use these as a crutch to remind themselves what they should be talking about but the slides are not for you they are for the audience. These should be in your speaker notes. On the topic of crowding the slides, also avoid complex diagrams as much as you can - your audience has a fixed bit bandwidth and I guarantee that your own very familiar and \u201csimple\u201d diagram is not as simple or interpretable to someone seeing it for the first time."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p57", "contents": "Careful with: result tables: Don\u2019t include dense tables of results showing that your method works better. You got a paper, I\u2019m sure your results were decent. I always find these parts boring and unnecessary unless the numbers show something interesting (other than your method works better), or of course unless there is a large gap that you\u2019re very proud of. If you do include results or graphs build them up slowly with transitions, don\u2019t post them all at once and spend 3 minutes on one slide."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p58", "contents": "Pitfall: the thin band between bored/confused. It\u2019s actually quite tricky to design talks where a good portion of your audience learns something. A common failure case (as an audience member) is to see talks where I\u2019m painfully bored during the first half and completely confused during the second half, learning nothing by the end. This can occur in talks that have a very general (too general) overview followed by a technical (too technical) second portion. Try to identify when your talk is in danger of having this property."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p59", "contents": "Pitfall: running out of time. Many speakers spend too much time on the early intro parts (that can often be somewhat boring) and then frantically speed through all the last few slides that contain the most interesting results, analysis or demos. Don\u2019t be that person."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p60", "contents": "Pitfall: formulaic talks. I might be a special case but I\u2019m always a fan of non-formulaic talks that challenge conventions. For instance, I despise the outline slide. It makes the talk so boring, it\u2019s like saying: \u201cThis movie is about a ring of power. In the first chapter we\u2019ll see a hobbit come into possession of the ring. In the second we\u2019ll see him travel to Mordor. In the third he\u2019ll cast the ring into Mount Doom and destroy it. I will start with chapter 1\u201d - Come on! I use outline slides for much longer talks to keep the audience anchored if they zone out (at 30min+ they inevitably will a few times), but it should be used sparingly."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p61", "contents": "Observe and learn. Ultimately, the best way to become better at giving talks (as it is with writing papers too) is to make conscious effort to pay attention to what great (and not so great) speakers do and build a binary classifier in your mind. Don\u2019t just enjoy talks; analyze them, break them down, learn from them. Additionally, pay close attention to the audience and their reactions. Sometimes a speaker will put up a complex table with many numbers and you will notice half of the audience immediately look down on their phone and open Facebook. Build an internal classifier of the events that cause this to happen and avoid them in your talks."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p62", "contents": "On the subject of conferences:"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p63", "contents": "Go. It\u2019s very important that you go to conferences, especially the 1-2 top conferences in your area. If your adviser lacks funds and does not want to pay for your travel expenses (e.g. if you don\u2019t have a paper) then you should be willing to pay for yourself (usually about $2000 for travel, accommodation, registration and food). This is important because you want to become part of the academic community and get a chance to meet more people in the area and gossip about research topics. Science might have this image of a few brilliant lone wolfs working in isolation, but the truth is that research is predominantly a highly social endeavor - you stand on the shoulders of many people, you\u2019re working on problems in parallel with other people, and it is these people that you\u2019re also writing papers to. Additionally, it\u2019s unfortunate but each field has knowledge that doesn\u2019t get serialized into papers but is instead spread across a shared understanding of the community; things such as what are the next important topics to work on, what papers are most interesting, what is the inside scoop on papers, how they developed historically, what methods work (not just on paper, in reality), etcetc. It is very valuable (and fun!) to become part of the community and get direct access to the hivemind - to learn from it first, and to hopefully influence it later."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p64", "contents": "Talks: choose by speaker. One conference trick I\u2019ve developed is that if you\u2019re choosing which talks to attend it can be better to look at the speakers instead of the topics. Some people give better talks than others (it\u2019s a skill, and you\u2019ll discover these people in time) and in my experience I find that it often pays off to see them speak even if it is on a topic that isn\u2019t exactly connected to your area of research."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p65", "contents": "The real action is in the hallways. The speed of innovation (especially in Machine Learning) now works at timescales much faster than conferences so most of the relevant papers you\u2019ll see at the conference are in fact old news. Therefore, conferences are primarily a social event. Instead of attending a talk I encourage you to view the hallway as one of the main events that doesn\u2019t appear on the schedule. It can also be valuable to stroll the poster session and discover some interesting papers and ideas that you may have missed."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p66", "contents": "It is said that there are three stages to a PhD. In the first stage you look at a related paper\u2019s reference section and you haven\u2019t read most of the papers. In the second stage you recognize all the papers. In the third stage you\u2019ve shared a beer with all the first authors of all the papers."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p67", "contents": "I can\u2019t find the quote anymore but I heard Sam Altman of YC say that there are no shortcuts or cheats when it comes to building a startup. You can\u2019t expect to win in the long run by somehow gaming the system or putting up false appearances. I think that the same applies in academia. Ultimately you\u2019re trying to do good research and push the field forward and if you try to game any of the proxy metrics you won\u2019t be successful in the long run. This is especially so because academia is in fact surprisingly small and highly interconnected, so anything shady you try to do to pad your academic resume (e.g. self-citing a lot, publishing the same idea multiple times with small remixes, resubmitting the same rejected paper over and over again with no changes, conveniently trying to leave out some baselines etc.) will eventually catch up with you and you will not be successful."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p68", "contents": "So at the end of the day it\u2019s quite simple. Do good work, communicate it properly, people will notice and good things will happen. Have a fun ride!"}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p69", "contents": "\nEDIT: HN discussion link."}
{"id": "http://karpathy.github.io//2016/09/07/phd/_p70", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2018/01/20/medium/_p0", "contents": "Jan 20, 2018"}
{"id": "http://karpathy.github.io//2018/01/20/medium/_p1", "contents": "The current state of this blog (with the last post 2 years ago) makes it look like I\u2019ve disappeared. I\u2019ve certainly become less active on blogs since I\u2019ve joined Tesla, but\nwhenever I do get a chance to post something I have recently been defaulting\nto doing it on Medium because it is much faster and easier. I still plan to come back \nhere for longer posts if I get any time, but I\u2019ll default to Medium for everything short-medium in length."}
{"id": "http://karpathy.github.io//2018/01/20/medium/_p2", "contents": "Have a look at my Medium blog."}
{"id": "http://karpathy.github.io//2018/01/20/medium/_p3", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p0", "contents": "Apr 25, 2019"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p1", "contents": "Some few weeks ago I posted a tweet on \u201cthe most common neural net mistakes\u201d, listing a few common gotchas related to training neural nets. The tweet got quite a bit more engagement than I anticipated (including a webinar :)). Clearly, a lot of people have personally encountered the large gap between \u201chere is how a convolutional layer works\u201d and \u201cour convnet achieves state of the art results\u201d."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p2", "contents": "So I thought it could be fun to brush off my dusty blog to expand my tweet to the long form that this topic deserves. However, instead of going into an enumeration of more common errors or fleshing them out, I wanted to dig a bit deeper and talk about how one can avoid making these errors altogether (or fix them very fast). The trick to doing so is to follow a certain process, which as far as I can tell is not very often documented. Let\u2019s start with two important observations that motivate it."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p3", "contents": "It is allegedly easy to get started with training neural nets. Numerous libraries and frameworks take pride in displaying 30-line miracle snippets that solve your data problems, giving the (false) impression that this stuff is plug and play. It\u2019s common see things like:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p4", "contents": "These libraries and examples activate the part of our brain that is familiar with standard software - a place where clean APIs and abstractions are often attainable. Requests library to demonstrate:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p5", "contents": "That\u2019s cool! A courageous developer has taken the burden of understanding query strings, urls, GET/POST requests, HTTP connections, and so on from you and largely hidden the complexity behind a few lines of code. This is what we are familiar with and expect. Unfortunately, neural nets are nothing like that. They are not \u201coff-the-shelf\u201d technology the second you deviate slightly from training an ImageNet classifier. I\u2019ve tried to make this point in my post \u201cYes you should understand backprop\u201d by picking on backpropagation and calling it a \u201cleaky abstraction\u201d, but the situation is unfortunately much more dire. Backprop + SGD does not magically make your network work. Batch norm does not magically make it converge faster. RNNs don\u2019t magically let you \u201cplug in\u201d text. And just because you can formulate your problem as RL doesn\u2019t mean you should. If you insist on using the technology without understanding how it works you are likely to fail. Which brings me to\u2026"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p6", "contents": "When you break or misconfigure code you will often get some kind of an exception. You plugged in an integer where something expected a string. The function only expected 3 arguments. This import failed. That key does not exist. The number of elements in the two lists isn\u2019t equal. In addition, it\u2019s often possible to create unit tests for a certain functionality."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p7", "contents": "This is just a start when it comes to training neural nets. Everything could be correct syntactically, but the whole thing isn\u2019t arranged properly, and it\u2019s really hard to tell. The \u201cpossible error surface\u201d is large, logical (as opposed to syntactic), and very tricky to unit test. For example, perhaps you forgot to flip your labels when you left-right flipped the image during data augmentation. Your net can still (shockingly) work pretty well because your network can internally learn to detect flipped images and then it left-right flips its predictions. Or maybe your autoregressive model accidentally takes the thing it\u2019s trying to predict as an input due to an off-by-one bug. Or you tried to clip your gradients but instead clipped the loss, causing the outlier examples to be ignored during training. Or you initialized your weights from a pretrained checkpoint but didn\u2019t use the original mean. Or you just screwed up the settings for regularization strengths, learning rate, its decay rate, model size, etc. Therefore, your misconfigured neural net will throw exceptions only if you\u2019re lucky; Most of the time it will train but silently work a bit worse."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p8", "contents": "As a result, (and this is reeaally difficult to over-emphasize) a \u201cfast and furious\u201d approach to training neural networks does not work and only leads to suffering. Now, suffering is a perfectly natural part of getting a neural network to work well, but it can be mitigated by being thorough, defensive, paranoid, and obsessed with visualizations of basically every possible thing. The qualities that in my experience correlate most strongly to success in deep learning are patience and attention to detail."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p9", "contents": "In light of the above two facts, I have developed a specific process for myself that I follow when applying a neural net to a new problem, which I will try to describe. You will see that it takes the two principles above very seriously. In particular, it builds from simple to complex and at every step of the way we make concrete hypotheses about what will happen and then either validate them with an experiment or investigate until we find some issue. What we try to prevent very hard is the introduction of a lot of \u201cunverified\u201d complexity at once, which is bound to introduce bugs/misconfigurations that will take forever to find (if ever). If writing your neural net code was like training one, you\u2019d want to use a very small learning rate and guess and then evaluate the full test set after every iteration."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p10", "contents": "The first step to training a neural net is to not touch any neural net code at all and instead begin by thoroughly inspecting your data. This step is critical. I like to spend copious amount of time (measured in units of hours) scanning through thousands of examples, understanding their distribution and looking for patterns. Luckily, your brain is pretty good at this. One time I discovered that the data contained duplicate examples. Another time I found corrupted images / labels. I look for data imbalances and biases. I will typically also pay attention to my own process for classifying the data, which hints at the kinds of architectures we\u2019ll eventually explore. As an example - are very local features enough or do we need global context? How much variation is there and what form does it take? What variation is spurious and could be preprocessed out? Does spatial position matter or do we want to average pool it out? How much does detail matter and how far could we afford to downsample the images? How noisy are the labels?"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p11", "contents": "In addition, since the neural net is effectively a compressed/compiled version of your dataset, you\u2019ll be able to look at your network (mis)predictions and understand where they might be coming from. And if your network is giving you some prediction that doesn\u2019t seem consistent with what you\u2019ve seen in the data, something is off."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p12", "contents": "Once you get a qualitative sense it is also a good idea to write some simple code to search/filter/sort by whatever you can think of (e.g. type of label, size of annotations, number of annotations, etc.) and visualize their distributions and the outliers along any axis. The outliers especially almost always uncover some bugs in data quality or preprocessing."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p13", "contents": "Now that we understand our data can we reach for our super fancy Multi-scale ASPP FPN ResNet and begin training awesome models? For sure no. That is the road to suffering. Our next step is to set up a full training + evaluation skeleton and gain trust in its correctness via a series of experiments. At this stage it is best to pick some simple model that you couldn\u2019t possibly have screwed up somehow - e.g. a linear classifier, or a very tiny ConvNet. We\u2019ll want to train it, visualize the losses, any other metrics (e.g. accuracy), model predictions, and perform a series of ablation experiments with explicit hypotheses along the way."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p14", "contents": "Tips & tricks for this stage:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p15", "contents": "At this stage we should have a good understanding of the dataset and we have the full training + evaluation pipeline working. For any given model we can (reproducibly) compute a metric that we trust. We are also armed with our performance for an input-independent baseline, the performance of a few dumb baselines (we better beat these), and we have a rough sense of the performance of a human (we hope to reach this). The stage is now set for iterating on a good model."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p16", "contents": "The approach I like to take to finding a good model has two stages: first get a model large enough that it can overfit (i.e. focus on training loss) and then regularize it appropriately (give up some training loss to improve the validation loss). The reason I like these two stages is that if we are not able to reach a low error rate with any model at all that may again indicate some issues, bugs, or misconfiguration."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p17", "contents": "A few tips & tricks for this stage:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p18", "contents": "Ideally, we are now at a place where we have a large model that is fitting at least the training set. Now it is time to regularize it and gain some validation accuracy by giving up some of the training accuracy. Some tips & tricks:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p19", "contents": "Finally, to gain additional confidence that your network is a reasonable classifier, I like to visualize the network\u2019s first-layer weights and ensure you get nice edges that make sense. If your first layer filters look like noise then something could be off. Similarly, activations inside the net can sometimes display odd artifacts and hint at problems."}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p20", "contents": "You should now be \u201cin the loop\u201d with your dataset exploring a wide model space for architectures that achieve low validation loss. A few tips and tricks for this step:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p21", "contents": "Once you find the best types of architectures and hyper-parameters you can still use a few more tricks to squeeze out the last pieces of juice out of the system:"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p22", "contents": "Once you make it here you\u2019ll have all the ingredients for success: You have a deep understanding of the technology, the dataset and the problem, you\u2019ve set up the entire training/evaluation infrastructure and achieved high confidence in its accuracy, and you\u2019ve explored increasingly more complex models, gaining performance improvements in ways you\u2019ve predicted each step of the way. You\u2019re now ready to read a lot of papers, try a large number of experiments, and get your SOTA results. Good luck!"}
{"id": "http://karpathy.github.io//2019/04/25/recipe/_p23", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p0", "contents": "Jun 11, 2020"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p1", "contents": "Throughout my life I never paid too much attention to health, exercise, diet or nutrition. I knew that you\u2019re supposed to get some exercise and eat vegetables or something, but it stopped at that (\u201cmom said\u201d-) level of abstraction. I also knew that I can probably get away with some ignorance while I am young, but at some point I was messing with my health-adjusted life expectancy. So about halfway through 2019 I resolved to spend some time studying these topics in greater detail and dip my toes into some biohacking. And now\u2026 it\u2019s been a year!"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p2", "contents": "Now, I won\u2019t lie, things got a bit out of hand over the last year with ketogenic diets, (continuous) blood glucose / beta-hydroxybutyrate tests, intermittent fasting, extended water fasting, various supplements, blood tests, heart rate monitors, dexa scans, sleep trackers, sleep studies, cardio equipments, resistance training routines etc., all of which I won\u2019t go into full details of because it lets a bit too much of the mad scientist crazy out. But as someone who has taken plenty of physics, some chemistry but basically zero biology during my high school / undergrad years, undergoing some of these experiments was incredibly fun and a great excuse to study a number of textbooks on biochemistry (I liked \u201cMolecular Biology of the Cell\u201d), biology (I liked Campbell\u2019s Biology), human nutrition (I liked \u201cAdvanced Nutrition and Human Metabolism\u201d), etc."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p3", "contents": "For this post I wanted to focus on some of my experiments around weight loss because 1) weight is very easy to measure and 2) the biochemistry of it is interesting. In particular, in June 2019 I was around 200lb and I decided I was going to lose at least 25lb to bring myself to ~175lb, which according to a few publications is the weight associated with the lowest all cause mortality for my gender, age, and height. Obviously, a target weight is an exceedingly blunt instrument and is by itself just barely associated with health and general well-being. I also understand that weight loss is a sensitive, complicated topic and much has been discussed on the subject from a large number of perspectives. The goal of this post is to nerd out over biochemistry and energy metabolism in the animal kingdom, and potentially inspire others on their own biohacking lite adventure."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p4", "contents": "What weight is lost anyway? So it turns out that, roughly speaking, we weigh more because our batteries are very full. A human body is like an iPhone with a battery pack that can grow nearly indefinitely, and with the abundance of food around us we scarcely unplug from the charging outlet. In this case, the batteries are primarily the adipose tissue and triglycerides (fat) stored within, which are eagerly stockpiled (or sometimes also synthesized!) by your body to be burned for energy in case food becomes scarce. This was all very clever and dandy when our hunter gatherer ancestors downed a mammoth once in a while during an ice age, but not so much today with weaponized truffle double chocolate fudge cheesecakes masquerading on dessert menus."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p5", "contents": "Body\u2019s batteries. To be precise, the body has roughly 4 batteries available to it, each varying in its total capacity and the latency/throughput with which it can be mobilized. The biochemical implementation details of each storage medium vary but, remarkably, in every case your body discharges the batteries for a single, unique purpose: to synthesize adenosine triphosphate, or ATP from ADP (alright technically/aside some also goes to the \u201credox power\u201d of NADH/NADPH). The synthesis itself is relatively straightforward, taking one molecule of adenosine diphosphate (ADP), and literally snapping on a 3rd phosphate group to its end. Doing this is kind of like a molecular equivalent of squeezing and loading a spring:"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p6", "contents": "This is completely not obvious and remarkable - a single molecule (ATP) functions as a universal $1 bill that energetically \u201cpays for\u201d much of the work done by your protein machinery. Even better, this system turns out to have an ancient origin and is common to all life on Earth. Need to (active) transport some molecule across the cell membrane? ATP binding to the transmembrane protein provides the needed \u201cumph\u201d. Need to temporarily untie the DNA against its hydrogen bonds? ATP binds to the protein complex to power the unzipping. Need to move myosin down an actin filament to contract a muscle? ATP to the rescue! Need to shuttle proteins around the cell\u2019s cytoskeleton? ATP powers the tiny molecular motor (kinesin). Need to attach an amino acid to tRNA to prepare it for protein synthesis in the ribosome? ATP required. You get the idea."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p7", "contents": "Now, the body only maintains a very small amount ATP molecules \u201cin supply\u201d at any time. The ATP is quickly hydrolyzed, chopping off the third phosphate group, releasing energy for work, and leaving behind ADP. As mentioned, we have roughly 4 batteries that can all be \u201cdischarged\u201d into re-generating ATP from ADP:"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p8", "contents": "All four of these batteries are charged/discharged at all times to different amounts. If you just ate a cookie, your cookie will promptly be chopped down to glucose, which will circulate in your bloodstream. If there is too much glucose around (in the case of cookies there would be), your anabolic pathways will promptly store it as glycogen in the liver and skeletal muscle, or (more rarely, if in vast abundance) convert it to fat. On the catabolic side, if you start jogging you\u2019ll primarily use (1) for the first ~3 seconds, (2) for the next 8-10 seconds anaerobically, and then (2, 3) will ramp up aerobically (a higher latency, higher throughput pathway) once your body kicks into a higher gear by increasing the heart rate, breathing rate, and oxygen transport. (4) comes into play mostly if you starve yourself or deprive your body of carbohydrates in your diet."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p9", "contents": "Since I am a computer scientist it is hard to avoid a comparison of this \u201cenergy hierarchy\u201d to the memory hierarchy of a typical computer system. Moving energy around (stored chemically in high energy C-H / C-C bonds of molecules) is expensive just like moving bits around a chip. (1) is your L1/L2 cache - it is local, immediate, but tiny. Anaerobic (2) via glycolysis in the cytosol is your RAM, and aerobic respiration (3) is your disk: high latency (the fatty acids are shuttled over all the way from adipose tissue through the bloodstream!) but high throughput and massive storage."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p10", "contents": "The source of weight loss. So where does your body weight go exactly when you \u201close it\u201d? It\u2019s a simple question but it stumps most people, including my younger self. Your body weight is ultimately just the sum of the individual weights of the atoms that make you up - carbon, hydrogen, nitrogen, oxygen, etc. arranged into a zoo of complex, organic molecules. One day you could weigh 180lb and the next 178lb. Where did the 2lb of atoms go? It turns out that most of your day-to-day fluctuations are attributable to water retention, which can vary a lot with your levels of sodium, your current glycogen levels, various hormone/vitamin/mineral levels, etc. The contents of your stomach/intestine and stool/urine also add to this. But where does the fat, specifically, go when you \u201close\u201d it, or \u201cburn\u201d it? Those carbon/hydrogen atoms that make it up don\u2019t just evaporate out of existence. (If our body could evaporate them we\u2019d expect E=mc^2 of energy, which would be cool). Anyway, it turns out that you breathe out most of your weight. Your breath looks transparent but you inhale a bunch of oxygen and you exhale a bunch of carbon dioxide. The carbon in that carbon dioxide you just breathed out may have just seconds ago been part of a triglyceride molecule in your fat. It\u2019s highly amusing to think that every single time you breathe out (in a fasted state) you are literally breathing out your fat carbon by carbon. There is a good TED talk and even a whole paper with the full biochemistry/stoichiometry involved."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p11", "contents": "Combustion. Let\u2019s now turn to the chemical process underlying weight loss. You know how you can take wood and light it on fire to \u201cburn\u201d it?  This chemical reaction is combustion; You\u2019re taking a bunch of organic matter with a lot of C-C and C-H bonds and, with a spark, providing the activation energy necessary for the surrounding voraciously electronegative oxygen to react with it, stripping away all of the carbons into carbon dioxide (CO2) and all of the hydrogens into water (H2O). This reaction releases a lot of heat in the process, thus sustaining the reaction until all energy-rich C-C and C-H bonds are depleted. These bonds are referred to as \u201cenergy-rich\u201d because energetically carbon reeeallly wants to be carbon dioxide (CO2) and hydrogen reeeeally wants to be water (H2O), but this reaction is gated by an activation energy barrier, allowing large amounts of C-C/C-H rich macromolecules to exist in stable forms, in ambient conditions, and in the presence of oxygen."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p12", "contents": "Cellular respiration: \u201cslow motion\u201d combustion. Remarkably, your body does the exact same thing as far as inputs (organic compounds), outputs (CO2 and H2O) and stoichiometry are concerned, but the burning is not explosive but slow and controlled, with plenty of molecular intermediates that torture biology students. This biochemical miracle begins with fats/carbohydrates/proteins (molecules rich in C-C and C-H bonds) and goes through stepwise, complete, slow-motion combustion via glycolysis / beta oxidation, citric acid cycle, oxidative phosphorylation, and finally the electron transport chain and the whoa-are-you-serious molecular motor - the ATP synthase, imo the most incredible macromolecule not DNA. Okay potentially a tie with the Ribosome. Even better, this is an exceedingly efficient process that traps almost 40% of the energy in the form of ATP (the rest is lost as heat). This is much more efficient than your typical internal combustion motor at around 25%. I am also skipping a lot of incredible detail that doesn\u2019t fit into a paragraph, including how food is chopped up piece by piece all the way to tiny acetate molecules, how their electrons are stripped and loaded up on molecular shuttles (NAD+ -> NADH), how they then quantum tunnel their way down the electron transport chain (literally a flow of electricity down a protein complex \u201cwire\u201d, from food to oxygen), how this pumps protons across the inner mitochondrial membrane (an electrochemical equaivalent of pumping water uphill in a hydro plant), how this process is brilliant, flexible, ancient, highly conserved in all of life and very closely related to photosynthesis, and finally how the protons are allowed to flow back through little holes in the ATP synthase, spinning it like a water wheel on a river, and powering its head to take an ADP and a phosphate and snap them together to ATP."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p13", "contents": "Photosynthesis: \u201cinverse combustion\u201d. If H2O and CO2 are oh so energetically favored, it\u2019s worth keeping in mind where all of this C-C, C-H rich fuel came from in the first place. Of course, it comes from plants - the OG nanomolecular factories. In the process of photosynthesis, plants strip hydrogen atoms away from oxygen in molecules of water with light, and via further processing snatch carbon dioxide (CO2) lego blocks from the atmosphere to build all kinds of organics. Amusingly, unlike fixing hydrogen from H2O and carbon from CO2, plants are unable to fix the plethora of nitrogen from the atmosphere (the triple bond in N2 is very strong) and rely on bacteria to synthesize more chemically active forms (Ammonia, NH3), which is why chemical fertilizers are so important for plant growth and why the Haber-Bosch process basically averted the Malthusian catastrophe. Anyway, the point is that plants build all kinds of insanely complex organic molecules from these basic lego blocks (carbon dioxide, water) and all of it is fundamentally powered by light via the miracle of photosynthesis. The sunlight\u2019s energy is trapped in the C-C / C-H bonds of the manufactured organics, which we eat and oxidize back to CO2 / H2O (capturing ~40% of in the form of a 3rd phosphate group on ATP), and finally convert to blog posts like this one, and a bunch of heat. Also, going in I didn\u2019t quite appreciate just how much we know about all of the reactions involved, that we we can track individual atoms around all of them, and that any student can easily calculate answers to questions such as \u201cHow many ATP molecules are generated during the complete oxidation of one molecule of palmitic acid?\u201d (it\u2019s 106, now you know)."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p14", "contents": "We\u2019ve now established in some detail that fat is your body\u2019s primary battery pack and we\u2019d like to breathe it out. Let\u2019s turn to the details of the accounting."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p15", "contents": "Energy input. Humans turn out to have a very simple and surprisingly narrow energy metabolism. We don\u2019t partake in the miracle of photosynthesis like plants/cyanobacteria do. We don\u2019t oxidize inorganic compounds like hydrogen sulfide or nitrite or something like some of our bacteria/archaea cousins. Similar to everything else alive, we do not fuse or fission atomic nuclei (that would be awesome). No, the only way we input any and all energy into the system is through the breakdown of food. \u201cFood\u201d is actually a fairly narrow subset of organic molecules that we can digest and metabolize for energy. It includes classes of molecules that come in 3 major groups (\u201cmacros\u201d): proteins, fats, carbohydrates and a few other special case molecules like alcohol. There are plenty of molecules we can\u2019t metabolize for energy and don\u2019t count as food, such as cellulose (fiber; actually also a carbohydrate, a major component of plants, although some of it is digestible by some animals like cattle; also your microbiome loooves it), or hydrocarbons (which can only be \u201cmetabolized\u201d by our internal combustion engines). In any case, this makes for exceedingly simple accounting: the energy input to your body is upper bounded by the number of food calories that you eat. The food industry attempts to guesstimate these by adding up the macros in each food, and you can find these estimates on the nutrition labels. In particular, naive calorimetry would over-estimate food calories because as mentioned not everything combustible is digestible."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p16", "contents": "Energy output. You might think that most of your energy output would come from movement, but in fact 1) your body is exceedingly efficient when it comes to movement, and 2) it is energetically unintuitively expensive to just exist. To keep you alive your body has to maintain homeostasis, manage thermo-regulation, respiration, heartbeat, brain/nerve function, blood circulation, protein synthesis, active transport, etc etc. Collectively, this portion of energy expenditure is called the Base Metabolic Rate (BMR) and you burn this \u201cfor free\u201d even if you slept the entire day. As an example, my BMR is somewhere around 1800kcal/day (a common estimate due to Mifflin St. Jeor for men is 10 x weight (kg) + 6.25 x height (cm) - 5 x age (y) + 5). Anyone who\u2019s been at the gym and ran on a treadmill will know just how much of a free win this is. I start panting and sweating uncomfortably just after a small few hundred kcal of running. So yes, movement burns calories, but the 30min elliptical session you do in the gym is a drop in the bucket compared to your base metabolic rate. Of course if you\u2019re doing the elliptical for cardio-vascular health - great! But if you\u2019re doing it thinking that this is necessary or a major contributor to losing weight, you\u2019d be wrong."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p17", "contents": "Energy deficit. In summary, the amount of energy you expend (BMR + movement) subtract the amount you take in (via food alone) is your energy deficit. This means you will discharge your battery more than you charge it, and breathe out more fat than you synthesize/store, decreasing the size of your battery pack, and recording less on the scale because all those carbon atoms that made up your triglyceride chains in the morning are now diffused around the atmosphere."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p18", "contents": "So\u2026 a few textbooks later we see that to lose weight one should eat less and move more."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p19", "contents": "Experiment section. So how big of a deficit should one introduce? I did not want the deficit to be so large that it would stress me out, make me hangry and impact my work. In addition, with greater deficit your body will increasingly begin to sacrifice lean body mass (paper). To keep things simple, I aimed to lose about 1lb/week, which is consistent with a few recommendations I found in a few papers. Since 1lb = 454g, 1g of fat is estimated at approx. 9 kcal, and adipose tissue is ~87% lipids, some (very rough) napkin math suggests that 3500 kcal = 1lb of fat. The precise details of this are much more complicated, but this would suggest a target deficit of about 500 kcal/day. I found that it was hard to reach this deficit with calorie restriction alone, and psychologically it was much easier to eat near the break even point and create most of the deficit with cardio. It also helped a lot to adopt a 16:8 intermittent fasting schedule (i.e. \u201cskip breakfast\u201d, eat only from e.g. 12-8pm) which helps control appetite and dramatically reduces snacking. I started the experiment in June 2019 at about 195lb (day 120 on the chart below), and 1 year later I am at 165lb, giving an overall empirical rate of 0.58lb/week:"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p20", "contents": "Other stuff. I should mention that despite the focus of this post the experiment was of course much broader for me than weight loss alone, as I tried to improve many other variables I started to understand were linked to longevity and general well-being. I went on a relatively low carbohydrate mostly Pescetarian diet, I stopped eating nearly all forms of sugar (except for berries) and processed foods, I stopped drinking calories in any form (soda, orange juice, alcohol, milk), I started regular cardio a few times a week (first running then cycling), I started regular resistance training, etc. I am not militant about any of these and have cheated a number of times on all of it because I think sticking to it 90% of the time produces 90% of the benefit. As a result I\u2019ve improved a number of biomarkers (e.g. resting heart rate, resting blood glucose, strength, endurance, nutritional deficiencies, etc). I wish I could say I feel significantly better or sharper, but honestly I feel about the same. But the numbers tell me I\u2019m supposed to be on a better path and I think I am content with that \ud83e\udd37."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p21", "contents": "Explicit modeling. Now, getting back to weight, clearly the overall rate of 0.58lb/week is not our expected 1lb/week. To validate the energy deficit math I spent 100 days around late 2019 very carefully tracking my daily energy input and output. For the input I recorded my total calorie intake - I kept logs in my notes app of everything I ate. When nutrition labels were not available, I did my best to estimate the intake. Luckily, I have a strange obsession with guesstimating calories in any food, I\u2019ve done so for years for fun, and have gotten quite good at it. Isn\u2019t it a ton of fun to always guess calories in some food before checking the answer on the nutrition label and seeing if you fall within 10% correct? No? Alright. For energy output I recorded the number my Apple Watch reports in the \u201cActivity App\u201d. TLDR simply subtracting expenditure from intake gives the approximate deficit for that day, which we can use to calculate the expected weight loss, and finally compare to the actual weight loss. As an example, an excerpt of the raw data and the simple calculation looks something like:"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p22", "contents": "Where we have a few nan if I missed a weight measurement in the morning. Plotting this we get the following:"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p23", "contents": "Clearly, my actual weight loss (red) turned out to be slower than expected one based on our simple deficit math (blue). So this is where things get interesting. A number of possibilities come to mind. I could be consistently underestimating calories eaten. My Apple Watch could be overestimating my calorie expenditure. The naive conversion math of 1lb of fat = 3500 kcal could be off. I think one of the other significant culprits is that when I eat protein I am naively recording its caloric value under intake, implicitly assuming that my body burns it for energy. However, since I was simultaneously resistance training and building some muscle, my body could redirect 1g of protein into muscle and instead mobilize only ~0.5g of fat to cover the same energy need (since fat is 9kcal/g and protein only 4kcal/g). The outcome is that depending on my muscle gain my weight loss would look slower, as we observe. Most likely, some combination of all of the above is going on."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p24", "contents": "Water factor. Another fun thing I noticed is that my observed weight can fluctuate and rise a lot, even while my expected weight calculation expects a loss. I found that this discrepancy grows with the amount of carbohydrates in my diet (dessert, bread/pasta, potatoes, etc.). Eating these likely increases glycogen levels, which as I already mentioned briefly, acts as a sponge and soaks up water. I noticed that my weight can rise multiple pounds, but when I revert back to my typical low-carbohydrate pasketerianish diet these \u201cfake\u201d pounds evaporate in a matter of a few days. The final outcome are wild swings in my body weight depending mostly on how much candy I\u2019ve succumbed to, or if I squeezed in some pizza at a party."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p25", "contents": "Body composition. Since simultaneous muscle building skews the simple deficit math, to get a better fit we\u2019d have to understand the details of my body composition. The weight scale I use (Withings Body+) claims to estimate and separate fat weight and lean body weight by the use of bioelectrical impedance analysis, which uses the fact that more muscle is more water is less electrical resistance. This is the most common approach accessible to a regular consumer. I didn\u2019t know how much I could trust this measurement so I also ordered three DEXA scans (a gold standard for body composition measurements used in the literature based on low dosage X-rays) separated 1.5 months apart. I used BodySpec, who charge $45 per scan, each taking about 7 minutes at one of their physical locations. The amount of radiation is tiny - about 0.4 uSv, which is the dose you\u2019d get by eating 4 bananas (they contain radioactive potassium-40). I was not able to get a scan recently due to COVID-19. Here is my body composition data visualized from both sources during late 2019:"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p26", "contents": "BIA vs DEXA. Unfortunately, we can see that the BIA measurement provided by my scale disagrees with DEXA results by a lot. That said, I am also forced to interpret the DEXA scan with skepticism specifically for the lean body mass amount, which is affected by hydration level, with water showing up mostly as lean body mass. In particular, during my third measurement I was fasted and in ketosis. Hence my glycogen levels were low and I was less hydrated, which I believe showed up as a dramatic loss of muscle. That said, focusing on fat, both approaches show me losing body fat at roughly the same rate, though they are off by an absolute offset."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p27", "contents": "BIA. An additional way to see that BIA is making stuff up is that it shows me losing lean body mass over time. I find this relatively unlikely because during the entire course of this experiment I exercised regularly and was able to monotonically increase my strength in terms of weight and reps for most exercises (e.g. bench press, pull ups, etc.). So that makes no sense either \u00af\\(\u30c4)/\u00af"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p28", "contents": "Summary So there you have it. DEXA scans are severely affected by hydration (which is hard to control) and BIA is making stuff up entirely, so we don\u2019t get to fully resolve the mystery of the slower-than-expected weight loss. But overall, maintaining an average deficit of 500kcal per day did lead to about 60% of the expected weight loss over the course of a year. More importantly, we studied the process by which our Sun\u2019s free energy powers blog posts via a transformation of nuclear binding energy to electromagnetic radiation to heat. The photons power the fixing of carbon in CO2 and hydrogen in H2O into C-C/C-H rich organic molecules in plants, which we digest and break back down via a \u201cslow\u201d stepwise combustion in our cell\u2019s cytosols and mitochondria, which \u201ccharges\u201d some (ATP) molecular springs, which provide the \u201cumph\u201d that fires the neurons and moves the fingers. Also, any excess energy is stockpiled by the body as fat, so we need to intake less of it or \u201cwaste\u201d some of it away on movement to discharge our primary battery and breathe out our weight. It\u2019s been super fun to self-study these topics (which I skipped in high school), and I hope this post was an interesting intro to some of it. Okay great. I\u2019ll now go eat some cookies, because yolo."}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p29", "contents": "\n(later edits)"}
{"id": "http://karpathy.github.io//2020/06/11/biohacking-lite/_p30", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//about/_p0", "contents": "See my website."}
{"id": "http://karpathy.github.io//about/_p1", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io/#_p0", "contents": "Musings of a Computer Scientist."}
{"id": "http://karpathy.github.io//_p0", "contents": "Musings of a Computer Scientist."}
